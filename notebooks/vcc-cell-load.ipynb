{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837a8ecd",
   "metadata": {},
   "source": [
    "# VCC Submission Notebook\n",
    "\n",
    "Hello! \n",
    "\n",
    "This is a notebook that will help you prepare your predicted AnnData to be ready to be scored by `cell-eval` against a validation dataset.\n",
    "\n",
    "Before we begin you will need a few things:\n",
    "\n",
    "1. `cell-eval` installed and in your `$PATH` (see our [installation guide](https://github.com/ArcInstitute/cell-eval?tab=readme-ov-file#installation))\n",
    "2. The number of expected cells / perturbation in the validation dataset (CSV) ([download](https://virtualcellchallenge.org/app))\n",
    "3. The gene names to predict (CSV) ([download](https://virtualcellchallenge.org/app))\n",
    "4. Your model predictions in an AnnData (h5ad)\n",
    "5. (Optional) The training AnnData (if you are not predicting Non-Targeting Controls) ([download](https://virtualcellchallenge.org/app))\n",
    "\n",
    "\n",
    "> Note: Your model predictions **may not exceed 100K cells total**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc204d",
   "metadata": {},
   "source": [
    "## Building an Example Submission\n",
    "\n",
    "For the purposes of this tutorial we will be generating **random predictions** and preparing them to be evaluated.\n",
    "\n",
    "We will create an AnnData with *random gene abundances* for each cell, where the number of cells for each perturbation matches the number of cells in the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c543f",
   "metadata": {},
   "source": [
    "### Load in our Expected Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d172eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (50, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target_gene</th><th>n_cells</th><th>median_umi_per_cell</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;SH3BP4&quot;</td><td>2925</td><td>54551.0</td></tr><tr><td>&quot;ZNF581&quot;</td><td>2502</td><td>53803.5</td></tr><tr><td>&quot;ANXA6&quot;</td><td>2496</td><td>55175.0</td></tr><tr><td>&quot;PACSIN3&quot;</td><td>2101</td><td>54088.0</td></tr><tr><td>&quot;MGST1&quot;</td><td>2096</td><td>54217.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────┬─────────┬─────────────────────┐\n",
       "│ target_gene ┆ n_cells ┆ median_umi_per_cell │\n",
       "│ ---         ┆ ---     ┆ ---                 │\n",
       "│ str         ┆ i64     ┆ f64                 │\n",
       "╞═════════════╪═════════╪═════════════════════╡\n",
       "│ SH3BP4      ┆ 2925    ┆ 54551.0             │\n",
       "│ ZNF581      ┆ 2502    ┆ 53803.5             │\n",
       "│ ANXA6       ┆ 2496    ┆ 55175.0             │\n",
       "│ PACSIN3     ┆ 2101    ┆ 54088.0             │\n",
       "│ MGST1       ┆ 2096    ┆ 54217.5             │\n",
       "└─────────────┴─────────┴─────────────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Define our path\n",
    "pert_counts_path = \"../vcc_data/pert_counts_Validation.csv\"\n",
    "\n",
    "# Read in the csv\n",
    "pert_counts = pl.read_csv(pert_counts_path)\n",
    "\n",
    "# Show the dimensions\n",
    "print(f\"Dimensions: {pert_counts.shape}\")\n",
    "pert_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34164d85",
   "metadata": {},
   "source": [
    "### Load in our Expected Gene Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e3cfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SAMD11', 'NOC2L', 'KLHL17', ..., 'MT-ND5', 'MT-ND6', 'MT-CYB'],\n",
       "      shape=(18080,), dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_names_path = \"../vcc_data/gene_names.csv\"\n",
    "\n",
    "# Read this in and immediately convert to array\n",
    "gene_names = pl.read_csv(gene_names_path, has_header=False).to_numpy().flatten()\n",
    "\n",
    "gene_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322877ba-3464-4fc9-b8ea-e5a8999fd115",
   "metadata": {},
   "source": [
    "# Model inferrence to construct the anndata object for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f875fc3a-30e6-43c1-aeab-606f793972e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset path does not exist: /home/tphan/state/state/competition_support_set/{competition_train,k562_gwps,rpe1,jurkat,k562,hepg2}.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tphan/state/state/competition_support_set/{competition_train,k562_gwps,rpe1,jurkat,k562,hepg2}.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing replogle_h1:   0%|                                                                                        | 0/6 [00:00<?, ?it/s][INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "Processing replogle_h1:   0%|                                                                                        | 0/6 [00:00<?, ?it/s][INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "Processing replogle_h1:  33%|██████████████████████████▋                                                     | 2/6 [00:00<00:00, 12.63it/s][INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "Processing replogle_h1:  33%|██████████████████████████▋                                                     | 2/6 [00:00<00:00, 12.63it/s][INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "Processing replogle_h1:  33%|██████████████████████████▋                                                     | 2/6 [00:00<00:00, 12.63it/s][INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "Processing replogle_h1:  33%|██████████████████████████▋                                                     | 2/6 [00:00<00:00, 12.63it/s][INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "Processing replogle_h1: 100%|████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed competition_train: 221273 train, 0 val, 0 test\n",
      "Processed k562_gwps: 111605 train, 0 val, 0 test\n",
      "Processed rpe1: 22317 train, 0 val, 0 test\n",
      "Processed jurkat: 21412 train, 0 val, 0 test\n",
      "Processed k562: 18465 train, 0 val, 0 test\n",
      "Processed hepg2: 0 train, 0 val, 9386 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cell_load.data_modules import PerturbationDataModule\n",
    "dm = PerturbationDataModule(\n",
    "    toml_config_path=\"starter.toml\",\n",
    "    embed_key=None, \n",
    "    num_workers=8,\n",
    "    batch_col=\"batch_var\",\n",
    "    pert_col=\"target_gene\",\n",
    "    cell_type_key=\"cell_type\",\n",
    "    control_pert=\"non-targeting\",\n",
    "    use_scplode = True,\n",
    "    perturbation_features_file=\"/home/tphan/state/state/competition_support_set/ESM2_pert_features.pt\",\n",
    "    output_space=\"gene\",\n",
    "    basal_mapping_strategy=\"random\",\n",
    "    n_basal_samples=1,\n",
    "    should_yield_control_cells=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cd4bdb-f2ca-4f2d-8506-6d419be957b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from protoplast.scrna.models.baseline import BaselinePerturbModel\n",
    "\n",
    "G = 18080           # genes\n",
    "n_cell_lines = 5\n",
    "pert_d = 5120   # genes + control\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "last_ck = f\"baseline-delta-pert-emb/epoch=30.pt\"\n",
    "ckpt = torch.load(last_ck, map_location=device)\n",
    "model = BaselinePerturbModel(G, n_cell_lines, pert_d).to(device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac6b84d-e9cb-4a02-9e53-7d47122cab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('ARC_H1'): tensor([1., 0., 0., 0., 0.]),\n",
       " np.str_('hepg2'): tensor([0., 1., 0., 0., 0.]),\n",
       " np.str_('jurkat'): tensor([0., 0., 1., 0., 0.]),\n",
       " np.str_('k562'): tensor([0., 0., 0., 1., 0.]),\n",
       " np.str_('rpe1'): tensor([0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.cell_type_onehot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466d4e4f-037a-43c8-8c78-f97a773032b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on gene: 0\n",
      "working on gene: 5\n",
      "working on gene: 10\n",
      "working on gene: 15\n",
      "working on gene: 20\n",
      "working on gene: 25\n",
      "working on gene: 30\n",
      "working on gene: 35\n",
      "working on gene: 40\n",
      "working on gene: 45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "import anndata as ad\n",
    "import torch.nn.functional as F\n",
    "from scipy import sparse\n",
    "\n",
    "def model_inference(model,\n",
    "                    dm,\n",
    "                    pert_names: NDArray[np.str_],\n",
    "                    cell_counts: NDArray[np.int64],\n",
    "                    gene_names: NDArray[np.str_],\n",
    "                    max_count: int | float = 1e4,\n",
    "                    control_ratio = .3\n",
    "                   ):\n",
    "\n",
    "    obs_target_genes = []\n",
    "    X = None\n",
    "    total_cell = 0\n",
    "    for i, target_gene in enumerate(pert_names):\n",
    "        if not i % 5:\n",
    "            print(f\"working on gene: {i}\")\n",
    "        n_cells = int(cell_counts[i] * (1 + control_ratio))\n",
    "        total_cell += n_cells\n",
    "        n_ctrl = int(n_cells * control_ratio)\n",
    "        n_pert = n_cells - n_ctrl\n",
    "\n",
    "        xp = dm.pert_onehot_map[target_gene].to(device)\n",
    "        xp = xp.squeeze(0).expand(n_cells, -1)\n",
    "        y = dm.cell_type_onehot_map[\"ARC_H1\"].to(device)\n",
    "        y = y.squeeze(0).expand(n_cells, -1)\n",
    "        xh_ctrl, delta, xh_prt = model(y, xp)\n",
    "        ctrl_X = xh_ctrl[0:n_ctrl].detach().cpu().numpy()\n",
    "        ctrl_X = sparse.csr_matrix(ctrl_X) \n",
    "        pert_X = xh_prt[n_ctrl:n_cells].detach().cpu().numpy()\n",
    "        pert_X = sparse.csr_matrix(pert_X) \n",
    "        # TODO, make it sparse\n",
    "        if X is None:\n",
    "            X = sparse.vstack([ctrl_X, pert_X], format='csr')\n",
    "        else:\n",
    "            X = sparse.vstack([X, ctrl_X, pert_X], format='csr')\n",
    "        obs_target_genes += [\"non-targeting\"] * n_ctrl + [target_gene] * n_pert\n",
    "    return ad.AnnData(\n",
    "        X=X,\n",
    "        obs=pd.DataFrame(\n",
    "            {\n",
    "                \"target_gene\": obs_target_genes,\n",
    "            },\n",
    "            index=np.arange(total_cell).astype(str),\n",
    "        ),\n",
    "        var=pd.DataFrame(index=gene_names),\n",
    "    )\n",
    "adata = model_inference(model, dm, pert_counts[\"target_gene\"].to_numpy(), pert_counts[\"n_cells\"].to_numpy(), gene_names)\n",
    "adata.write_h5ad(\"./baseline-delta-pert-emb.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9de9dd",
   "metadata": {},
   "source": [
    "### Adding in Non-Targeting Controls if you are not predicting them\n",
    "\n",
    "Our evaluation framework expects non-targeting controls to be included in the predicted AnnData, but not all models may try to predict non-targeting controls.\n",
    "If you are not predicting non-targeting controls, you can take the non-targeting from the training AnnData and just copy them over into your predicted AnnData for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3879267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our path to the training anndata\n",
    "tr_adata_path = \"./adata_Training.h5ad\"\n",
    "\n",
    "# Read in the anndata\n",
    "tr_adata = ad.read_h5ad(tr_adata_path)\n",
    "\n",
    "# Filter for non-targeting\n",
    "ntc_adata = tr_adata[tr_adata.obs[\"target_gene\"] == \"non-targeting\"]\n",
    "\n",
    "# Append the non-targeting controls to the example anndata if they're missing\n",
    "if \"non-targeting\" not in adata.obs[\"target_gene\"].unique():\n",
    "    assert np.all(adata.var_names.values == ntc_adata.var_names.values), (\n",
    "        \"Gene-Names are out of order or unequal\"\n",
    "    )\n",
    "    adata = ad.concat(\n",
    "        [\n",
    "            adata,\n",
    "            ntc_adata,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19ac72",
   "metadata": {},
   "source": [
    "### Write our predictions to some output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386ee994",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(\"./baseline-delta-1.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd57ef",
   "metadata": {},
   "source": [
    "## Running `cell-eval prep`\n",
    "\n",
    "Now that we have our predictions, we will run `cell-eval` to prepare our AnnData for competition scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716a83e",
   "metadata": {},
   "source": [
    "```bash\n",
    "cell-eval prep \\\n",
    "    -i ./example.h5ad \\\n",
    "    --genes ./gene_names.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f938a60",
   "metadata": {},
   "source": [
    "And that's it! Your model outputs will be output to path: `./example.prep.vcc` are ready for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a396ade-929a-4815-ba76-1f0885283d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
