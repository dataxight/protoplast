{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837a8ecd",
   "metadata": {},
   "source": [
    "# VCC Submission Notebook\n",
    "\n",
    "Hello! \n",
    "\n",
    "This is a notebook that will help you prepare your predicted AnnData to be ready to be scored by `cell-eval` against a validation dataset.\n",
    "\n",
    "Before we begin you will need a few things:\n",
    "\n",
    "1. `cell-eval` installed and in your `$PATH` (see our [installation guide](https://github.com/ArcInstitute/cell-eval?tab=readme-ov-file#installation))\n",
    "2. The number of expected cells / perturbation in the validation dataset (CSV) ([download](https://virtualcellchallenge.org/app))\n",
    "3. The gene names to predict (CSV) ([download](https://virtualcellchallenge.org/app))\n",
    "4. Your model predictions in an AnnData (h5ad)\n",
    "5. (Optional) The training AnnData (if you are not predicting Non-Targeting Controls) ([download](https://virtualcellchallenge.org/app))\n",
    "\n",
    "\n",
    "> Note: Your model predictions **may not exceed 100K cells total**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc204d",
   "metadata": {},
   "source": [
    "## Building an Example Submission\n",
    "\n",
    "For the purposes of this tutorial we will be generating **random predictions** and preparing them to be evaluated.\n",
    "\n",
    "We will create an AnnData with *random gene abundances* for each cell, where the number of cells for each perturbation matches the number of cells in the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c543f",
   "metadata": {},
   "source": [
    "### Load in our Expected Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d172eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (50, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target_gene</th><th>n_cells</th><th>median_umi_per_cell</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;SH3BP4&quot;</td><td>2925</td><td>54551.0</td></tr><tr><td>&quot;ZNF581&quot;</td><td>2502</td><td>53803.5</td></tr><tr><td>&quot;ANXA6&quot;</td><td>2496</td><td>55175.0</td></tr><tr><td>&quot;PACSIN3&quot;</td><td>2101</td><td>54088.0</td></tr><tr><td>&quot;MGST1&quot;</td><td>2096</td><td>54217.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────┬─────────┬─────────────────────┐\n",
       "│ target_gene ┆ n_cells ┆ median_umi_per_cell │\n",
       "│ ---         ┆ ---     ┆ ---                 │\n",
       "│ str         ┆ i64     ┆ f64                 │\n",
       "╞═════════════╪═════════╪═════════════════════╡\n",
       "│ SH3BP4      ┆ 2925    ┆ 54551.0             │\n",
       "│ ZNF581      ┆ 2502    ┆ 53803.5             │\n",
       "│ ANXA6       ┆ 2496    ┆ 55175.0             │\n",
       "│ PACSIN3     ┆ 2101    ┆ 54088.0             │\n",
       "│ MGST1       ┆ 2096    ┆ 54217.5             │\n",
       "└─────────────┴─────────┴─────────────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Define our path\n",
    "pert_counts_path = \"../vcc_data/pert_counts_Validation.csv\"\n",
    "\n",
    "# pert_counts_path = \"gene_counts_arc_h1_true_validation.csv\"\n",
    "\n",
    "# Read in the csv\n",
    "pert_counts = pl.read_csv(pert_counts_path)\n",
    "\n",
    "# Show the dimensions\n",
    "print(f\"Dimensions: {pert_counts.shape}\")\n",
    "pert_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34164d85",
   "metadata": {},
   "source": [
    "### Load in our Expected Gene Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e3cfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SAMD11', 'NOC2L', 'KLHL17', ..., 'MT-ND5', 'MT-ND6', 'MT-CYB'],\n",
       "      shape=(18080,), dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_names_path = \"../vcc_data/gene_names.csv\"\n",
    "\n",
    "# Read this in and immediately convert to array\n",
    "gene_names = pl.read_csv(gene_names_path, has_header=False).to_numpy().flatten()\n",
    "\n",
    "gene_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322877ba-3464-4fc9-b8ea-e5a8999fd115",
   "metadata": {},
   "source": [
    "# Model inferrence to construct the anndata object for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f875fc3a-30e6-43c1-aeab-606f793972e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Applied AnnDataFileManager patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 05:18:07,511 - protoplast.scrna.anndata.pert_dataset - INFO - write mmap file for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/competition_train.h5\n",
      "[INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "2025-09-08 05:18:07,550 - protoplast.scrna.anndata.pert_dataset - INFO - n_obs for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/competition_train.h5: 221273\n",
      "2025-09-08 05:18:07,551 - protoplast.scrna.anndata.pert_dataset - INFO - write mmap file for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/hepg2.h5\n",
      "[INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "2025-09-08 05:18:07,559 - protoplast.scrna.anndata.pert_dataset - INFO - n_obs for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/hepg2.h5: 9386\n",
      "2025-09-08 05:18:07,559 - protoplast.scrna.anndata.pert_dataset - INFO - write mmap file for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/jurkat.h5\n",
      "[INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "2025-09-08 05:18:07,569 - protoplast.scrna.anndata.pert_dataset - INFO - n_obs for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/jurkat.h5: 21412\n",
      "2025-09-08 05:18:07,570 - protoplast.scrna.anndata.pert_dataset - INFO - write mmap file for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/k562.h5\n",
      "[INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "2025-09-08 05:18:07,579 - protoplast.scrna.anndata.pert_dataset - INFO - n_obs for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/k562.h5: 18465\n",
      "2025-09-08 05:18:07,580 - protoplast.scrna.anndata.pert_dataset - INFO - write mmap file for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/k562_gwps.h5\n",
      "[INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "2025-09-08 05:18:07,609 - protoplast.scrna.anndata.pert_dataset - INFO - n_obs for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/k562_gwps.h5: 111605\n",
      "2025-09-08 05:18:07,610 - protoplast.scrna.anndata.pert_dataset - INFO - write mmap file for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/rpe1.h5\n",
      "[INFO] Loading index: obs\n",
      "[INFO] Loading index: var\n",
      "[INFO] Loading index: dat (implicitly)\n",
      "2025-09-08 05:18:07,620 - protoplast.scrna.anndata.pert_dataset - INFO - n_obs for /home/tphan/Softwares/protoplast/notebooks/competition_support_set/rpe1.h5: 22317\n",
      "2025-09-08 05:18:08,146 - protoplast.scrna.anndata.pert_dataset - INFO - n_cells: 404458\n",
      "2025-09-08 05:18:08,148 - protoplast.scrna.anndata.pert_dataset - INFO - n_genes: 18080\n",
      "2025-09-08 05:18:08,380 - protoplast.scrna.anndata.pert_dataset - INFO - Total unique cell types: 5\n",
      "2025-09-08 05:18:08,856 - protoplast.scrna.anndata.pert_dataset - INFO - Total unique batches: 536\n",
      "2025-09-08 05:18:08,871 - protoplast.scrna.anndata.pert_dataset - INFO - Total control cells: 152669\n"
     ]
    }
   ],
   "source": [
    "from protoplast.scrna.anndata.pert_modules import PerturbDataModule\n",
    "dm = PerturbDataModule(\n",
    "        config_path=\"pert-dataconfig.toml\",\n",
    "        pert_embedding_file=\"/home/tphan/Softwares/protoplast/notebooks/competition_support_set/ESM2_pert_features.pt\",\n",
    "        train_batch_size=1024,\n",
    "        eval_batch_size=256,\n",
    "        num_workers=8,\n",
    "        persistent_workers=True,\n",
    "        n_basal_samples=10,\n",
    "        barcodes=True\n",
    "    )\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e620aff-db63-482d-8a05-efcde170e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cd4bdb-f2ca-4f2d-8506-6d419be957b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from protoplast.scrna.models.cpa_vae_deepset import CPAVAE_Simple\n",
    "\n",
    "G = 18080\n",
    "n_cell_lines = 5\n",
    "n_batches = 536\n",
    "d_xp = 5120\n",
    "device = \"cuda\"\n",
    "\n",
    "# ---- Training loop ----\n",
    "model = CPAVAE_Simple(G, n_cell_lines, d_xp=d_xp).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "last_ck = f\"cpa-vae-ctrl-set//epoch=25.pt\"\n",
    "ckpt = torch.load(last_ck, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac6b84d-e9cb-4a02-9e53-7d47122cab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('ARC_H1'): tensor([1., 0., 0., 0., 0.]),\n",
       " np.str_('hepg2'): tensor([0., 1., 0., 0., 0.]),\n",
       " np.str_('jurkat'): tensor([0., 0., 1., 0., 0.]),\n",
       " np.str_('k562'): tensor([0., 0., 0., 1., 0.]),\n",
       " np.str_('rpe1'): tensor([0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.ds.cell_types_onehot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099093a6-c1d9-43b0-89dc-756eb64d6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the control set\n",
    "import anndata as ad\n",
    "tr_adata_path = \"./competition_support_set/competition_train.h5\"\n",
    "tr_adata = ad.read_h5ad(tr_adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21dc9fee-844c-49f7-a1a5-90cce2188de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "control_indices = np.where(tr_adata.obs.target_gene == \"non-targeting\")[0]\n",
    "control30 = random.sample(control_indices.tolist(), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9646f5-fccd-4f1e-a08c-8e10e658331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control = tr_adata.X[control30, :].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34e674d-459f-4111-b0ae-c5ea81c2df09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.6931, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0986, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0986, 1.0986],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.6931, 0.0000],\n",
       "        [0.0000, 1.0986, 0.0000,  ..., 0.0000, 1.3863, 1.6094]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X_control = torch.tensor(X_control).to(device)\n",
    "X_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466d4e4f-037a-43c8-8c78-f97a773032b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on gene: 0\n",
      "working on gene: 5\n",
      "working on gene: 10\n",
      "working on gene: 15\n",
      "working on gene: 20\n",
      "working on gene: 25\n",
      "working on gene: 30\n",
      "working on gene: 35\n",
      "working on gene: 40\n",
      "working on gene: 45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "import anndata as ad\n",
    "import torch.nn.functional as F\n",
    "from scipy import sparse\n",
    "\n",
    "def model_inference(model,\n",
    "                    dm,\n",
    "                    pert_names: NDArray[np.str_],\n",
    "                    cell_counts: NDArray[np.int64],\n",
    "                    median_library_size: NDArray[np.int64],\n",
    "                    gene_names: NDArray[np.str_],\n",
    "                    X_control = NDArray[np.float64]\n",
    "                   ):\n",
    "\n",
    "    obs_target_genes = []\n",
    "    X = None\n",
    "    total_cell = 0\n",
    "    for i, target_gene in enumerate(pert_names):\n",
    "        if not i % 5:\n",
    "            print(f\"working on gene: {i}\")\n",
    "        n_cells = int(cell_counts[i] / 2)\n",
    "        total_cell += n_cells\n",
    "\n",
    "        xp = dm.ds.pert_embedding[target_gene].to(device)\n",
    "        xp = xp.squeeze(0).expand(n_cells, -1)\n",
    "        y = dm.ds.cell_types_onehot_map[\"ARC_H1\"].to(device)\n",
    "        y = y.squeeze(0).expand(n_cells, -1)\n",
    "        x_ctrl_set = X_control.unsqueeze(0).repeat(n_cells, 1, 1)\n",
    "        # ---- generate from (y, xp) ----\n",
    "        xhat_ctrl, xhat_pert, mu_x_pert, logvar_x_pert = model.predict_from_yxp(y, xp, x_ctrl_set, sample=True, temperature=1.0)\n",
    "        del x_ctrl_set\n",
    "        torch.cuda.empty_cache()\n",
    "        # xhat_counts = torch.poisson(torch.expm1(xhat_pert))\n",
    "        # library_size = xhat_counts.sum(dim=1)\n",
    "        # factor = median_library_size[i] / library_size\n",
    "        # xhat_counts = xhat_counts * factor[:, None]\n",
    "        # xhat_log = torch.log1p(xhat_counts)\n",
    "        pert_X = sparse.csr_matrix(xhat_pert.detach().cpu().numpy()) \n",
    "        # TODO, make it sparse\n",
    "        if X is None:\n",
    "            X = sparse.vstack([pert_X], format='csr')\n",
    "        else:\n",
    "            X = sparse.vstack([X, pert_X], format='csr')\n",
    "        obs_target_genes += [target_gene] * n_cells\n",
    "    return ad.AnnData(\n",
    "        X=X,\n",
    "        obs=pd.DataFrame(\n",
    "            {\n",
    "                \"target_gene\": obs_target_genes,\n",
    "            },\n",
    "            index=np.arange(total_cell).astype(str),\n",
    "        ),\n",
    "        var=pd.DataFrame(index=gene_names),\n",
    "    )\n",
    "adata = model_inference(model, dm, pert_counts[\"target_gene\"].to_numpy(), pert_counts[\"n_cells\"].to_numpy(), pert_counts[\"median_umi_per_cell\"].to_numpy(), gene_names, X_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d1b360-95ba-47ba-86ec-dd0014ac8670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 30364 × 18080\n",
       "    obs: 'target_gene'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc1c02c-7c9d-44a1-8f37-0f7e68d9e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_controls = 10000\n",
    "controls = random.sample(control_indices.tolist(), n_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9de9dd",
   "metadata": {},
   "source": [
    "### Adding in Non-Targeting Controls if you are not predicting them\n",
    "\n",
    "Our evaluation framework expects non-targeting controls to be included in the predicted AnnData, but not all models may try to predict non-targeting controls.\n",
    "If you are not predicting non-targeting controls, you can take the non-targeting from the training AnnData and just copy them over into your predicted AnnData for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3879267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for non-targeting\n",
    "ntc_adata = tr_adata[controls]\n",
    "\n",
    "# Append the non-targeting controls to the example anndata if they're missing\n",
    "if \"non-targeting\" not in adata.obs[\"target_gene\"].unique():\n",
    "    assert np.all(adata.var_names.values == ntc_adata.var_names.values), (\n",
    "        \"Gene-Names are out of order or unequal\"\n",
    "    )\n",
    "    adata = ad.concat(\n",
    "        [\n",
    "            adata,\n",
    "            ntc_adata,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff3813f-60ca-4135-a7e6-0d19a571b5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 40364 × 18080\n",
       "    obs: 'target_gene'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19ac72",
   "metadata": {},
   "source": [
    "### Write our predictions to some output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386ee994",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(\"./cpa-vae-simple-deepset-epoch25.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd57ef",
   "metadata": {},
   "source": [
    "## Running `cell-eval prep`\n",
    "\n",
    "Now that we have our predictions, we will run `cell-eval` to prepare our AnnData for competition scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716a83e",
   "metadata": {},
   "source": [
    "```bash\n",
    "cell-eval prep \\\n",
    "    -i ./example.h5ad \\\n",
    "    --genes ./gene_names.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f938a60",
   "metadata": {},
   "source": [
    "And that's it! Your model outputs will be output to path: `./example.prep.vcc` are ready for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a396ade-929a-4815-ba76-1f0885283d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
