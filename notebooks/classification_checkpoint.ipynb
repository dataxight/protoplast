{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66267ca4-71ee-44a2-b428-723c23e02526",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Showcasing Protoplast Checkpointing in Cell-line Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook showcases the checkpointing feature in PROTOplast, which enables resuming model training even after interruptions or switching to a different dataset. It demonstrates how to save and load training checkpoints, making it easy to continue model development without starting from scratch. This is particularly useful for long training sessions, experimentation with various datasets, or training across multiple sessions or environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vblA",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Applied AnnDataFileManager patch\n",
      "✓ Applied AnnDataFileManager patch\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import protoplast as pt\n",
    "import ray\n",
    "import torch\n",
    "\n",
    "from anndata.experimental import AnnCollection\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedAnnDataset\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb, DistributedCellLineAnnDataset\n",
    "\n",
    "from ray.train import Checkpoint\n",
    "from ray.train.lightning import RayDDPStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## 2. Dataset pre-processing\n",
    "\n",
    "We begin by reading the two datasets used to train the cell-line classification model in this notebook. To ensure compatibility, the model requires that both datasets have the same output dimensions\n",
    "\n",
    "In the following section, we create a unified view by performing an **inner join** on the two datasets based on shared features. During this step, we:\n",
    "\n",
    "- Identify and record the **number of output classes** (cell-lines),\n",
    "- Extract the list of **cell-line** of both dataset.\n",
    "\n",
    "This alignment is essential to ensure the model receives a consistent input/output structure regardless of the dataset source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATHS = [\"/mnt/hdd2/tan/tahoe100m/plate1_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\",\n",
    "           \"/mnt/hdd2/tan/tahoe100m/plate2_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
    "adatas = [anndata.io.read_h5ad(p, backed = \"r\") for p in DS_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view of all dataset\n",
    "collection = AnnCollection(adatas, join_vars = \"inner\")\n",
    "\n",
    "# Record the cell-lines (output classes) in both datasets\n",
    "cell_lines = collection.obs.cell_line.unique().tolist()\n",
    "cell_lines_count = collection.obs.cell_line.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## 3. Configure training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_per_worker = 12\n",
    "test_size = 0.2 \n",
    "val_size = 0.0 # if you have only training and test data, just put val_size = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## 4. Train on `plate1_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate1_adata = adatas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Hstk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>gene_count</th>\n",
       "      <th>tscp_count</th>\n",
       "      <th>mread_count</th>\n",
       "      <th>drugname_drugconc</th>\n",
       "      <th>drug</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>sublibrary</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>pcnt_mito</th>\n",
       "      <th>S_score</th>\n",
       "      <th>G2M_score</th>\n",
       "      <th>phase</th>\n",
       "      <th>pass_filter</th>\n",
       "      <th>cell_name</th>\n",
       "      <th>plate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARCODE_SUB_LIB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_001_025-lib_841</th>\n",
       "      <td>smp_1495</td>\n",
       "      <td>1676</td>\n",
       "      <td>2441</td>\n",
       "      <td>2892</td>\n",
       "      <td>[('Infigratinib', 0.05, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0131</td>\n",
       "      <td>lib_841</td>\n",
       "      <td>01_001_025</td>\n",
       "      <td>0.025399</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.095055</td>\n",
       "      <td>G1</td>\n",
       "      <td>full</td>\n",
       "      <td>A-172</td>\n",
       "      <td>plate1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_026-lib_841</th>\n",
       "      <td>smp_1495</td>\n",
       "      <td>1657</td>\n",
       "      <td>2454</td>\n",
       "      <td>2925</td>\n",
       "      <td>[('Infigratinib', 0.05, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0480</td>\n",
       "      <td>lib_841</td>\n",
       "      <td>01_001_026</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.650549</td>\n",
       "      <td>G2M</td>\n",
       "      <td>full</td>\n",
       "      <td>PANC-1</td>\n",
       "      <td>plate1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_048-lib_841</th>\n",
       "      <td>smp_1495</td>\n",
       "      <td>1749</td>\n",
       "      <td>2521</td>\n",
       "      <td>2963</td>\n",
       "      <td>[('Infigratinib', 0.05, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0293</td>\n",
       "      <td>lib_841</td>\n",
       "      <td>01_001_048</td>\n",
       "      <td>0.056724</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>G2M</td>\n",
       "      <td>full</td>\n",
       "      <td>HEC-1-A</td>\n",
       "      <td>plate1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_076-lib_841</th>\n",
       "      <td>smp_1495</td>\n",
       "      <td>834</td>\n",
       "      <td>1038</td>\n",
       "      <td>1258</td>\n",
       "      <td>[('Infigratinib', 0.05, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0397</td>\n",
       "      <td>lib_841</td>\n",
       "      <td>01_001_076</td>\n",
       "      <td>0.066474</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.245788</td>\n",
       "      <td>G2M</td>\n",
       "      <td>full</td>\n",
       "      <td>LS 180</td>\n",
       "      <td>plate1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_088-lib_841</th>\n",
       "      <td>smp_1495</td>\n",
       "      <td>1275</td>\n",
       "      <td>1710</td>\n",
       "      <td>2006</td>\n",
       "      <td>[('Infigratinib', 0.05, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_1097</td>\n",
       "      <td>lib_841</td>\n",
       "      <td>01_001_088</td>\n",
       "      <td>0.028655</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.085348</td>\n",
       "      <td>G1</td>\n",
       "      <td>full</td>\n",
       "      <td>C32</td>\n",
       "      <td>plate1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sample  gene_count  tscp_count  mread_count  \\\n",
       "BARCODE_SUB_LIB_ID                                                  \n",
       "01_001_025-lib_841  smp_1495        1676        2441         2892   \n",
       "01_001_026-lib_841  smp_1495        1657        2454         2925   \n",
       "01_001_048-lib_841  smp_1495        1749        2521         2963   \n",
       "01_001_076-lib_841  smp_1495         834        1038         1258   \n",
       "01_001_088-lib_841  smp_1495        1275        1710         2006   \n",
       "\n",
       "                                 drugname_drugconc          drug  cell_line  \\\n",
       "BARCODE_SUB_LIB_ID                                                            \n",
       "01_001_025-lib_841  [('Infigratinib', 0.05, 'uM')]  Infigratinib  CVCL_0131   \n",
       "01_001_026-lib_841  [('Infigratinib', 0.05, 'uM')]  Infigratinib  CVCL_0480   \n",
       "01_001_048-lib_841  [('Infigratinib', 0.05, 'uM')]  Infigratinib  CVCL_0293   \n",
       "01_001_076-lib_841  [('Infigratinib', 0.05, 'uM')]  Infigratinib  CVCL_0397   \n",
       "01_001_088-lib_841  [('Infigratinib', 0.05, 'uM')]  Infigratinib  CVCL_1097   \n",
       "\n",
       "                   sublibrary     BARCODE  pcnt_mito   S_score  G2M_score  \\\n",
       "BARCODE_SUB_LIB_ID                                                          \n",
       "01_001_025-lib_841    lib_841  01_001_025   0.025399 -0.066667  -0.095055   \n",
       "01_001_026-lib_841    lib_841  01_001_026   0.042787  0.128571   0.650549   \n",
       "01_001_048-lib_841    lib_841  01_001_048   0.056724  0.242857   0.308791   \n",
       "01_001_076-lib_841    lib_841  01_001_076   0.066474  0.009524   0.245788   \n",
       "01_001_088-lib_841    lib_841  01_001_088   0.028655 -0.100000  -0.085348   \n",
       "\n",
       "                   phase pass_filter cell_name   plate  \n",
       "BARCODE_SUB_LIB_ID                                      \n",
       "01_001_025-lib_841    G1        full     A-172  plate1  \n",
       "01_001_026-lib_841   G2M        full    PANC-1  plate1  \n",
       "01_001_048-lib_841   G2M        full   HEC-1-A  plate1  \n",
       "01_001_076-lib_841   G2M        full    LS 180  plate1  \n",
       "01_001_088-lib_841    G1        full       C32  plate1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate1_adata.obs.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ROlb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 06:41:41,087\tINFO worker.py:1951 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=425332)\u001b[0m ✓ Applied AnnDataFileManager patch\n",
      "\u001b[36m(TrainTrainable pid=425332)\u001b[0m ✓ Applied AnnDataFileManager patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=425332)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=425332)\u001b[0m - (node_id=0006e3752903b255c8b7b4e65afdd75a78a7465fb4a83ffa9a32d9c8, ip=192.168.1.226, pid=425562) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m ✓ Applied AnnDataFileManager patch\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m ✓ Applied AnnDataFileManager patch\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m =========Starting the training on 0 with num threads: 12=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.11 /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.1 ...\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4297 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/4297 [00:15<18:40:07,  0.06it/s, v_num=0, train_loss=3.990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 2/4297 [00:15<9:26:46,  0.13it/s, v_num=0, train_loss=3.600] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 4/4297 [00:16<4:52:40,  0.24it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 0:   0%|          | 9/4297 [00:16<2:11:33,  0.54it/s, v_num=0, train_loss=0.832]\n",
      "Epoch 0:   0%|          | 17/4297 [00:16<1:09:58,  1.02it/s, v_num=0, train_loss=0.482]\n",
      "Epoch 0:   0%|          | 18/4297 [00:16<1:06:08,  1.08it/s, v_num=0, train_loss=0.496]\n",
      "Epoch 0:   1%|          | 27/4297 [00:16<44:18,  1.61it/s, v_num=0, train_loss=0.316]  \n",
      "Epoch 0:   1%|          | 35/4297 [00:16<34:20,  2.07it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:   1%|          | 36/4297 [00:16<33:24,  2.13it/s, v_num=0, train_loss=0.250]\n",
      "Epoch 0:   1%|          | 37/4297 [00:16<32:31,  2.18it/s, v_num=0, train_loss=0.250]\n",
      "Epoch 0:   1%|          | 37/4297 [00:16<32:31,  2.18it/s, v_num=0, train_loss=0.211]\n",
      "Epoch 0:   1%|          | 45/4297 [00:17<26:52,  2.64it/s, v_num=0, train_loss=0.283] \n",
      "Epoch 0:   1%|          | 45/4297 [00:17<26:52,  2.64it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:   1%|          | 46/4297 [00:17<26:18,  2.69it/s, v_num=0, train_loss=0.382]\n",
      "Epoch 0:   1%|          | 52/4297 [00:17<23:23,  3.02it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:   1%|▏         | 59/4297 [00:17<20:43,  3.41it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:   2%|▏         | 67/4297 [00:17<18:20,  3.84it/s, v_num=0, train_loss=0.178]\n",
      "Epoch 0:   2%|▏         | 74/4297 [00:17<16:41,  4.22it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0:   2%|▏         | 81/4297 [00:17<15:18,  4.59it/s, v_num=0, train_loss=0.231] \n",
      "Epoch 0:   2%|▏         | 82/4297 [00:17<15:08,  4.64it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:   2%|▏         | 83/4297 [00:17<14:57,  4.69it/s, v_num=0, train_loss=0.236]\n",
      "Epoch 0:   2%|▏         | 91/4297 [00:17<13:42,  5.11it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:   2%|▏         | 92/4297 [00:17<13:33,  5.17it/s, v_num=0, train_loss=0.282]\n",
      "Epoch 0:   2%|▏         | 93/4297 [00:17<13:25,  5.22it/s, v_num=0, train_loss=0.336]\n",
      "Epoch 0:   2%|▏         | 100/4297 [00:17<12:31,  5.58it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:   2%|▏         | 101/4297 [00:17<12:25,  5.63it/s, v_num=0, train_loss=0.0795]\n",
      "Epoch 0:   3%|▎         | 108/4297 [00:18<11:40,  5.98it/s, v_num=0, train_loss=0.258] \n",
      "Epoch 0:   3%|▎         | 109/4297 [00:18<11:34,  6.03it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:   3%|▎         | 117/4297 [00:18<10:49,  6.44it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:   3%|▎         | 125/4297 [00:18<10:10,  6.83it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:   3%|▎         | 126/4297 [00:18<10:05,  6.88it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:   3%|▎         | 135/4297 [00:18<09:27,  7.33it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:   3%|▎         | 141/4297 [00:18<09:06,  7.61it/s, v_num=0, train_loss=0.217]\n",
      "Epoch 0:   3%|▎         | 142/4297 [00:18<09:02,  7.65it/s, v_num=0, train_loss=0.193]\n",
      "Epoch 0:   3%|▎         | 149/4297 [00:18<08:39,  7.98it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:   4%|▎         | 156/4297 [00:18<08:18,  8.30it/s, v_num=0, train_loss=0.204]\n",
      "Epoch 0:   4%|▍         | 163/4297 [00:18<07:59,  8.63it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:   4%|▍         | 169/4297 [00:19<07:44,  8.89it/s, v_num=0, train_loss=0.299]\n",
      "Epoch 0:   4%|▍         | 170/4297 [00:19<07:41,  8.94it/s, v_num=0, train_loss=0.235]\n",
      "Epoch 0:   4%|▍         | 175/4297 [00:19<07:30,  9.14it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:   4%|▍         | 182/4297 [00:19<07:15,  9.46it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:   4%|▍         | 188/4297 [00:19<07:03,  9.71it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:   4%|▍         | 189/4297 [00:19<07:01,  9.75it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:   4%|▍         | 189/4297 [00:19<07:01,  9.75it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:   5%|▍         | 196/4297 [00:19<06:47, 10.05it/s, v_num=0, train_loss=0.190]\n",
      "Epoch 0:   5%|▍         | 202/4297 [00:19<06:37, 10.30it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:   5%|▍         | 203/4297 [00:19<06:35, 10.35it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:   5%|▍         | 209/4297 [00:19<06:26, 10.59it/s, v_num=0, train_loss=0.0512]\n",
      "Epoch 0:   5%|▌         | 216/4297 [00:19<06:15, 10.88it/s, v_num=0, train_loss=0.258] \n",
      "Epoch 0:   5%|▌         | 223/4297 [00:19<06:04, 11.16it/s, v_num=0, train_loss=0.209]\n",
      "Epoch 0:   5%|▌         | 230/4297 [00:20<05:55, 11.45it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:   5%|▌         | 236/4297 [00:20<05:47, 11.69it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:   6%|▌         | 237/4297 [00:20<05:46, 11.72it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:   6%|▌         | 238/4297 [00:20<05:44, 11.77it/s, v_num=0, train_loss=0.221]\n",
      "Epoch 0:   6%|▌         | 244/4297 [00:20<05:37, 11.99it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:   6%|▌         | 252/4297 [00:20<05:28, 12.31it/s, v_num=0, train_loss=0.275] \n",
      "Epoch 0:   6%|▌         | 259/4297 [00:20<05:20, 12.59it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:   6%|▌         | 260/4297 [00:20<05:19, 12.63it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:   6%|▌         | 268/4297 [00:20<05:11, 12.94it/s, v_num=0, train_loss=0.268] \n",
      "Epoch 0:   6%|▋         | 276/4297 [00:20<05:03, 13.26it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:   6%|▋         | 277/4297 [00:20<05:02, 13.30it/s, v_num=0, train_loss=0.241]\n",
      "Epoch 0:   7%|▋         | 285/4297 [00:20<04:54, 13.61it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:   7%|▋         | 286/4297 [00:20<04:53, 13.65it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:   7%|▋         | 286/4297 [00:20<04:53, 13.65it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:   7%|▋         | 293/4297 [00:21<04:47, 13.91it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:   7%|▋         | 294/4297 [00:21<04:46, 13.95it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:   7%|▋         | 300/4297 [00:21<04:42, 14.17it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:   7%|▋         | 301/4297 [00:21<04:41, 14.21it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:   7%|▋         | 308/4297 [00:21<04:35, 14.47it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:   7%|▋         | 309/4297 [00:21<04:35, 14.50it/s, v_num=0, train_loss=0.254]\n",
      "Epoch 0:   7%|▋         | 316/4297 [00:21<04:29, 14.75it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:   8%|▊         | 323/4297 [00:21<04:25, 14.99it/s, v_num=0, train_loss=0.0668]\n",
      "Epoch 0:   8%|▊         | 324/4297 [00:21<04:24, 15.03it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:   8%|▊         | 330/4297 [00:21<04:20, 15.24it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:   8%|▊         | 331/4297 [00:21<04:19, 15.27it/s, v_num=0, train_loss=0.227]\n",
      "Epoch 0:   8%|▊         | 337/4297 [00:21<04:16, 15.47it/s, v_num=0, train_loss=0.188] \n",
      "Epoch 0:   8%|▊         | 338/4297 [00:21<04:15, 15.50it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:   8%|▊         | 346/4297 [00:21<04:10, 15.79it/s, v_num=0, train_loss=0.211] \n",
      "Epoch 0:   8%|▊         | 352/4297 [00:22<04:06, 15.99it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:   8%|▊         | 353/4297 [00:22<04:06, 16.01it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:   8%|▊         | 358/4297 [00:22<04:03, 16.16it/s, v_num=0, train_loss=0.0933]\n",
      "Epoch 0:   8%|▊         | 359/4297 [00:22<04:03, 16.19it/s, v_num=0, train_loss=0.0622]\n",
      "Epoch 0:   8%|▊         | 365/4297 [00:22<04:00, 16.38it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:   9%|▊         | 371/4297 [00:22<03:57, 16.56it/s, v_num=0, train_loss=0.0825]\n",
      "Epoch 0:   9%|▉         | 376/4297 [00:22<03:54, 16.70it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:   9%|▉         | 377/4297 [00:22<03:54, 16.73it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:   9%|▉         | 382/4297 [00:22<03:52, 16.87it/s, v_num=0, train_loss=0.0965]\n",
      "Epoch 0:   9%|▉         | 384/4297 [00:22<03:51, 16.92it/s, v_num=0, train_loss=0.240] \n",
      "Epoch 0:   9%|▉         | 386/4297 [00:24<04:06, 15.87it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:   9%|▉         | 387/4297 [00:24<04:05, 15.90it/s, v_num=0, train_loss=0.219]\n",
      "Epoch 0:   9%|▉         | 391/4297 [00:24<04:04, 15.99it/s, v_num=0, train_loss=0.254] \n",
      "Epoch 0:   9%|▉         | 398/4297 [00:24<04:00, 16.21it/s, v_num=0, train_loss=0.177] \n",
      "Epoch 0:   9%|▉         | 399/4297 [00:24<04:00, 16.24it/s, v_num=0, train_loss=0.195]\n",
      "Epoch 0:   9%|▉         | 407/4297 [00:24<03:55, 16.49it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:   9%|▉         | 408/4297 [00:24<03:55, 16.52it/s, v_num=0, train_loss=0.054]\n",
      "Epoch 0:  10%|▉         | 417/4297 [00:24<03:50, 16.80it/s, v_num=0, train_loss=0.0737]\n",
      "Epoch 0:  10%|▉         | 425/4297 [00:24<03:47, 17.05it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  10%|▉         | 426/4297 [00:24<03:46, 17.08it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  10%|▉         | 427/4297 [00:24<03:46, 17.12it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  10%|█         | 435/4297 [00:25<03:42, 17.36it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  10%|█         | 436/4297 [00:25<03:42, 17.39it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  10%|█         | 442/4297 [00:25<03:39, 17.56it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  10%|█         | 443/4297 [00:25<03:39, 17.59it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  10%|█         | 450/4297 [00:25<03:36, 17.78it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  11%|█         | 457/4297 [00:25<03:33, 17.98it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  11%|█         | 458/4297 [00:25<03:33, 18.01it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  11%|█         | 466/4297 [00:25<03:30, 18.24it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  11%|█         | 472/4297 [00:25<03:27, 18.40it/s, v_num=0, train_loss=0.202] \n",
      "Epoch 0:  11%|█         | 473/4297 [00:25<03:27, 18.42it/s, v_num=0, train_loss=0.132]\n",
      "Epoch 0:  11%|█         | 480/4297 [00:25<03:25, 18.61it/s, v_num=0, train_loss=0.0615]\n",
      "Epoch 0:  11%|█▏        | 487/4297 [00:25<03:22, 18.80it/s, v_num=0, train_loss=0.248] \n",
      "Epoch 0:  11%|█▏        | 493/4297 [00:26<03:20, 18.96it/s, v_num=0, train_loss=0.0915]\n",
      "Epoch 0:  11%|█▏        | 494/4297 [00:26<03:20, 18.98it/s, v_num=0, train_loss=0.0981]\n",
      "Epoch 0:  12%|█▏        | 501/4297 [00:26<03:18, 19.16it/s, v_num=0, train_loss=0.187] \n",
      "Epoch 0:  12%|█▏        | 502/4297 [00:26<03:17, 19.19it/s, v_num=0, train_loss=0.0966]\n",
      "Epoch 0:  12%|█▏        | 508/4297 [00:26<03:15, 19.34it/s, v_num=0, train_loss=0.076] \n",
      "Epoch 0:  12%|█▏        | 509/4297 [00:26<03:15, 19.37it/s, v_num=0, train_loss=0.0885]\n",
      "Epoch 0:  12%|█▏        | 515/4297 [00:26<03:13, 19.51it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  12%|█▏        | 522/4297 [00:26<03:11, 19.69it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  12%|█▏        | 527/4297 [00:26<03:10, 19.80it/s, v_num=0, train_loss=0.161]\n",
      "Epoch 0:  12%|█▏        | 528/4297 [00:26<03:10, 19.82it/s, v_num=0, train_loss=0.096]\n",
      "Epoch 0:  12%|█▏        | 534/4297 [00:26<03:08, 19.96it/s, v_num=0, train_loss=0.0705]\n",
      "Epoch 0:  13%|█▎        | 540/4297 [00:26<03:06, 20.10it/s, v_num=0, train_loss=0.0473]\n",
      "Epoch 0:  13%|█▎        | 547/4297 [00:26<03:04, 20.27it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  13%|█▎        | 553/4297 [00:27<03:03, 20.41it/s, v_num=0, train_loss=0.0936]\n",
      "Epoch 0:  13%|█▎        | 554/4297 [00:27<03:03, 20.43it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  13%|█▎        | 561/4297 [00:27<03:01, 20.60it/s, v_num=0, train_loss=0.180] \n",
      "Epoch 0:  13%|█▎        | 562/4297 [00:27<03:01, 20.63it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  13%|█▎        | 568/4297 [00:27<02:59, 20.76it/s, v_num=0, train_loss=0.218] \n",
      "Epoch 0:  13%|█▎        | 568/4297 [00:27<02:59, 20.76it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  13%|█▎        | 575/4297 [00:27<02:57, 20.92it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  14%|█▎        | 582/4297 [00:27<02:56, 21.09it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  14%|█▎        | 583/4297 [00:27<02:55, 21.12it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:  14%|█▎        | 588/4297 [00:27<02:54, 21.22it/s, v_num=0, train_loss=0.0852]\n",
      "Epoch 0:  14%|█▍        | 595/4297 [00:27<02:53, 21.38it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:  14%|█▍        | 596/4297 [00:27<02:52, 21.40it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  14%|█▍        | 602/4297 [00:27<02:51, 21.54it/s, v_num=0, train_loss=0.237] \n",
      "Epoch 0:  14%|█▍        | 607/4297 [00:28<02:50, 21.63it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  14%|█▍        | 608/4297 [00:28<02:50, 21.65it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  14%|█▍        | 614/4297 [00:28<02:49, 21.77it/s, v_num=0, train_loss=0.238] \n",
      "Epoch 0:  14%|█▍        | 620/4297 [00:28<02:47, 21.90it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  14%|█▍        | 621/4297 [00:28<02:47, 21.92it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  15%|█▍        | 629/4297 [00:28<02:45, 22.11it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  15%|█▍        | 636/4297 [00:28<02:44, 22.27it/s, v_num=0, train_loss=0.0504]\n",
      "Epoch 0:  15%|█▍        | 637/4297 [00:28<02:44, 22.30it/s, v_num=0, train_loss=0.0535]\n",
      "Epoch 0:  15%|█▍        | 638/4297 [00:28<02:43, 22.32it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  15%|█▌        | 646/4297 [00:28<02:42, 22.51it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  15%|█▌        | 653/4297 [00:28<02:40, 22.66it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  15%|█▌        | 660/4297 [00:28<02:39, 22.82it/s, v_num=0, train_loss=0.180] \n",
      "Epoch 0:  15%|█▌        | 661/4297 [00:28<02:39, 22.84it/s, v_num=0, train_loss=0.222]\n",
      "Epoch 0:  16%|█▌        | 668/4297 [00:29<02:37, 22.98it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  16%|█▌        | 676/4297 [00:29<02:36, 23.16it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  16%|█▌        | 682/4297 [00:29<02:35, 23.29it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  16%|█▌        | 683/4297 [00:29<02:35, 23.31it/s, v_num=0, train_loss=0.193]\n",
      "Epoch 0:  16%|█▌        | 690/4297 [00:29<02:33, 23.45it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  16%|█▌        | 698/4297 [00:29<02:32, 23.63it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  16%|█▋        | 705/4297 [00:29<02:31, 23.77it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:  17%|█▋        | 712/4297 [00:29<02:29, 23.91it/s, v_num=0, train_loss=0.207] \n",
      "Epoch 0:  17%|█▋        | 712/4297 [00:29<02:29, 23.91it/s, v_num=0, train_loss=0.133]\n",
      "Epoch 0:  17%|█▋        | 713/4297 [00:29<02:29, 23.93it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  17%|█▋        | 720/4297 [00:29<02:28, 24.07it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  17%|█▋        | 726/4297 [00:30<02:27, 24.19it/s, v_num=0, train_loss=0.0516]\n",
      "Epoch 0:  17%|█▋        | 727/4297 [00:30<02:27, 24.21it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  17%|█▋        | 733/4297 [00:30<02:26, 24.32it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  17%|█▋        | 734/4297 [00:30<02:26, 24.34it/s, v_num=0, train_loss=0.245]\n",
      "Epoch 0:  17%|█▋        | 739/4297 [00:30<02:25, 24.42it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  17%|█▋        | 745/4297 [00:30<02:24, 24.52it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  17%|█▋        | 746/4297 [00:30<02:24, 24.53it/s, v_num=0, train_loss=0.172]\n",
      "Epoch 0:  18%|█▊        | 752/4297 [00:30<02:23, 24.64it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  18%|█▊        | 757/4297 [00:30<02:23, 24.72it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  18%|█▊        | 758/4297 [00:30<02:23, 24.73it/s, v_num=0, train_loss=0.132]\n",
      "Epoch 0:  18%|█▊        | 763/4297 [00:30<02:22, 24.82it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  18%|█▊        | 764/4297 [00:30<02:22, 24.83it/s, v_num=0, train_loss=0.0933]\n",
      "Epoch 0:  18%|█▊        | 769/4297 [00:30<02:21, 24.91it/s, v_num=0, train_loss=0.0841]\n",
      "Epoch 0:  18%|█▊        | 770/4297 [00:32<02:27, 23.91it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  18%|█▊        | 772/4297 [00:32<02:27, 23.91it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  18%|█▊        | 774/4297 [00:32<02:27, 23.83it/s, v_num=0, train_loss=0.172]\n",
      "Epoch 0:  18%|█▊        | 782/4297 [00:32<02:27, 23.86it/s, v_num=0, train_loss=0.276]\n",
      "Epoch 0:  18%|█▊        | 790/4297 [00:32<02:25, 24.02it/s, v_num=0, train_loss=0.0895]\n",
      "Epoch 0:  18%|█▊        | 791/4297 [00:32<02:25, 24.04it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  19%|█▊        | 799/4297 [00:33<02:24, 24.21it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  19%|█▊        | 800/4297 [00:33<02:24, 24.23it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  19%|█▉        | 809/4297 [00:33<02:22, 24.41it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  19%|█▉        | 817/4297 [00:33<02:21, 24.57it/s, v_num=0, train_loss=0.0366]\n",
      "Epoch 0:  19%|█▉        | 818/4297 [00:33<02:21, 24.59it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  19%|█▉        | 826/4297 [00:33<02:20, 24.75it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  19%|█▉        | 827/4297 [00:33<02:20, 24.77it/s, v_num=0, train_loss=0.177]\n",
      "Epoch 0:  19%|█▉        | 833/4297 [00:33<02:19, 24.87it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  19%|█▉        | 834/4297 [00:33<02:19, 24.88it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  20%|█▉        | 839/4297 [00:33<02:18, 24.95it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  20%|█▉        | 846/4297 [00:33<02:17, 25.07it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  20%|█▉        | 852/4297 [00:33<02:16, 25.17it/s, v_num=0, train_loss=0.234]\n",
      "Epoch 0:  20%|█▉        | 853/4297 [00:33<02:16, 25.19it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  20%|█▉        | 854/4297 [00:33<02:16, 25.21it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  20%|██        | 862/4297 [00:33<02:15, 25.36it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  20%|██        | 863/4297 [00:34<02:15, 25.38it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  20%|██        | 869/4297 [00:34<02:14, 25.48it/s, v_num=0, train_loss=0.079]\n",
      "Epoch 0:  20%|██        | 870/4297 [00:34<02:14, 25.49it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  20%|██        | 876/4297 [00:34<02:13, 25.59it/s, v_num=0, train_loss=0.220] \n",
      "Epoch 0:  20%|██        | 878/4297 [00:35<02:18, 24.61it/s, v_num=0, train_loss=0.177]\n",
      "Epoch 0:  20%|██        | 879/4297 [00:35<02:18, 24.63it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  21%|██        | 887/4297 [00:35<02:17, 24.77it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  21%|██        | 895/4297 [00:35<02:16, 24.92it/s, v_num=0, train_loss=0.145] \n",
      "Epoch 0:  21%|██        | 896/4297 [00:35<02:16, 24.94it/s, v_num=0, train_loss=0.178]\n",
      "Epoch 0:  21%|██        | 905/4297 [00:36<02:15, 25.10it/s, v_num=0, train_loss=0.0929]\n",
      "Epoch 0:  21%|██        | 913/4297 [00:36<02:14, 25.25it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:  21%|██▏       | 921/4297 [00:36<02:12, 25.39it/s, v_num=0, train_loss=0.0853]\n",
      "Epoch 0:  21%|██▏       | 922/4297 [00:36<02:12, 25.40it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  22%|██▏       | 928/4297 [00:36<02:12, 25.48it/s, v_num=0, train_loss=0.0642]\n",
      "Epoch 0:  22%|██▏       | 934/4297 [00:36<02:11, 25.57it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  22%|██▏       | 940/4297 [00:36<02:10, 25.66it/s, v_num=0, train_loss=0.0661]\n",
      "Epoch 0:  22%|██▏       | 941/4297 [00:36<02:10, 25.68it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  22%|██▏       | 948/4297 [00:36<02:09, 25.78it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  22%|██▏       | 954/4297 [00:36<02:09, 25.87it/s, v_num=0, train_loss=0.254] \n",
      "Epoch 0:  22%|██▏       | 955/4297 [00:36<02:09, 25.89it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  22%|██▏       | 961/4297 [00:36<02:08, 25.98it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  22%|██▏       | 962/4297 [00:37<02:08, 25.99it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  23%|██▎       | 968/4297 [00:37<02:07, 26.08it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  23%|██▎       | 974/4297 [00:37<02:07, 26.16it/s, v_num=0, train_loss=0.189] \n",
      "Epoch 0:  23%|██▎       | 981/4297 [00:37<02:06, 26.27it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  23%|██▎       | 982/4297 [00:37<02:06, 26.28it/s, v_num=0, train_loss=0.0836]\n",
      "Epoch 0:  23%|██▎       | 988/4297 [00:37<02:05, 26.37it/s, v_num=0, train_loss=0.152] \n",
      "Epoch 0:  23%|██▎       | 989/4297 [00:37<02:05, 26.38it/s, v_num=0, train_loss=0.149]\n",
      "Epoch 0:  23%|██▎       | 993/4297 [00:37<02:05, 26.42it/s, v_num=0, train_loss=0.0482]\n",
      "Epoch 0:  23%|██▎       | 994/4297 [00:37<02:04, 26.43it/s, v_num=0, train_loss=0.0692]\n",
      "Epoch 0:  23%|██▎       | 1000/4297 [00:37<02:04, 26.51it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  23%|██▎       | 1007/4297 [00:37<02:03, 26.61it/s, v_num=0, train_loss=0.0755]\n",
      "Epoch 0:  24%|██▎       | 1014/4297 [00:37<02:02, 26.72it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  24%|██▎       | 1015/4297 [00:37<02:02, 26.74it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  24%|██▎       | 1016/4297 [00:37<02:02, 26.75it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  24%|██▍       | 1023/4297 [00:38<02:01, 26.86it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  24%|██▍       | 1024/4297 [00:38<02:01, 26.87it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:  24%|██▍       | 1031/4297 [00:38<02:01, 26.98it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  24%|██▍       | 1037/4297 [00:38<02:00, 27.06it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  24%|██▍       | 1038/4297 [00:38<02:00, 27.07it/s, v_num=0, train_loss=0.138]\n",
      "Epoch 0:  24%|██▍       | 1045/4297 [00:38<01:59, 27.17it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  24%|██▍       | 1051/4297 [00:38<01:59, 27.25it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  24%|██▍       | 1052/4297 [00:38<01:59, 27.26it/s, v_num=0, train_loss=0.0999]\n",
      "Epoch 0:  25%|██▍       | 1057/4297 [00:38<01:58, 27.31it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  25%|██▍       | 1058/4297 [00:38<01:58, 27.33it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  25%|██▍       | 1065/4297 [00:38<01:57, 27.43it/s, v_num=0, train_loss=0.0402]\n",
      "Epoch 0:  25%|██▍       | 1066/4297 [00:38<01:57, 27.45it/s, v_num=0, train_loss=0.248] \n",
      "Epoch 0:  25%|██▍       | 1072/4297 [00:38<01:57, 27.53it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  25%|██▍       | 1073/4297 [00:38<01:57, 27.54it/s, v_num=0, train_loss=0.0979]\n",
      "Epoch 0:  25%|██▌       | 1079/4297 [00:39<01:56, 27.62it/s, v_num=0, train_loss=0.0884]\n",
      "Epoch 0:  25%|██▌       | 1085/4297 [00:39<01:56, 27.69it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  25%|██▌       | 1086/4297 [00:39<01:55, 27.70it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  25%|██▌       | 1092/4297 [00:39<01:55, 27.78it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  25%|██▌       | 1093/4297 [00:39<01:55, 27.79it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:  26%|██▌       | 1098/4297 [00:39<01:54, 27.85it/s, v_num=0, train_loss=0.0906]\n",
      "Epoch 0:  26%|██▌       | 1099/4297 [00:39<01:54, 27.86it/s, v_num=0, train_loss=0.0493]\n",
      "Epoch 0:  26%|██▌       | 1105/4297 [00:39<01:54, 27.93it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  26%|██▌       | 1106/4297 [00:39<01:54, 27.95it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  26%|██▌       | 1107/4297 [00:39<01:54, 27.96it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  26%|██▌       | 1113/4297 [00:39<01:53, 28.03it/s, v_num=0, train_loss=0.0464]\n",
      "Epoch 0:  26%|██▌       | 1119/4297 [00:39<01:53, 28.11it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  26%|██▌       | 1124/4297 [00:39<01:52, 28.16it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:  26%|██▋       | 1130/4297 [00:40<01:52, 28.22it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  26%|██▋       | 1136/4297 [00:40<01:51, 28.29it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  27%|██▋       | 1142/4297 [00:40<01:51, 28.36it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  27%|██▋       | 1143/4297 [00:40<01:51, 28.37it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  27%|██▋       | 1143/4297 [00:40<01:51, 28.37it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  27%|██▋       | 1148/4297 [00:40<01:50, 28.41it/s, v_num=0, train_loss=0.287] \n",
      "Epoch 0:  27%|██▋       | 1153/4297 [00:40<01:50, 28.47it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  27%|██▋       | 1155/4297 [00:41<01:53, 27.62it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  27%|██▋       | 1159/4297 [00:42<01:54, 27.41it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  27%|██▋       | 1167/4297 [00:42<01:53, 27.53it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  27%|██▋       | 1168/4297 [00:42<01:53, 27.55it/s, v_num=0, train_loss=0.0635]\n",
      "Epoch 0:  27%|██▋       | 1169/4297 [00:42<01:53, 27.56it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  27%|██▋       | 1175/4297 [00:42<01:52, 27.63it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  27%|██▋       | 1176/4297 [00:42<01:52, 27.64it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  28%|██▊       | 1185/4297 [00:42<01:52, 27.78it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  28%|██▊       | 1194/4297 [00:42<01:51, 27.92it/s, v_num=0, train_loss=0.099] \n",
      "Epoch 0:  28%|██▊       | 1195/4297 [00:42<01:51, 27.93it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  28%|██▊       | 1203/4297 [00:42<01:50, 28.05it/s, v_num=0, train_loss=0.195] \n",
      "Epoch 0:  28%|██▊       | 1204/4297 [00:42<01:50, 28.07it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  28%|██▊       | 1205/4297 [00:42<01:50, 28.08it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  28%|██▊       | 1211/4297 [00:43<01:49, 28.15it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  28%|██▊       | 1212/4297 [00:43<01:49, 28.16it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:  28%|██▊       | 1218/4297 [00:43<01:49, 28.23it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  28%|██▊       | 1219/4297 [00:43<01:48, 28.24it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  29%|██▊       | 1226/4297 [00:43<01:48, 28.33it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  29%|██▊       | 1227/4297 [00:43<01:48, 28.35it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  29%|██▊       | 1234/4297 [00:43<01:47, 28.44it/s, v_num=0, train_loss=0.0682]\n",
      "Epoch 0:  29%|██▊       | 1235/4297 [00:43<01:47, 28.45it/s, v_num=0, train_loss=0.0682]\n",
      "Epoch 0:  29%|██▊       | 1235/4297 [00:43<01:47, 28.45it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  29%|██▉       | 1241/4297 [00:43<01:47, 28.51it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  29%|██▉       | 1248/4297 [00:43<01:46, 28.60it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  29%|██▉       | 1249/4297 [00:43<01:46, 28.61it/s, v_num=0, train_loss=0.0752]\n",
      "Epoch 0:  29%|██▉       | 1256/4297 [00:43<01:45, 28.70it/s, v_num=0, train_loss=0.078] \n",
      "Epoch 0:  29%|██▉       | 1257/4297 [00:43<01:45, 28.72it/s, v_num=0, train_loss=0.0923]\n",
      "Epoch 0:  29%|██▉       | 1260/4297 [00:43<01:45, 28.76it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  29%|██▉       | 1265/4297 [00:45<01:48, 27.92it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  30%|██▉       | 1273/4297 [00:45<01:47, 28.03it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  30%|██▉       | 1273/4297 [00:45<01:47, 28.03it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  30%|██▉       | 1274/4297 [00:45<01:47, 28.04it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  30%|██▉       | 1282/4297 [00:45<01:47, 28.15it/s, v_num=0, train_loss=0.0865]\n",
      "Epoch 0:  30%|██▉       | 1283/4297 [00:45<01:47, 28.16it/s, v_num=0, train_loss=0.084] \n",
      "Epoch 0:  30%|███       | 1291/4297 [00:45<01:46, 28.27it/s, v_num=0, train_loss=0.0931]\n",
      "Epoch 0:  30%|███       | 1292/4297 [00:45<01:46, 28.28it/s, v_num=0, train_loss=0.0646]\n",
      "Epoch 0:  30%|███       | 1300/4297 [00:45<01:45, 28.39it/s, v_num=0, train_loss=0.0834]\n",
      "Epoch 0:  30%|███       | 1308/4297 [00:45<01:44, 28.49it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  30%|███       | 1309/4297 [00:45<01:44, 28.50it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  31%|███       | 1315/4297 [00:46<01:44, 28.56it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  31%|███       | 1322/4297 [00:46<01:43, 28.64it/s, v_num=0, train_loss=0.0903]\n",
      "Epoch 0:  31%|███       | 1328/4297 [00:46<01:43, 28.70it/s, v_num=0, train_loss=0.0977]\n",
      "Epoch 0:  31%|███       | 1329/4297 [00:46<01:43, 28.72it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  31%|███       | 1336/4297 [00:46<01:42, 28.79it/s, v_num=0, train_loss=0.0843]\n",
      "Epoch 0:  31%|███▏      | 1343/4297 [00:46<01:42, 28.88it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  31%|███▏      | 1344/4297 [00:46<01:42, 28.89it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:  31%|███▏      | 1350/4297 [00:46<01:41, 28.95it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  32%|███▏      | 1357/4297 [00:46<01:41, 29.03it/s, v_num=0, train_loss=0.0972]\n",
      "Epoch 0:  32%|███▏      | 1358/4297 [00:46<01:41, 29.04it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  32%|███▏      | 1364/4297 [00:46<01:40, 29.10it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  32%|███▏      | 1365/4297 [00:46<01:40, 29.11it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  32%|███▏      | 1372/4297 [00:46<01:40, 29.19it/s, v_num=0, train_loss=0.0724]\n",
      "Epoch 0:  32%|███▏      | 1373/4297 [00:47<01:40, 29.20it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  32%|███▏      | 1374/4297 [00:47<01:40, 29.22it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  32%|███▏      | 1374/4297 [00:47<01:40, 29.22it/s, v_num=0, train_loss=0.0613]\n",
      "Epoch 0:  32%|███▏      | 1379/4297 [00:47<01:39, 29.25it/s, v_num=0, train_loss=0.0238]\n",
      "Epoch 0:  32%|███▏      | 1386/4297 [00:47<01:39, 29.32it/s, v_num=0, train_loss=0.247] \n",
      "Epoch 0:  32%|███▏      | 1387/4297 [00:47<01:39, 29.34it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  32%|███▏      | 1393/4297 [00:47<01:38, 29.39it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  33%|███▎      | 1398/4297 [00:47<01:38, 29.44it/s, v_num=0, train_loss=0.0761]\n",
      "Epoch 0:  33%|███▎      | 1399/4297 [00:47<01:38, 29.44it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:  33%|███▎      | 1404/4297 [00:47<01:38, 29.48it/s, v_num=0, train_loss=0.0872]\n",
      "Epoch 0:  33%|███▎      | 1405/4297 [00:47<01:38, 29.49it/s, v_num=0, train_loss=0.0794]\n",
      "Epoch 0:  33%|███▎      | 1413/4297 [00:47<01:37, 29.58it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  33%|███▎      | 1418/4297 [00:47<01:37, 29.62it/s, v_num=0, train_loss=0.0899]\n",
      "Epoch 0:  33%|███▎      | 1419/4297 [00:47<01:37, 29.63it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  33%|███▎      | 1426/4297 [00:47<01:36, 29.71it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  33%|███▎      | 1433/4297 [00:48<01:36, 29.79it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  33%|███▎      | 1434/4297 [00:48<01:36, 29.80it/s, v_num=0, train_loss=0.0926]\n",
      "Epoch 0:  34%|███▎      | 1441/4297 [00:48<01:35, 29.87it/s, v_num=0, train_loss=0.063] \n",
      "Epoch 0:  34%|███▎      | 1442/4297 [00:48<01:35, 29.88it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  34%|███▎      | 1449/4297 [00:48<01:35, 29.96it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  34%|███▍      | 1457/4297 [00:48<01:34, 30.05it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  34%|███▍      | 1465/4297 [00:48<01:33, 30.14it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  34%|███▍      | 1466/4297 [00:48<01:33, 30.15it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  34%|███▍      | 1466/4297 [00:48<01:33, 30.15it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  34%|███▍      | 1472/4297 [00:48<01:33, 30.21it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  34%|███▍      | 1473/4297 [00:48<01:33, 30.22it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  34%|███▍      | 1480/4297 [00:48<01:33, 30.29it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  34%|███▍      | 1481/4297 [00:48<01:32, 30.30it/s, v_num=0, train_loss=0.0869]\n",
      "Epoch 0:  35%|███▍      | 1487/4297 [00:48<01:32, 30.36it/s, v_num=0, train_loss=0.0683]\n",
      "Epoch 0:  35%|███▍      | 1488/4297 [00:48<01:32, 30.37it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  35%|███▍      | 1494/4297 [00:49<01:32, 30.43it/s, v_num=0, train_loss=0.0874]\n",
      "Epoch 0:  35%|███▍      | 1495/4297 [00:49<01:32, 30.44it/s, v_num=0, train_loss=0.220] \n",
      "Epoch 0:  35%|███▍      | 1496/4297 [00:49<01:31, 30.45it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  35%|███▍      | 1501/4297 [00:49<01:31, 30.49it/s, v_num=0, train_loss=0.262] \n",
      "Epoch 0:  35%|███▌      | 1507/4297 [00:49<01:31, 30.53it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  35%|███▌      | 1513/4297 [00:49<01:31, 30.58it/s, v_num=0, train_loss=0.182] \n",
      "Epoch 0:  35%|███▌      | 1514/4297 [00:49<01:30, 30.59it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  35%|███▌      | 1520/4297 [00:49<01:30, 30.64it/s, v_num=0, train_loss=0.0834]\n",
      "Epoch 0:  35%|███▌      | 1524/4297 [00:49<01:30, 30.66it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  36%|███▌      | 1529/4297 [00:49<01:30, 30.69it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  36%|███▌      | 1530/4297 [00:49<01:30, 30.69it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  36%|███▌      | 1534/4297 [00:49<01:29, 30.72it/s, v_num=0, train_loss=0.0567]\n",
      "Epoch 0:  36%|███▌      | 1535/4297 [00:49<01:29, 30.72it/s, v_num=0, train_loss=0.0669]\n",
      "Epoch 0:  36%|███▌      | 1537/4297 [00:50<01:29, 30.73it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  36%|███▌      | 1540/4297 [00:51<01:32, 29.95it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:  36%|███▌      | 1544/4297 [00:51<01:31, 29.96it/s, v_num=0, train_loss=0.205] \n",
      "Epoch 0:  36%|███▌      | 1545/4297 [00:51<01:31, 29.97it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  36%|███▌      | 1550/4297 [00:51<01:31, 30.00it/s, v_num=0, train_loss=0.188] \n",
      "Epoch 0:  36%|███▋      | 1558/4297 [00:51<01:31, 30.09it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  36%|███▋      | 1559/4297 [00:51<01:30, 30.10it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  36%|███▋      | 1567/4297 [00:51<01:30, 30.19it/s, v_num=0, train_loss=0.294] \n",
      "Epoch 0:  36%|███▋      | 1568/4297 [00:51<01:30, 30.21it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  37%|███▋      | 1577/4297 [00:52<01:29, 30.31it/s, v_num=0, train_loss=0.0682]\n",
      "Epoch 0:  37%|███▋      | 1578/4297 [00:52<01:29, 30.32it/s, v_num=0, train_loss=0.0674]\n",
      "Epoch 0:  37%|███▋      | 1585/4297 [00:52<01:29, 30.40it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  37%|███▋      | 1586/4297 [00:52<01:29, 30.41it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  37%|███▋      | 1587/4297 [00:52<01:29, 30.42it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  37%|███▋      | 1595/4297 [00:52<01:28, 30.51it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  37%|███▋      | 1596/4297 [00:52<01:28, 30.52it/s, v_num=0, train_loss=0.149]\n",
      "Epoch 0:  37%|███▋      | 1602/4297 [00:52<01:28, 30.58it/s, v_num=0, train_loss=0.0978]\n",
      "Epoch 0:  37%|███▋      | 1603/4297 [00:52<01:28, 30.58it/s, v_num=0, train_loss=0.0978]\n",
      "Epoch 0:  37%|███▋      | 1603/4297 [00:52<01:28, 30.58it/s, v_num=0, train_loss=0.077] \n",
      "Epoch 0:  37%|███▋      | 1611/4297 [00:52<01:27, 30.66it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  38%|███▊      | 1617/4297 [00:52<01:27, 30.72it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  38%|███▊      | 1624/4297 [00:52<01:26, 30.77it/s, v_num=0, train_loss=0.149]\n",
      "Epoch 0:  38%|███▊      | 1631/4297 [00:52<01:26, 30.84it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  38%|███▊      | 1637/4297 [00:52<01:26, 30.89it/s, v_num=0, train_loss=0.0437]\n",
      "Epoch 0:  38%|███▊      | 1644/4297 [00:53<01:25, 30.95it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  38%|███▊      | 1646/4297 [00:54<01:27, 30.23it/s, v_num=0, train_loss=0.0997]\n",
      "Epoch 0:  38%|███▊      | 1647/4297 [00:54<01:27, 30.25it/s, v_num=0, train_loss=0.216] \n",
      "Epoch 0:  39%|███▊      | 1656/4297 [00:54<01:27, 30.34it/s, v_num=0, train_loss=0.0871]\n",
      "Epoch 0:  39%|███▊      | 1665/4297 [00:54<01:26, 30.44it/s, v_num=0, train_loss=0.249] \n",
      "Epoch 0:  39%|███▉      | 1674/4297 [00:54<01:25, 30.54it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  39%|███▉      | 1683/4297 [00:54<01:25, 30.64it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  39%|███▉      | 1692/4297 [00:55<01:24, 30.74it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  39%|███▉      | 1693/4297 [00:55<01:24, 30.75it/s, v_num=0, train_loss=0.295]\n",
      "Epoch 0:  40%|███▉      | 1699/4297 [00:55<01:24, 30.80it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  40%|███▉      | 1706/4297 [00:55<01:23, 30.86it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  40%|███▉      | 1714/4297 [00:55<01:23, 30.94it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  40%|███▉      | 1715/4297 [00:55<01:23, 30.95it/s, v_num=0, train_loss=0.225]\n",
      "Epoch 0:  40%|████      | 1720/4297 [00:55<01:23, 30.98it/s, v_num=0, train_loss=0.0956]\n",
      "Epoch 0:  40%|████      | 1721/4297 [00:55<01:23, 30.99it/s, v_num=0, train_loss=0.145] \n",
      "Epoch 0:  40%|████      | 1728/4297 [00:55<01:22, 31.05it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  40%|████      | 1735/4297 [00:55<01:22, 31.12it/s, v_num=0, train_loss=0.210]\n",
      "Epoch 0:  40%|████      | 1736/4297 [00:55<01:22, 31.13it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  41%|████      | 1744/4297 [00:55<01:21, 31.20it/s, v_num=0, train_loss=0.195]\n",
      "Epoch 0:  41%|████      | 1751/4297 [00:56<01:21, 31.26it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  41%|████      | 1757/4297 [00:56<01:21, 31.31it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  41%|████      | 1758/4297 [00:56<01:21, 31.32it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  41%|████      | 1759/4297 [00:56<01:21, 31.33it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  41%|████      | 1765/4297 [00:56<01:20, 31.38it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  41%|████      | 1766/4297 [00:56<01:20, 31.39it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  41%|████      | 1771/4297 [00:56<01:20, 31.42it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  41%|████      | 1772/4297 [00:56<01:20, 31.42it/s, v_num=0, train_loss=0.0813]\n",
      "Epoch 0:  41%|████▏     | 1777/4297 [00:56<01:20, 31.46it/s, v_num=0, train_loss=0.0994]\n",
      "Epoch 0:  41%|████▏     | 1778/4297 [00:56<01:20, 31.46it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  42%|████▏     | 1784/4297 [00:56<01:19, 31.51it/s, v_num=0, train_loss=0.187] \n",
      "Epoch 0:  42%|████▏     | 1785/4297 [00:56<01:19, 31.51it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  42%|████▏     | 1785/4297 [00:56<01:19, 31.51it/s, v_num=0, train_loss=0.251]\n",
      "Epoch 0:  42%|████▏     | 1792/4297 [00:56<01:19, 31.57it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  42%|████▏     | 1793/4297 [00:56<01:19, 31.58it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:  42%|████▏     | 1800/4297 [00:56<01:18, 31.64it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  42%|████▏     | 1806/4297 [00:56<01:18, 31.68it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  42%|████▏     | 1807/4297 [00:57<01:18, 31.69it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  42%|████▏     | 1814/4297 [00:57<01:18, 31.75it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  42%|████▏     | 1815/4297 [00:57<01:18, 31.76it/s, v_num=0, train_loss=0.175]\n",
      "Epoch 0:  42%|████▏     | 1821/4297 [00:57<01:17, 31.81it/s, v_num=0, train_loss=0.246] \n",
      "Epoch 0:  42%|████▏     | 1822/4297 [00:57<01:17, 31.81it/s, v_num=0, train_loss=0.195]\n",
      "Epoch 0:  43%|████▎     | 1828/4297 [00:57<01:17, 31.86it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  43%|████▎     | 1829/4297 [00:57<01:17, 31.87it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  43%|████▎     | 1834/4297 [00:57<01:17, 31.90it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  43%|████▎     | 1835/4297 [00:57<01:17, 31.90it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  43%|████▎     | 1841/4297 [00:57<01:16, 31.94it/s, v_num=0, train_loss=0.208]\n",
      "Epoch 0:  43%|████▎     | 1847/4297 [00:57<01:16, 31.98it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  43%|████▎     | 1853/4297 [00:57<01:16, 32.03it/s, v_num=0, train_loss=0.269] \n",
      "Epoch 0:  43%|████▎     | 1854/4297 [00:57<01:16, 32.03it/s, v_num=0, train_loss=0.208]\n",
      "Epoch 0:  43%|████▎     | 1861/4297 [00:57<01:15, 32.10it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  43%|████▎     | 1862/4297 [00:57<01:15, 32.10it/s, v_num=0, train_loss=0.0877]\n",
      "Epoch 0:  44%|████▎     | 1870/4297 [00:58<01:15, 32.18it/s, v_num=0, train_loss=0.0717]\n",
      "Epoch 0:  44%|████▎     | 1876/4297 [00:58<01:15, 32.22it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  44%|████▎     | 1877/4297 [00:58<01:15, 32.23it/s, v_num=0, train_loss=0.108]\n",
      "Epoch 0:  44%|████▍     | 1883/4297 [00:58<01:14, 32.27it/s, v_num=0, train_loss=0.0912]\n",
      "Epoch 0:  44%|████▍     | 1888/4297 [00:58<01:14, 32.29it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  44%|████▍     | 1889/4297 [00:58<01:14, 32.30it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  44%|████▍     | 1894/4297 [00:58<01:14, 32.33it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  44%|████▍     | 1895/4297 [00:58<01:14, 32.33it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  44%|████▍     | 1901/4297 [00:58<01:14, 32.37it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  44%|████▍     | 1906/4297 [00:58<01:13, 32.39it/s, v_num=0, train_loss=0.178]\n",
      "Epoch 0:  44%|████▍     | 1907/4297 [00:58<01:13, 32.40it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  44%|████▍     | 1912/4297 [00:58<01:13, 32.42it/s, v_num=0, train_loss=0.0545]\n",
      "Epoch 0:  45%|████▍     | 1917/4297 [00:59<01:13, 32.45it/s, v_num=0, train_loss=0.232] \n",
      "Epoch 0:  45%|████▍     | 1921/4297 [00:59<01:13, 32.47it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  45%|████▍     | 1922/4297 [01:00<01:14, 31.88it/s, v_num=0, train_loss=0.224]\n",
      "Epoch 0:  45%|████▍     | 1923/4297 [01:00<01:14, 31.85it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  45%|████▍     | 1928/4297 [01:00<01:14, 31.74it/s, v_num=0, train_loss=0.227] \n",
      "Epoch 0:  45%|████▍     | 1929/4297 [01:00<01:14, 31.75it/s, v_num=0, train_loss=0.064]\n",
      "Epoch 0:  45%|████▍     | 1931/4297 [01:00<01:14, 31.70it/s, v_num=0, train_loss=0.250] \n",
      "Epoch 0:  45%|████▌     | 1936/4297 [01:01<01:14, 31.69it/s, v_num=0, train_loss=0.188] \n",
      "Epoch 0:  45%|████▌     | 1937/4297 [01:01<01:14, 31.70it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  45%|████▌     | 1944/4297 [01:01<01:14, 31.76it/s, v_num=0, train_loss=0.0605]\n",
      "Epoch 0:  45%|████▌     | 1945/4297 [01:01<01:14, 31.77it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  45%|████▌     | 1946/4297 [01:01<01:13, 31.78it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  45%|████▌     | 1955/4297 [01:01<01:13, 31.86it/s, v_num=0, train_loss=0.193]\n",
      "Epoch 0:  46%|████▌     | 1962/4297 [01:01<01:13, 31.92it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  46%|████▌     | 1963/4297 [01:01<01:13, 31.93it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  46%|████▌     | 1963/4297 [01:01<01:13, 31.93it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:  46%|████▌     | 1971/4297 [01:01<01:12, 32.00it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  46%|████▌     | 1972/4297 [01:01<01:12, 32.01it/s, v_num=0, train_loss=0.0915]\n",
      "Epoch 0:  46%|████▌     | 1973/4297 [01:01<01:12, 32.02it/s, v_num=0, train_loss=0.0837]\n",
      "Epoch 0:  46%|████▌     | 1981/4297 [01:01<01:12, 32.09it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  46%|████▌     | 1982/4297 [01:01<01:12, 32.10it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  46%|████▋     | 1988/4297 [01:01<01:11, 32.14it/s, v_num=0, train_loss=0.269] \n",
      "Epoch 0:  46%|████▋     | 1989/4297 [01:01<01:11, 32.15it/s, v_num=0, train_loss=0.210]\n",
      "Epoch 0:  46%|████▋     | 1990/4297 [01:01<01:11, 32.16it/s, v_num=0, train_loss=0.0786]\n",
      "Epoch 0:  46%|████▋     | 1996/4297 [01:01<01:11, 32.20it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  46%|████▋     | 1997/4297 [01:01<01:11, 32.21it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  46%|████▋     | 1998/4297 [01:02<01:11, 32.22it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  46%|████▋     | 1998/4297 [01:02<01:11, 32.22it/s, v_num=0, train_loss=0.223]\n",
      "Epoch 0:  47%|████▋     | 2006/4297 [01:02<01:10, 32.29it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  47%|████▋     | 2014/4297 [01:02<01:10, 32.36it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  47%|████▋     | 2015/4297 [01:02<01:10, 32.37it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  47%|████▋     | 2023/4297 [01:02<01:10, 32.44it/s, v_num=0, train_loss=0.0986]\n",
      "Epoch 0:  47%|████▋     | 2028/4297 [01:02<01:09, 32.47it/s, v_num=0, train_loss=0.0641]\n",
      "Epoch 0:  47%|████▋     | 2032/4297 [01:03<01:11, 31.85it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  47%|████▋     | 2033/4297 [01:03<01:11, 31.85it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  48%|████▊     | 2042/4297 [01:03<01:10, 31.94it/s, v_num=0, train_loss=0.245] \n",
      "Epoch 0:  48%|████▊     | 2050/4297 [01:04<01:10, 32.01it/s, v_num=0, train_loss=0.0896]\n",
      "Epoch 0:  48%|████▊     | 2051/4297 [01:04<01:10, 32.01it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  48%|████▊     | 2060/4297 [01:04<01:09, 32.10it/s, v_num=0, train_loss=0.270]\n",
      "Epoch 0:  48%|████▊     | 2068/4297 [01:04<01:09, 32.16it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  48%|████▊     | 2069/4297 [01:04<01:09, 32.17it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  48%|████▊     | 2077/4297 [01:04<01:08, 32.24it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  48%|████▊     | 2084/4297 [01:04<01:08, 32.29it/s, v_num=0, train_loss=0.239]\n",
      "Epoch 0:  49%|████▊     | 2085/4297 [01:04<01:08, 32.30it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  49%|████▊     | 2092/4297 [01:04<01:08, 32.35it/s, v_num=0, train_loss=0.182] \n",
      "Epoch 0:  49%|████▉     | 2100/4297 [01:04<01:07, 32.41it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  49%|████▉     | 2107/4297 [01:04<01:07, 32.47it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  49%|████▉     | 2114/4297 [01:05<01:07, 32.51it/s, v_num=0, train_loss=0.133]\n",
      "Epoch 0:  49%|████▉     | 2121/4297 [01:05<01:06, 32.56it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  49%|████▉     | 2127/4297 [01:05<01:06, 32.60it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  50%|████▉     | 2128/4297 [01:05<01:06, 32.61it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  50%|████▉     | 2133/4297 [01:05<01:06, 32.63it/s, v_num=0, train_loss=0.252] \n",
      "Epoch 0:  50%|████▉     | 2139/4297 [01:05<01:06, 32.67it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  50%|████▉     | 2140/4297 [01:05<01:06, 32.67it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  50%|████▉     | 2141/4297 [01:05<01:05, 32.68it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  50%|████▉     | 2141/4297 [01:05<01:05, 32.68it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  50%|████▉     | 2148/4297 [01:05<01:05, 32.73it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  50%|█████     | 2155/4297 [01:05<01:05, 32.77it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  50%|█████     | 2161/4297 [01:05<01:05, 32.81it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  50%|█████     | 2168/4297 [01:05<01:04, 32.86it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  50%|█████     | 2169/4297 [01:05<01:04, 32.87it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  51%|█████     | 2177/4297 [01:06<01:04, 32.93it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  51%|█████     | 2183/4297 [01:06<01:04, 32.97it/s, v_num=0, train_loss=0.0791]\n",
      "Epoch 0:  51%|█████     | 2184/4297 [01:06<01:04, 32.97it/s, v_num=0, train_loss=0.0827]\n",
      "Epoch 0:  51%|█████     | 2190/4297 [01:06<01:03, 33.01it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  51%|█████     | 2191/4297 [01:06<01:03, 33.02it/s, v_num=0, train_loss=0.0848]\n",
      "Epoch 0:  51%|█████     | 2198/4297 [01:06<01:03, 33.07it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  51%|█████     | 2199/4297 [01:06<01:03, 33.08it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  51%|█████▏    | 2206/4297 [01:06<01:03, 33.13it/s, v_num=0, train_loss=0.0861]\n",
      "Epoch 0:  51%|█████▏    | 2207/4297 [01:06<01:03, 33.14it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  52%|█████▏    | 2213/4297 [01:06<01:02, 33.17it/s, v_num=0, train_loss=0.0862]\n",
      "Epoch 0:  52%|█████▏    | 2219/4297 [01:06<01:02, 33.21it/s, v_num=0, train_loss=0.0576]\n",
      "Epoch 0:  52%|█████▏    | 2220/4297 [01:06<01:02, 33.21it/s, v_num=0, train_loss=0.0553]\n",
      "Epoch 0:  52%|█████▏    | 2227/4297 [01:06<01:02, 33.26it/s, v_num=0, train_loss=0.0725]\n",
      "Epoch 0:  52%|█████▏    | 2228/4297 [01:06<01:02, 33.27it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  52%|█████▏    | 2229/4297 [01:06<01:02, 33.28it/s, v_num=0, train_loss=0.238]\n",
      "Epoch 0:  52%|█████▏    | 2235/4297 [01:07<01:01, 33.31it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  52%|█████▏    | 2236/4297 [01:07<01:01, 33.32it/s, v_num=0, train_loss=0.0724]\n",
      "Epoch 0:  52%|█████▏    | 2243/4297 [01:07<01:01, 33.37it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  52%|█████▏    | 2248/4297 [01:07<01:01, 33.39it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  52%|█████▏    | 2249/4297 [01:07<01:01, 33.39it/s, v_num=0, train_loss=0.0433]\n",
      "Epoch 0:  52%|█████▏    | 2255/4297 [01:07<01:01, 33.43it/s, v_num=0, train_loss=0.0908]\n",
      "Epoch 0:  53%|█████▎    | 2262/4297 [01:07<01:00, 33.48it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  53%|█████▎    | 2268/4297 [01:07<01:00, 33.50it/s, v_num=0, train_loss=0.0854]\n",
      "Epoch 0:  53%|█████▎    | 2275/4297 [01:07<01:00, 33.55it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  53%|█████▎    | 2276/4297 [01:07<01:00, 33.56it/s, v_num=0, train_loss=0.241]\n",
      "Epoch 0:  53%|█████▎    | 2281/4297 [01:07<01:00, 33.58it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  53%|█████▎    | 2282/4297 [01:07<00:59, 33.59it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  53%|█████▎    | 2288/4297 [01:08<00:59, 33.63it/s, v_num=0, train_loss=0.230] \n",
      "Epoch 0:  53%|█████▎    | 2289/4297 [01:08<00:59, 33.63it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  53%|█████▎    | 2294/4297 [01:08<00:59, 33.65it/s, v_num=0, train_loss=0.323] \n",
      "Epoch 0:  53%|█████▎    | 2295/4297 [01:08<00:59, 33.66it/s, v_num=0, train_loss=0.235]\n",
      "Epoch 0:  54%|█████▎    | 2301/4297 [01:08<00:59, 33.69it/s, v_num=0, train_loss=0.194] \n",
      "Epoch 0:  54%|█████▎    | 2305/4297 [01:08<00:59, 33.70it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  54%|█████▎    | 2306/4297 [01:09<01:00, 33.12it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  54%|█████▍    | 2311/4297 [01:10<01:00, 32.92it/s, v_num=0, train_loss=0.241] \n",
      "Epoch 0:  54%|█████▍    | 2319/4297 [01:10<00:59, 32.98it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  54%|█████▍    | 2328/4297 [01:10<00:59, 33.06it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  54%|█████▍    | 2329/4297 [01:10<00:59, 33.06it/s, v_num=0, train_loss=0.236]\n",
      "Epoch 0:  54%|█████▍    | 2336/4297 [01:10<00:59, 33.12it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  54%|█████▍    | 2337/4297 [01:10<00:59, 33.12it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  54%|█████▍    | 2338/4297 [01:10<00:59, 33.13it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  55%|█████▍    | 2346/4297 [01:10<00:58, 33.19it/s, v_num=0, train_loss=0.0555]\n",
      "Epoch 0:  55%|█████▍    | 2347/4297 [01:10<00:58, 33.20it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:  55%|█████▍    | 2348/4297 [01:10<00:58, 33.21it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  55%|█████▍    | 2354/4297 [01:10<00:58, 33.26it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:  55%|█████▍    | 2355/4297 [01:10<00:58, 33.26it/s, v_num=0, train_loss=0.091]\n",
      "Epoch 0:  55%|█████▍    | 2361/4297 [01:10<00:58, 33.28it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  55%|█████▌    | 2367/4297 [01:11<00:57, 33.32it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  55%|█████▌    | 2373/4297 [01:11<00:57, 33.35it/s, v_num=0, train_loss=0.0934]\n",
      "Epoch 0:  55%|█████▌    | 2374/4297 [01:11<00:57, 33.36it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  55%|█████▌    | 2375/4297 [01:11<00:57, 33.37it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  55%|█████▌    | 2382/4297 [01:11<00:57, 33.41it/s, v_num=0, train_loss=0.0642]\n",
      "Epoch 0:  56%|█████▌    | 2389/4297 [01:11<00:57, 33.45it/s, v_num=0, train_loss=0.0888]\n",
      "Epoch 0:  56%|█████▌    | 2389/4297 [01:11<00:57, 33.45it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  56%|█████▌    | 2395/4297 [01:11<00:56, 33.49it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:  56%|█████▌    | 2396/4297 [01:11<00:56, 33.49it/s, v_num=0, train_loss=0.0793]\n",
      "Epoch 0:  56%|█████▌    | 2401/4297 [01:11<00:56, 33.51it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  56%|█████▌    | 2402/4297 [01:11<00:56, 33.52it/s, v_num=0, train_loss=0.226]\n",
      "Epoch 0:  56%|█████▌    | 2409/4297 [01:11<00:56, 33.57it/s, v_num=0, train_loss=0.193]\n",
      "Epoch 0:  56%|█████▌    | 2412/4297 [01:11<00:56, 33.58it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  56%|█████▋    | 2419/4297 [01:13<00:56, 32.95it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  56%|█████▋    | 2420/4297 [01:13<00:56, 32.96it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  56%|█████▋    | 2421/4297 [01:13<00:56, 32.97it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  57%|█████▋    | 2430/4297 [01:13<00:56, 33.04it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  57%|█████▋    | 2439/4297 [01:13<00:56, 33.10it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  57%|█████▋    | 2439/4297 [01:13<00:56, 33.10it/s, v_num=0, train_loss=0.0861]\n",
      "Epoch 0:  57%|█████▋    | 2440/4297 [01:13<00:56, 33.11it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  57%|█████▋    | 2448/4297 [01:13<00:55, 33.17it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:  57%|█████▋    | 2449/4297 [01:13<00:55, 33.18it/s, v_num=0, train_loss=0.0525]\n",
      "Epoch 0:  57%|█████▋    | 2450/4297 [01:13<00:55, 33.19it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  57%|█████▋    | 2459/4297 [01:13<00:55, 33.26it/s, v_num=0, train_loss=0.177] \n",
      "Epoch 0:  57%|█████▋    | 2465/4297 [01:14<00:55, 33.29it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  57%|█████▋    | 2466/4297 [01:14<00:54, 33.30it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  58%|█████▊    | 2472/4297 [01:14<00:54, 33.33it/s, v_num=0, train_loss=0.0523]\n",
      "Epoch 0:  58%|█████▊    | 2478/4297 [01:14<00:54, 33.36it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  58%|█████▊    | 2479/4297 [01:14<00:54, 33.37it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  58%|█████▊    | 2485/4297 [01:14<00:54, 33.40it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  58%|█████▊    | 2486/4297 [01:14<00:54, 33.41it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  58%|█████▊    | 2491/4297 [01:14<00:54, 33.43it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  58%|█████▊    | 2492/4297 [01:14<00:53, 33.43it/s, v_num=0, train_loss=0.0367]\n",
      "Epoch 0:  58%|█████▊    | 2493/4297 [01:14<00:53, 33.44it/s, v_num=0, train_loss=0.195] \n",
      "Epoch 0:  58%|█████▊    | 2500/4297 [01:14<00:53, 33.48it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  58%|█████▊    | 2506/4297 [01:14<00:53, 33.51it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  58%|█████▊    | 2507/4297 [01:14<00:53, 33.52it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  58%|█████▊    | 2512/4297 [01:14<00:53, 33.54it/s, v_num=0, train_loss=0.0707]\n",
      "Epoch 0:  58%|█████▊    | 2513/4297 [01:14<00:53, 33.54it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  59%|█████▊    | 2518/4297 [01:15<00:53, 33.56it/s, v_num=0, train_loss=0.255] \n",
      "Epoch 0:  59%|█████▉    | 2525/4297 [01:15<00:52, 33.60it/s, v_num=0, train_loss=0.057] \n",
      "Epoch 0:  59%|█████▉    | 2533/4297 [01:15<00:52, 33.66it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  59%|█████▉    | 2539/4297 [01:15<00:52, 33.68it/s, v_num=0, train_loss=0.0999]\n",
      "Epoch 0:  59%|█████▉    | 2545/4297 [01:15<00:51, 33.71it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  59%|█████▉    | 2546/4297 [01:15<00:51, 33.72it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  59%|█████▉    | 2552/4297 [01:15<00:51, 33.75it/s, v_num=0, train_loss=0.308] \n",
      "Epoch 0:  59%|█████▉    | 2553/4297 [01:15<00:51, 33.76it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  60%|█████▉    | 2561/4297 [01:15<00:51, 33.81it/s, v_num=0, train_loss=0.0712]\n",
      "Epoch 0:  60%|█████▉    | 2569/4297 [01:15<00:51, 33.86it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  60%|█████▉    | 2570/4297 [01:15<00:50, 33.87it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0:  60%|█████▉    | 2577/4297 [01:15<00:50, 33.91it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  60%|██████    | 2584/4297 [01:16<00:50, 33.95it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  60%|██████    | 2590/4297 [01:16<00:50, 33.98it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  60%|██████    | 2591/4297 [01:16<00:50, 33.99it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:  60%|██████    | 2599/4297 [01:16<00:49, 34.04it/s, v_num=0, train_loss=0.0868]\n",
      "Epoch 0:  61%|██████    | 2606/4297 [01:16<00:49, 34.08it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  61%|██████    | 2607/4297 [01:16<00:49, 34.09it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  61%|██████    | 2614/4297 [01:16<00:49, 34.13it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  61%|██████    | 2615/4297 [01:16<00:49, 34.14it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  61%|██████    | 2620/4297 [01:16<00:49, 34.16it/s, v_num=0, train_loss=0.0877]\n",
      "Epoch 0:  61%|██████    | 2621/4297 [01:16<00:49, 34.16it/s, v_num=0, train_loss=0.0686]\n",
      "Epoch 0:  61%|██████    | 2628/4297 [01:16<00:48, 34.20it/s, v_num=0, train_loss=0.223] \n",
      "Epoch 0:  61%|██████▏   | 2634/4297 [01:16<00:48, 34.23it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  61%|██████▏   | 2635/4297 [01:16<00:48, 34.23it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  61%|██████▏   | 2640/4297 [01:17<00:48, 34.26it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:  61%|██████▏   | 2641/4297 [01:17<00:48, 34.26it/s, v_num=0, train_loss=0.0543]\n",
      "Epoch 0:  62%|██████▏   | 2647/4297 [01:17<00:48, 34.29it/s, v_num=0, train_loss=0.199] \n",
      "Epoch 0:  62%|██████▏   | 2648/4297 [01:17<00:48, 34.29it/s, v_num=0, train_loss=0.290]\n",
      "Epoch 0:  62%|██████▏   | 2654/4297 [01:17<00:47, 34.32it/s, v_num=0, train_loss=0.0794]\n",
      "Epoch 0:  62%|██████▏   | 2655/4297 [01:17<00:47, 34.33it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  62%|██████▏   | 2659/4297 [01:17<00:47, 34.34it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  62%|██████▏   | 2660/4297 [01:17<00:47, 34.34it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  62%|██████▏   | 2666/4297 [01:17<00:47, 34.36it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  62%|██████▏   | 2672/4297 [01:17<00:47, 34.39it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  62%|██████▏   | 2678/4297 [01:17<00:47, 34.41it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  62%|██████▏   | 2684/4297 [01:17<00:46, 34.44it/s, v_num=0, train_loss=0.232] \n",
      "Epoch 0:  63%|██████▎   | 2689/4297 [01:18<00:46, 34.46it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  63%|██████▎   | 2690/4297 [01:19<00:47, 33.91it/s, v_num=0, train_loss=0.223]\n",
      "Epoch 0:  63%|██████▎   | 2691/4297 [01:19<00:47, 33.80it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  63%|██████▎   | 2692/4297 [01:19<00:47, 33.81it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  63%|██████▎   | 2699/4297 [01:19<00:47, 33.86it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  63%|██████▎   | 2700/4297 [01:19<00:47, 33.86it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  63%|██████▎   | 2708/4297 [01:19<00:46, 33.91it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  63%|██████▎   | 2715/4297 [01:19<00:46, 33.95it/s, v_num=0, train_loss=0.044] \n",
      "Epoch 0:  63%|██████▎   | 2716/4297 [01:19<00:46, 33.96it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  63%|██████▎   | 2717/4297 [01:20<00:46, 33.96it/s, v_num=0, train_loss=0.175]\n",
      "Epoch 0:  63%|██████▎   | 2725/4297 [01:20<00:46, 34.02it/s, v_num=0, train_loss=0.098]\n",
      "Epoch 0:  63%|██████▎   | 2726/4297 [01:20<00:46, 34.02it/s, v_num=0, train_loss=0.098]\n",
      "Epoch 0:  63%|██████▎   | 2726/4297 [01:20<00:46, 34.02it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  64%|██████▎   | 2735/4297 [01:20<00:45, 34.08it/s, v_num=0, train_loss=0.201] \n",
      "Epoch 0:  64%|██████▍   | 2743/4297 [01:20<00:45, 34.13it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  64%|██████▍   | 2750/4297 [01:20<00:45, 34.17it/s, v_num=0, train_loss=0.311] \n",
      "Epoch 0:  64%|██████▍   | 2757/4297 [01:20<00:45, 34.21it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  64%|██████▍   | 2764/4297 [01:20<00:44, 34.24it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  64%|██████▍   | 2765/4297 [01:20<00:44, 34.25it/s, v_num=0, train_loss=0.273]\n",
      "Epoch 0:  65%|██████▍   | 2773/4297 [01:20<00:44, 34.30it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  65%|██████▍   | 2779/4297 [01:20<00:44, 34.33it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  65%|██████▍   | 2786/4297 [01:21<00:43, 34.36it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  65%|██████▍   | 2792/4297 [01:21<00:43, 34.39it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  65%|██████▍   | 2793/4297 [01:21<00:43, 34.40it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  65%|██████▌   | 2796/4297 [01:21<00:43, 34.41it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  65%|██████▌   | 2799/4297 [01:22<00:44, 33.83it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  65%|██████▌   | 2800/4297 [01:22<00:44, 33.84it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  65%|██████▌   | 2809/4297 [01:22<00:43, 33.90it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  66%|██████▌   | 2818/4297 [01:22<00:43, 33.96it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  66%|██████▌   | 2819/4297 [01:22<00:43, 33.97it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  66%|██████▌   | 2827/4297 [01:23<00:43, 34.02it/s, v_num=0, train_loss=0.225] \n",
      "Epoch 0:  66%|██████▌   | 2828/4297 [01:23<00:43, 34.03it/s, v_num=0, train_loss=0.264]\n",
      "Epoch 0:  66%|██████▌   | 2829/4297 [01:23<00:43, 34.03it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  66%|██████▌   | 2837/4297 [01:23<00:42, 34.09it/s, v_num=0, train_loss=0.264] \n",
      "Epoch 0:  66%|██████▌   | 2838/4297 [01:23<00:42, 34.09it/s, v_num=0, train_loss=0.0527]\n",
      "Epoch 0:  66%|██████▌   | 2839/4297 [01:23<00:42, 34.10it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  66%|██████▋   | 2847/4297 [01:23<00:42, 34.15it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  66%|██████▋   | 2848/4297 [01:23<00:42, 34.16it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  66%|██████▋   | 2854/4297 [01:23<00:42, 34.19it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  66%|██████▋   | 2855/4297 [01:23<00:42, 34.19it/s, v_num=0, train_loss=0.239]\n",
      "Epoch 0:  67%|██████▋   | 2860/4297 [01:23<00:42, 34.20it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  67%|██████▋   | 2867/4297 [01:23<00:41, 34.24it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  67%|██████▋   | 2873/4297 [01:23<00:41, 34.26it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  67%|██████▋   | 2880/4297 [01:23<00:41, 34.30it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  67%|██████▋   | 2881/4297 [01:23<00:41, 34.31it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  67%|██████▋   | 2887/4297 [01:24<00:41, 34.33it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  67%|██████▋   | 2895/4297 [01:24<00:40, 34.38it/s, v_num=0, train_loss=0.216] \n",
      "Epoch 0:  68%|██████▊   | 2901/4297 [01:24<00:40, 34.40it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  68%|██████▊   | 2902/4297 [01:24<00:40, 34.41it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  68%|██████▊   | 2909/4297 [01:24<00:40, 34.44it/s, v_num=0, train_loss=0.224]\n",
      "Epoch 0:  68%|██████▊   | 2915/4297 [01:24<00:40, 34.47it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  68%|██████▊   | 2923/4297 [01:24<00:39, 34.51it/s, v_num=0, train_loss=0.0925]\n",
      "Epoch 0:  68%|██████▊   | 2929/4297 [01:24<00:39, 34.55it/s, v_num=0, train_loss=0.0953]\n",
      "Epoch 0:  68%|██████▊   | 2930/4297 [01:24<00:39, 34.55it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  68%|██████▊   | 2937/4297 [01:24<00:39, 34.58it/s, v_num=0, train_loss=0.0933]\n",
      "Epoch 0:  68%|██████▊   | 2938/4297 [01:24<00:39, 34.59it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  69%|██████▊   | 2944/4297 [01:25<00:39, 34.62it/s, v_num=0, train_loss=0.230] \n",
      "Epoch 0:  69%|██████▊   | 2950/4297 [01:25<00:38, 34.64it/s, v_num=0, train_loss=0.295]\n",
      "Epoch 0:  69%|██████▊   | 2951/4297 [01:25<00:38, 34.65it/s, v_num=0, train_loss=0.201]\n",
      "Epoch 0:  69%|██████▉   | 2959/4297 [01:25<00:38, 34.69it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  69%|██████▉   | 2966/4297 [01:25<00:38, 34.73it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0:  69%|██████▉   | 2967/4297 [01:25<00:38, 34.74it/s, v_num=0, train_loss=0.100]\n",
      "Epoch 0:  69%|██████▉   | 2974/4297 [01:25<00:38, 34.77it/s, v_num=0, train_loss=0.180] \n",
      "Epoch 0:  69%|██████▉   | 2975/4297 [01:25<00:38, 34.78it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  69%|██████▉   | 2982/4297 [01:25<00:37, 34.82it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  70%|██████▉   | 2988/4297 [01:25<00:37, 34.84it/s, v_num=0, train_loss=0.249] \n",
      "Epoch 0:  70%|██████▉   | 2989/4297 [01:25<00:37, 34.85it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  70%|██████▉   | 2996/4297 [01:25<00:37, 34.88it/s, v_num=0, train_loss=0.224] \n",
      "Epoch 0:  70%|██████▉   | 2997/4297 [01:25<00:37, 34.89it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  70%|██████▉   | 3003/4297 [01:26<00:37, 34.92it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  70%|██████▉   | 3004/4297 [01:26<00:37, 34.92it/s, v_num=0, train_loss=0.0986]\n",
      "Epoch 0:  70%|███████   | 3011/4297 [01:26<00:36, 34.96it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  70%|███████   | 3018/4297 [01:26<00:36, 34.99it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  70%|███████   | 3019/4297 [01:26<00:36, 35.00it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  70%|███████   | 3026/4297 [01:26<00:36, 35.03it/s, v_num=0, train_loss=0.230] \n",
      "Epoch 0:  71%|███████   | 3033/4297 [01:26<00:36, 35.07it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  71%|███████   | 3034/4297 [01:26<00:36, 35.07it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  71%|███████   | 3040/4297 [01:26<00:35, 35.10it/s, v_num=0, train_loss=0.0722]\n",
      "Epoch 0:  71%|███████   | 3041/4297 [01:26<00:35, 35.10it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  71%|███████   | 3047/4297 [01:26<00:35, 35.13it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  71%|███████   | 3048/4297 [01:26<00:35, 35.13it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  71%|███████   | 3055/4297 [01:26<00:35, 35.17it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  71%|███████   | 3056/4297 [01:26<00:35, 35.17it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  71%|███████▏  | 3062/4297 [01:26<00:35, 35.20it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  71%|███████▏  | 3063/4297 [01:27<00:35, 35.20it/s, v_num=0, train_loss=0.0794]\n",
      "Epoch 0:  71%|███████▏  | 3070/4297 [01:27<00:34, 35.24it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  71%|███████▏  | 3071/4297 [01:27<00:34, 35.25it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  72%|███████▏  | 3073/4297 [01:27<00:34, 35.25it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  72%|███████▏  | 3075/4297 [01:28<00:35, 34.73it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  72%|███████▏  | 3076/4297 [01:28<00:35, 34.64it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:  72%|███████▏  | 3079/4297 [01:29<00:35, 34.50it/s, v_num=0, train_loss=0.209]\n",
      "Epoch 0:  72%|███████▏  | 3080/4297 [01:29<00:35, 34.51it/s, v_num=0, train_loss=0.308]\n",
      "Epoch 0:  72%|███████▏  | 3088/4297 [01:29<00:34, 34.56it/s, v_num=0, train_loss=0.0836]\n",
      "Epoch 0:  72%|███████▏  | 3089/4297 [01:29<00:34, 34.56it/s, v_num=0, train_loss=0.0994]\n",
      "Epoch 0:  72%|███████▏  | 3097/4297 [01:29<00:34, 34.61it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  72%|███████▏  | 3098/4297 [01:29<00:34, 34.61it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  72%|███████▏  | 3098/4297 [01:29<00:34, 34.61it/s, v_num=0, train_loss=0.193]\n",
      "Epoch 0:  72%|███████▏  | 3099/4297 [01:29<00:34, 34.62it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  72%|███████▏  | 3106/4297 [01:29<00:34, 34.66it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  72%|███████▏  | 3107/4297 [01:29<00:34, 34.67it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  73%|███████▎  | 3116/4297 [01:29<00:34, 34.72it/s, v_num=0, train_loss=0.227] \n",
      "Epoch 0:  73%|███████▎  | 3124/4297 [01:29<00:33, 34.76it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  73%|███████▎  | 3131/4297 [01:29<00:33, 34.80it/s, v_num=0, train_loss=0.0308]\n",
      "Epoch 0:  73%|███████▎  | 3137/4297 [01:30<00:33, 34.82it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  73%|███████▎  | 3138/4297 [01:30<00:33, 34.83it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:  73%|███████▎  | 3145/4297 [01:30<00:33, 34.86it/s, v_num=0, train_loss=0.0943]\n",
      "Epoch 0:  73%|███████▎  | 3152/4297 [01:30<00:32, 34.90it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  73%|███████▎  | 3153/4297 [01:30<00:32, 34.90it/s, v_num=0, train_loss=0.0632]\n",
      "Epoch 0:  74%|███████▎  | 3159/4297 [01:30<00:32, 34.92it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  74%|███████▎  | 3164/4297 [01:30<00:32, 34.94it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  74%|███████▍  | 3171/4297 [01:30<00:32, 34.97it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:  74%|███████▍  | 3172/4297 [01:30<00:32, 34.97it/s, v_num=0, train_loss=0.0641]\n",
      "Epoch 0:  74%|███████▍  | 3179/4297 [01:30<00:31, 35.01it/s, v_num=0, train_loss=0.0892]\n",
      "Epoch 0:  74%|███████▍  | 3180/4297 [01:30<00:31, 35.01it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  74%|███████▍  | 3186/4297 [01:32<00:32, 34.54it/s, v_num=0, train_loss=0.322]\n",
      "Epoch 0:  74%|███████▍  | 3187/4297 [01:32<00:32, 34.55it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  74%|███████▍  | 3196/4297 [01:32<00:31, 34.60it/s, v_num=0, train_loss=0.0654]\n",
      "Epoch 0:  75%|███████▍  | 3204/4297 [01:32<00:31, 34.65it/s, v_num=0, train_loss=0.201] \n",
      "Epoch 0:  75%|███████▍  | 3205/4297 [01:32<00:31, 34.65it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  75%|███████▍  | 3213/4297 [01:32<00:31, 34.70it/s, v_num=0, train_loss=0.0858]\n",
      "Epoch 0:  75%|███████▍  | 3214/4297 [01:32<00:31, 34.70it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  75%|███████▍  | 3222/4297 [01:32<00:30, 34.75it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  75%|███████▌  | 3230/4297 [01:32<00:30, 34.80it/s, v_num=0, train_loss=0.0461]\n",
      "Epoch 0:  75%|███████▌  | 3231/4297 [01:32<00:30, 34.80it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  75%|███████▌  | 3232/4297 [01:32<00:30, 34.81it/s, v_num=0, train_loss=0.204]\n",
      "Epoch 0:  75%|███████▌  | 3232/4297 [01:32<00:30, 34.81it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  75%|███████▌  | 3238/4297 [01:32<00:30, 34.84it/s, v_num=0, train_loss=0.257]  \n",
      "Epoch 0:  76%|███████▌  | 3245/4297 [01:33<00:30, 34.87it/s, v_num=0, train_loss=0.0572]\n",
      "Epoch 0:  76%|███████▌  | 3246/4297 [01:33<00:30, 34.87it/s, v_num=0, train_loss=0.379] \n",
      "Epoch 0:  76%|███████▌  | 3253/4297 [01:33<00:29, 34.90it/s, v_num=0, train_loss=0.179]\n",
      "Epoch 0:  76%|███████▌  | 3260/4297 [01:33<00:29, 34.94it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  76%|███████▌  | 3261/4297 [01:33<00:29, 34.94it/s, v_num=0, train_loss=0.217]\n",
      "Epoch 0:  76%|███████▌  | 3268/4297 [01:33<00:29, 34.97it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  76%|███████▌  | 3269/4297 [01:33<00:29, 34.98it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  76%|███████▌  | 3276/4297 [01:33<00:29, 35.01it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  76%|███████▋  | 3282/4297 [01:33<00:28, 35.03it/s, v_num=0, train_loss=0.194] \n",
      "Epoch 0:  76%|███████▋  | 3283/4297 [01:33<00:28, 35.04it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  77%|███████▋  | 3290/4297 [01:33<00:28, 35.07it/s, v_num=0, train_loss=0.242]\n",
      "Epoch 0:  77%|███████▋  | 3297/4297 [01:33<00:28, 35.10it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  77%|███████▋  | 3298/4297 [01:33<00:28, 35.11it/s, v_num=0, train_loss=0.178]\n",
      "Epoch 0:  77%|███████▋  | 3304/4297 [01:34<00:28, 35.14it/s, v_num=0, train_loss=0.188] \n",
      "Epoch 0:  77%|███████▋  | 3305/4297 [01:34<00:28, 35.14it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  77%|███████▋  | 3305/4297 [01:34<00:28, 35.14it/s, v_num=0, train_loss=0.0343]\n",
      "Epoch 0:  77%|███████▋  | 3306/4297 [01:34<00:28, 35.15it/s, v_num=0, train_loss=0.187] \n",
      "Epoch 0:  77%|███████▋  | 3313/4297 [01:34<00:27, 35.18it/s, v_num=0, train_loss=0.188]  \n",
      "Epoch 0:  77%|███████▋  | 3320/4297 [01:34<00:27, 35.21it/s, v_num=0, train_loss=0.190] \n",
      "Epoch 0:  77%|███████▋  | 3321/4297 [01:34<00:27, 35.22it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  77%|███████▋  | 3327/4297 [01:34<00:27, 35.24it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  78%|███████▊  | 3334/4297 [01:34<00:27, 35.27it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  78%|███████▊  | 3340/4297 [01:34<00:27, 35.29it/s, v_num=0, train_loss=0.0838]\n",
      "Epoch 0:  78%|███████▊  | 3341/4297 [01:34<00:27, 35.30it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  78%|███████▊  | 3348/4297 [01:34<00:26, 35.33it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  78%|███████▊  | 3349/4297 [01:34<00:26, 35.33it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  78%|███████▊  | 3355/4297 [01:34<00:26, 35.36it/s, v_num=0, train_loss=0.0947]\n",
      "Epoch 0:  78%|███████▊  | 3356/4297 [01:34<00:26, 35.36it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  78%|███████▊  | 3362/4297 [01:35<00:26, 35.38it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  78%|███████▊  | 3363/4297 [01:35<00:26, 35.39it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  78%|███████▊  | 3370/4297 [01:35<00:26, 35.42it/s, v_num=0, train_loss=0.261] \n",
      "Epoch 0:  79%|███████▊  | 3377/4297 [01:35<00:25, 35.45it/s, v_num=0, train_loss=0.0331]\n",
      "Epoch 0:  79%|███████▊  | 3378/4297 [01:35<00:25, 35.46it/s, v_num=0, train_loss=0.180] \n",
      "Epoch 0:  79%|███████▉  | 3386/4297 [01:35<00:25, 35.50it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  79%|███████▉  | 3393/4297 [01:35<00:25, 35.53it/s, v_num=0, train_loss=0.0929]\n",
      "Epoch 0:  79%|███████▉  | 3400/4297 [01:35<00:25, 35.56it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  79%|███████▉  | 3406/4297 [01:35<00:25, 35.58it/s, v_num=0, train_loss=0.128]  \n",
      "Epoch 0:  79%|███████▉  | 3407/4297 [01:35<00:25, 35.59it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  79%|███████▉  | 3415/4297 [01:35<00:24, 35.63it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  80%|███████▉  | 3421/4297 [01:35<00:24, 35.65it/s, v_num=0, train_loss=0.0856]\n",
      "Epoch 0:  80%|███████▉  | 3422/4297 [01:35<00:24, 35.65it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  80%|███████▉  | 3426/4297 [01:36<00:24, 35.66it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  80%|███████▉  | 3427/4297 [01:36<00:24, 35.66it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  80%|███████▉  | 3432/4297 [01:36<00:24, 35.67it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  80%|███████▉  | 3437/4297 [01:36<00:24, 35.68it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  80%|████████  | 3438/4297 [01:36<00:24, 35.68it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  80%|████████  | 3443/4297 [01:36<00:23, 35.70it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  80%|████████  | 3444/4297 [01:36<00:23, 35.70it/s, v_num=0, train_loss=0.0608]\n",
      "Epoch 0:  80%|████████  | 3449/4297 [01:36<00:23, 35.71it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  80%|████████  | 3450/4297 [01:36<00:23, 35.71it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  80%|████████  | 3455/4297 [01:36<00:23, 35.73it/s, v_num=0, train_loss=0.173]\n",
      "Epoch 0:  80%|████████  | 3456/4297 [01:36<00:23, 35.73it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  80%|████████  | 3457/4297 [01:36<00:23, 35.73it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  80%|████████  | 3458/4297 [01:38<00:23, 35.26it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  81%|████████  | 3461/4297 [01:38<00:23, 35.13it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  81%|████████  | 3464/4297 [01:38<00:23, 35.04it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  81%|████████  | 3465/4297 [01:38<00:23, 35.04it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  81%|████████  | 3466/4297 [01:38<00:23, 35.05it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  81%|████████  | 3474/4297 [01:39<00:23, 35.09it/s, v_num=0, train_loss=0.0441]\n",
      "Epoch 0:  81%|████████  | 3482/4297 [01:39<00:23, 35.13it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  81%|████████  | 3483/4297 [01:39<00:23, 35.13it/s, v_num=0, train_loss=0.0788]\n",
      "Epoch 0:  81%|████████  | 3491/4297 [01:39<00:22, 35.17it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  81%|████████▏ | 3499/4297 [01:39<00:22, 35.21it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  82%|████████▏ | 3506/4297 [01:39<00:22, 35.25it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  82%|████████▏ | 3507/4297 [01:39<00:22, 35.25it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  82%|████████▏ | 3514/4297 [01:39<00:22, 35.28it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  82%|████████▏ | 3515/4297 [01:39<00:22, 35.29it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  82%|████████▏ | 3521/4297 [01:39<00:21, 35.31it/s, v_num=0, train_loss=0.199] \n",
      "Epoch 0:  82%|████████▏ | 3522/4297 [01:39<00:21, 35.31it/s, v_num=0, train_loss=0.0646]\n",
      "Epoch 0:  82%|████████▏ | 3528/4297 [01:39<00:21, 35.33it/s, v_num=0, train_loss=0.0707]\n",
      "Epoch 0:  82%|████████▏ | 3529/4297 [01:39<00:21, 35.33it/s, v_num=0, train_loss=0.067] \n",
      "Epoch 0:  82%|████████▏ | 3530/4297 [01:39<00:21, 35.34it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  82%|████████▏ | 3535/4297 [01:39<00:21, 35.35it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:  82%|████████▏ | 3536/4297 [01:40<00:21, 35.36it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  82%|████████▏ | 3543/4297 [01:40<00:21, 35.39it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  83%|████████▎ | 3550/4297 [01:40<00:21, 35.42it/s, v_num=0, train_loss=0.178]\n",
      "Epoch 0:  83%|████████▎ | 3551/4297 [01:40<00:21, 35.42it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  83%|████████▎ | 3556/4297 [01:40<00:20, 35.44it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  83%|████████▎ | 3557/4297 [01:40<00:20, 35.44it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  83%|████████▎ | 3564/4297 [01:40<00:20, 35.47it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  83%|████████▎ | 3571/4297 [01:41<00:20, 35.05it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  83%|████████▎ | 3572/4297 [01:41<00:20, 35.05it/s, v_num=0, train_loss=0.0847]\n",
      "Epoch 0:  83%|████████▎ | 3579/4297 [01:42<00:20, 35.09it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  83%|████████▎ | 3580/4297 [01:42<00:20, 35.09it/s, v_num=0, train_loss=0.132]\n",
      "Epoch 0:  83%|████████▎ | 3581/4297 [01:42<00:20, 35.10it/s, v_num=0, train_loss=0.195]\n",
      "Epoch 0:  84%|████████▎ | 3589/4297 [01:42<00:20, 35.13it/s, v_num=0, train_loss=0.0572]\n",
      "Epoch 0:  84%|████████▎ | 3590/4297 [01:42<00:20, 35.14it/s, v_num=0, train_loss=0.216] \n",
      "Epoch 0:  84%|████████▎ | 3598/4297 [01:42<00:19, 35.18it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  84%|████████▍ | 3606/4297 [01:42<00:19, 35.22it/s, v_num=0, train_loss=0.063] \n",
      "Epoch 0:  84%|████████▍ | 3607/4297 [01:42<00:19, 35.22it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  84%|████████▍ | 3614/4297 [01:42<00:19, 35.25it/s, v_num=0, train_loss=0.0912]\n",
      "Epoch 0:  84%|████████▍ | 3621/4297 [01:42<00:19, 35.28it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  84%|████████▍ | 3628/4297 [01:42<00:18, 35.31it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  85%|████████▍ | 3635/4297 [01:42<00:18, 35.34it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  85%|████████▍ | 3642/4297 [01:42<00:18, 35.36it/s, v_num=0, train_loss=0.0676]\n",
      "Epoch 0:  85%|████████▍ | 3649/4297 [01:43<00:18, 35.39it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  85%|████████▌ | 3656/4297 [01:43<00:18, 35.42it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  85%|████████▌ | 3662/4297 [01:43<00:17, 35.44it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  85%|████████▌ | 3663/4297 [01:43<00:17, 35.44it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  85%|████████▌ | 3664/4297 [01:43<00:17, 35.45it/s, v_num=0, train_loss=0.0971]\n",
      "Epoch 0:  85%|████████▌ | 3670/4297 [01:43<00:17, 35.47it/s, v_num=0, train_loss=0.084] \n",
      "Epoch 0:  85%|████████▌ | 3671/4297 [01:43<00:17, 35.47it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  86%|████████▌ | 3679/4297 [01:43<00:17, 35.51it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  86%|████████▌ | 3686/4297 [01:43<00:17, 35.54it/s, v_num=0, train_loss=0.074] \n",
      "Epoch 0:  86%|████████▌ | 3692/4297 [01:43<00:17, 35.56it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  86%|████████▌ | 3699/4297 [01:43<00:16, 35.59it/s, v_num=0, train_loss=0.234]\n",
      "Epoch 0:  86%|████████▌ | 3700/4297 [01:43<00:16, 35.59it/s, v_num=0, train_loss=0.208]\n",
      "Epoch 0:  86%|████████▌ | 3706/4297 [01:44<00:16, 35.61it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  86%|████████▋ | 3713/4297 [01:44<00:16, 35.63it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  87%|████████▋ | 3719/4297 [01:44<00:16, 35.65it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  87%|████████▋ | 3720/4297 [01:44<00:16, 35.66it/s, v_num=0, train_loss=0.215]\n",
      "Epoch 0:  87%|████████▋ | 3726/4297 [01:44<00:16, 35.68it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  87%|████████▋ | 3727/4297 [01:44<00:15, 35.68it/s, v_num=0, train_loss=0.239]\n",
      "Epoch 0:  87%|████████▋ | 3732/4297 [01:44<00:15, 35.70it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  87%|████████▋ | 3739/4297 [01:44<00:15, 35.72it/s, v_num=0, train_loss=0.270] \n",
      "Epoch 0:  87%|████████▋ | 3740/4297 [01:44<00:15, 35.73it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  87%|████████▋ | 3747/4297 [01:44<00:15, 35.76it/s, v_num=0, train_loss=0.208] \n",
      "Epoch 0:  87%|████████▋ | 3755/4297 [01:44<00:15, 35.79it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  88%|████████▊ | 3762/4297 [01:45<00:14, 35.82it/s, v_num=0, train_loss=0.0472]\n",
      "Epoch 0:  88%|████████▊ | 3768/4297 [01:45<00:14, 35.84it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  88%|████████▊ | 3774/4297 [01:45<00:14, 35.86it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:  88%|████████▊ | 3775/4297 [01:45<00:14, 35.86it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  88%|████████▊ | 3782/4297 [01:45<00:14, 35.89it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  88%|████████▊ | 3789/4297 [01:45<00:14, 35.91it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  88%|████████▊ | 3796/4297 [01:45<00:13, 35.94it/s, v_num=0, train_loss=0.241]\n",
      "Epoch 0:  88%|████████▊ | 3802/4297 [01:45<00:13, 35.96it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  89%|████████▊ | 3807/4297 [01:45<00:13, 35.97it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  89%|████████▊ | 3808/4297 [01:45<00:13, 35.97it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  89%|████████▊ | 3808/4297 [01:45<00:13, 35.97it/s, v_num=0, train_loss=0.160]\n",
      "Epoch 0:  89%|████████▉ | 3814/4297 [01:45<00:13, 35.99it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  89%|████████▉ | 3820/4297 [01:46<00:13, 36.00it/s, v_num=0, train_loss=0.262] \n",
      "Epoch 0:  89%|████████▉ | 3821/4297 [01:46<00:13, 36.01it/s, v_num=0, train_loss=0.262]\n",
      "Epoch 0:  89%|████████▉ | 3821/4297 [01:46<00:13, 36.01it/s, v_num=0, train_loss=0.0608]\n",
      "Epoch 0:  89%|████████▉ | 3827/4297 [01:46<00:13, 36.03it/s, v_num=0, train_loss=0.0406]\n",
      "Epoch 0:  89%|████████▉ | 3833/4297 [01:46<00:12, 36.05it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  89%|████████▉ | 3834/4297 [01:46<00:12, 36.05it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  89%|████████▉ | 3840/4297 [01:46<00:12, 36.07it/s, v_num=0, train_loss=0.0822]\n",
      "Epoch 0:  89%|████████▉ | 3841/4297 [01:46<00:12, 36.07it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:  89%|████████▉ | 3842/4297 [01:47<00:12, 35.63it/s, v_num=0, train_loss=0.100]\n",
      "Epoch 0:  90%|████████▉ | 3848/4297 [01:48<00:12, 35.55it/s, v_num=0, train_loss=0.149]\n",
      "Epoch 0:  90%|████████▉ | 3854/4297 [01:48<00:12, 35.57it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  90%|████████▉ | 3855/4297 [01:48<00:12, 35.57it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  90%|████████▉ | 3864/4297 [01:48<00:12, 35.61it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  90%|█████████ | 3871/4297 [01:48<00:11, 35.64it/s, v_num=0, train_loss=0.235]\n",
      "Epoch 0:  90%|█████████ | 3872/4297 [01:48<00:11, 35.65it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  90%|█████████ | 3880/4297 [01:48<00:11, 35.68it/s, v_num=0, train_loss=0.0232]\n",
      "Epoch 0:  90%|█████████ | 3881/4297 [01:48<00:11, 35.69it/s, v_num=0, train_loss=0.099] \n",
      "Epoch 0:  91%|█████████ | 3889/4297 [01:48<00:11, 35.72it/s, v_num=0, train_loss=0.226] \n",
      "Epoch 0:  91%|█████████ | 3896/4297 [01:48<00:11, 35.75it/s, v_num=0, train_loss=0.0806]\n",
      "Epoch 0:  91%|█████████ | 3902/4297 [01:49<00:11, 35.77it/s, v_num=0, train_loss=0.0954]\n",
      "Epoch 0:  91%|█████████ | 3903/4297 [01:49<00:11, 35.77it/s, v_num=0, train_loss=0.0852]\n",
      "Epoch 0:  91%|█████████ | 3909/4297 [01:49<00:10, 35.79it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  91%|█████████ | 3910/4297 [01:49<00:10, 35.79it/s, v_num=0, train_loss=0.195]\n",
      "Epoch 0:  91%|█████████ | 3917/4297 [01:49<00:10, 35.82it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  91%|█████████ | 3918/4297 [01:49<00:10, 35.83it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  91%|█████████▏| 3925/4297 [01:49<00:10, 35.86it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:  91%|█████████▏| 3926/4297 [01:49<00:10, 35.86it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  92%|█████████▏| 3933/4297 [01:49<00:10, 35.88it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  92%|█████████▏| 3940/4297 [01:49<00:09, 35.91it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  92%|█████████▏| 3941/4297 [01:49<00:09, 35.92it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  92%|█████████▏| 3942/4297 [01:49<00:09, 35.92it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  92%|█████████▏| 3948/4297 [01:49<00:09, 35.94it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  92%|█████████▏| 3949/4297 [01:51<00:09, 35.45it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  92%|█████████▏| 3950/4297 [01:51<00:09, 35.46it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  92%|█████████▏| 3958/4297 [01:51<00:09, 35.50it/s, v_num=0, train_loss=0.205] \n",
      "Epoch 0:  92%|█████████▏| 3959/4297 [01:51<00:09, 35.50it/s, v_num=0, train_loss=0.0998]\n",
      "Epoch 0:  92%|█████████▏| 3967/4297 [01:51<00:09, 35.54it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  92%|█████████▏| 3968/4297 [01:51<00:09, 35.54it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  93%|█████████▎| 3976/4297 [01:51<00:09, 35.58it/s, v_num=0, train_loss=0.216] \n",
      "Epoch 0:  93%|█████████▎| 3984/4297 [01:51<00:08, 35.61it/s, v_num=0, train_loss=0.248] \n",
      "Epoch 0:  93%|█████████▎| 3985/4297 [01:51<00:08, 35.62it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  93%|█████████▎| 3986/4297 [01:51<00:08, 35.62it/s, v_num=0, train_loss=0.0551]\n",
      "Epoch 0:  93%|█████████▎| 3994/4297 [01:52<00:08, 35.66it/s, v_num=0, train_loss=0.201] \n",
      "Epoch 0:  93%|█████████▎| 3995/4297 [01:52<00:08, 35.66it/s, v_num=0, train_loss=0.0984]\n",
      "Epoch 0:  93%|█████████▎| 3996/4297 [01:52<00:08, 35.67it/s, v_num=0, train_loss=0.211] \n",
      "Epoch 0:  93%|█████████▎| 4003/4297 [01:52<00:08, 35.70it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:  93%|█████████▎| 4009/4297 [01:52<00:08, 35.71it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:  93%|█████████▎| 4010/4297 [01:52<00:08, 35.72it/s, v_num=0, train_loss=0.242]\n",
      "Epoch 0:  93%|█████████▎| 4017/4297 [01:52<00:07, 35.74it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  94%|█████████▎| 4023/4297 [01:52<00:07, 35.76it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  94%|█████████▎| 4024/4297 [01:52<00:07, 35.76it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  94%|█████████▍| 4030/4297 [01:52<00:07, 35.78it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:  94%|█████████▍| 4035/4297 [01:52<00:07, 35.79it/s, v_num=0, train_loss=0.244] \n",
      "Epoch 0:  94%|█████████▍| 4042/4297 [01:52<00:07, 35.81it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  94%|█████████▍| 4043/4297 [01:52<00:07, 35.82it/s, v_num=0, train_loss=0.0578]\n",
      "Epoch 0:  94%|█████████▍| 4048/4297 [01:52<00:06, 35.83it/s, v_num=0, train_loss=0.203] \n",
      "Epoch 0:  94%|█████████▍| 4049/4297 [01:53<00:06, 35.83it/s, v_num=0, train_loss=0.177]\n",
      "Epoch 0:  94%|█████████▍| 4054/4297 [01:53<00:06, 35.84it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  94%|█████████▍| 4055/4297 [01:53<00:06, 35.85it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  95%|█████████▍| 4062/4297 [01:53<00:06, 35.87it/s, v_num=0, train_loss=0.086] \n",
      "Epoch 0:  95%|█████████▍| 4063/4297 [01:53<00:06, 35.88it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  95%|█████████▍| 4070/4297 [01:53<00:06, 35.90it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  95%|█████████▍| 4076/4297 [01:53<00:06, 35.92it/s, v_num=0, train_loss=0.0938]\n",
      "Epoch 0:  95%|█████████▌| 4084/4297 [01:53<00:05, 35.95it/s, v_num=0, train_loss=0.208] \n",
      "Epoch 0:  95%|█████████▌| 4090/4297 [01:53<00:05, 35.97it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  95%|█████████▌| 4091/4297 [01:53<00:05, 35.97it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  95%|█████████▌| 4097/4297 [01:53<00:05, 35.99it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  95%|█████████▌| 4098/4297 [01:53<00:05, 36.00it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  96%|█████████▌| 4104/4297 [01:53<00:05, 36.02it/s, v_num=0, train_loss=0.210]\n",
      "Epoch 0:  96%|█████████▌| 4105/4297 [01:53<00:05, 36.02it/s, v_num=0, train_loss=0.193]\n",
      "Epoch 0:  96%|█████████▌| 4112/4297 [01:54<00:05, 36.04it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  96%|█████████▌| 4118/4297 [01:54<00:04, 36.06it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  96%|█████████▌| 4119/4297 [01:54<00:04, 36.07it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  96%|█████████▌| 4125/4297 [01:54<00:04, 36.08it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  96%|█████████▌| 4126/4297 [01:54<00:04, 36.09it/s, v_num=0, train_loss=0.0762]\n",
      "Epoch 0:  96%|█████████▌| 4133/4297 [01:54<00:04, 36.11it/s, v_num=0, train_loss=0.266] \n",
      "Epoch 0:  96%|█████████▋| 4138/4297 [01:54<00:04, 36.12it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  96%|█████████▋| 4144/4297 [01:54<00:04, 36.14it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  97%|█████████▋| 4151/4297 [01:54<00:04, 36.16it/s, v_num=0, train_loss=0.067] \n",
      "Epoch 0:  97%|█████████▋| 4152/4297 [01:54<00:04, 36.17it/s, v_num=0, train_loss=0.0983]\n",
      "Epoch 0:  97%|█████████▋| 4153/4297 [01:54<00:03, 36.17it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  97%|█████████▋| 4158/4297 [01:54<00:03, 36.19it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  97%|█████████▋| 4159/4297 [01:54<00:03, 36.19it/s, v_num=0, train_loss=0.098]\n",
      "Epoch 0:  97%|█████████▋| 4166/4297 [01:55<00:03, 36.21it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  97%|█████████▋| 4173/4297 [01:55<00:03, 36.23it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  97%|█████████▋| 4180/4297 [01:55<00:03, 36.26it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  97%|█████████▋| 4188/4297 [01:55<00:03, 36.29it/s, v_num=0, train_loss=0.0986]\n",
      "Epoch 0:  98%|█████████▊| 4194/4297 [01:55<00:02, 36.31it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  98%|█████████▊| 4195/4297 [01:55<00:02, 36.31it/s, v_num=0, train_loss=0.211]\n",
      "Epoch 0:  98%|█████████▊| 4202/4297 [01:55<00:02, 36.34it/s, v_num=0, train_loss=0.0808]\n",
      "Epoch 0:  98%|█████████▊| 4209/4297 [01:55<00:02, 36.36it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  98%|█████████▊| 4210/4297 [01:55<00:02, 36.37it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  98%|█████████▊| 4217/4297 [01:55<00:02, 36.39it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:  98%|█████████▊| 4225/4297 [01:55<00:01, 36.43it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  98%|█████████▊| 4231/4297 [01:57<00:01, 35.94it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  98%|█████████▊| 4232/4297 [01:57<00:01, 35.94it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  99%|█████████▊| 4238/4297 [01:57<00:01, 35.96it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  99%|█████████▊| 4239/4297 [01:57<00:01, 35.97it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  99%|█████████▊| 4240/4297 [01:57<00:01, 35.97it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  99%|█████████▊| 4240/4297 [01:57<00:01, 35.97it/s, v_num=0, train_loss=0.0697]\n",
      "Epoch 0:  99%|█████████▉| 4246/4297 [01:57<00:01, 35.99it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  99%|█████████▉| 4247/4297 [01:58<00:01, 35.99it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  99%|█████████▉| 4254/4297 [01:58<00:01, 36.02it/s, v_num=0, train_loss=0.0892]\n",
      "Epoch 0:  99%|█████████▉| 4261/4297 [01:58<00:00, 36.04it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  99%|█████████▉| 4261/4297 [01:58<00:00, 36.04it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  99%|█████████▉| 4267/4297 [01:58<00:00, 36.06it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  99%|█████████▉| 4268/4297 [01:58<00:00, 36.06it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  99%|█████████▉| 4273/4297 [01:58<00:00, 36.07it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  99%|█████████▉| 4274/4297 [01:58<00:00, 36.08it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0: 100%|█████████▉| 4279/4297 [01:58<00:00, 36.08it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0: 100%|█████████▉| 4280/4297 [01:58<00:00, 36.09it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0: 100%|█████████▉| 4287/4297 [01:58<00:00, 36.11it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0: 100%|█████████▉| 4294/4297 [01:58<00:00, 36.14it/s, v_num=0, train_loss=0.0398]\n",
      "Epoch 0: 100%|█████████▉| 4295/4297 [01:58<00:00, 36.14it/s, v_num=0, train_loss=0.067] \n",
      "Epoch 0: 100%|██████████| 4297/4297 [01:58<00:00, 36.15it/s, v_num=0, train_loss=0.0371]\n",
      "Epoch 0: 100%|██████████| 4297/4297 [01:59<00:00, 36.09it/s, v_num=0, train_loss=0.0371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/nam/protoplast_results/TorchTrainer_2025-09-19_06-42-09/TorchTrainer_c4109_00000_0_2025-09-19_06-42-09/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4297/4297 [01:59<00:00, 36.06it/s, v_num=0, train_loss=0.0371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=425562)\u001b[0m [rank0]:[W919 06:44:32.967584019 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "# Set up training\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,\n",
    "    DistributedCellLineAnnDataset,\n",
    "    model_keys = [\"num_genes\",\n",
    "                  \"num_classes\"],\n",
    "    metadata_cb = cell_line_metadata_cb,\n",
    "    sparse_keys = \"X\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.train([DS_PATHS[0]],\n",
    "                       batch_size = 1024,\n",
    "                       test_size = test_size, \n",
    "                       val_size = val_size,\n",
    "                       num_workers = 1,\n",
    "                       resource_per_worker = {\"GPU\": 1, \"CPU\": thread_per_worker})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## 5. Train on `plate2_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab` dataset\n",
    "\n",
    "We now have a checkpoint saved after training the classification model using the first dataset. We need to pass into `train()` the path to the checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate2_adata = adatas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "DnEU",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>gene_count</th>\n",
       "      <th>tscp_count</th>\n",
       "      <th>mread_count</th>\n",
       "      <th>drugname_drugconc</th>\n",
       "      <th>drug</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>sublibrary</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>pcnt_mito</th>\n",
       "      <th>S_score</th>\n",
       "      <th>G2M_score</th>\n",
       "      <th>phase</th>\n",
       "      <th>pass_filter</th>\n",
       "      <th>cell_name</th>\n",
       "      <th>plate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARCODE_SUB_LIB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_001_053-lib_1000</th>\n",
       "      <td>smp_1591</td>\n",
       "      <td>2671</td>\n",
       "      <td>5629</td>\n",
       "      <td>6830</td>\n",
       "      <td>[('Infigratinib', 0.5, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_1119</td>\n",
       "      <td>lib_1000</td>\n",
       "      <td>01_001_053</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>-0.265873</td>\n",
       "      <td>-0.313553</td>\n",
       "      <td>G1</td>\n",
       "      <td>full</td>\n",
       "      <td>CFPAC-1</td>\n",
       "      <td>plate2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_082-lib_1000</th>\n",
       "      <td>smp_1591</td>\n",
       "      <td>2148</td>\n",
       "      <td>3173</td>\n",
       "      <td>3826</td>\n",
       "      <td>[('Infigratinib', 0.5, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0292</td>\n",
       "      <td>lib_1000</td>\n",
       "      <td>01_001_082</td>\n",
       "      <td>0.025843</td>\n",
       "      <td>0.400794</td>\n",
       "      <td>0.520879</td>\n",
       "      <td>G2M</td>\n",
       "      <td>full</td>\n",
       "      <td>HCT15</td>\n",
       "      <td>plate2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_145-lib_1000</th>\n",
       "      <td>smp_1591</td>\n",
       "      <td>683</td>\n",
       "      <td>886</td>\n",
       "      <td>1073</td>\n",
       "      <td>[('Infigratinib', 0.5, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_1098</td>\n",
       "      <td>lib_1000</td>\n",
       "      <td>01_001_145</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>-0.019841</td>\n",
       "      <td>-0.032967</td>\n",
       "      <td>G1</td>\n",
       "      <td>full</td>\n",
       "      <td>HepG2/C3A</td>\n",
       "      <td>plate2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_175-lib_1000</th>\n",
       "      <td>smp_1591</td>\n",
       "      <td>1845</td>\n",
       "      <td>2786</td>\n",
       "      <td>3368</td>\n",
       "      <td>[('Infigratinib', 0.5, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0131</td>\n",
       "      <td>lib_1000</td>\n",
       "      <td>01_001_175</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>-0.123016</td>\n",
       "      <td>-0.118498</td>\n",
       "      <td>G1</td>\n",
       "      <td>full</td>\n",
       "      <td>A-172</td>\n",
       "      <td>plate2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_001_181-lib_1000</th>\n",
       "      <td>smp_1591</td>\n",
       "      <td>1228</td>\n",
       "      <td>1849</td>\n",
       "      <td>2226</td>\n",
       "      <td>[('Infigratinib', 0.5, 'uM')]</td>\n",
       "      <td>Infigratinib</td>\n",
       "      <td>CVCL_0399</td>\n",
       "      <td>lib_1000</td>\n",
       "      <td>01_001_181</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>S</td>\n",
       "      <td>full</td>\n",
       "      <td>LoVo</td>\n",
       "      <td>plate2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sample  gene_count  tscp_count  mread_count  \\\n",
       "BARCODE_SUB_LIB_ID                                                   \n",
       "01_001_053-lib_1000  smp_1591        2671        5629         6830   \n",
       "01_001_082-lib_1000  smp_1591        2148        3173         3826   \n",
       "01_001_145-lib_1000  smp_1591         683         886         1073   \n",
       "01_001_175-lib_1000  smp_1591        1845        2786         3368   \n",
       "01_001_181-lib_1000  smp_1591        1228        1849         2226   \n",
       "\n",
       "                                 drugname_drugconc          drug  cell_line  \\\n",
       "BARCODE_SUB_LIB_ID                                                            \n",
       "01_001_053-lib_1000  [('Infigratinib', 0.5, 'uM')]  Infigratinib  CVCL_1119   \n",
       "01_001_082-lib_1000  [('Infigratinib', 0.5, 'uM')]  Infigratinib  CVCL_0292   \n",
       "01_001_145-lib_1000  [('Infigratinib', 0.5, 'uM')]  Infigratinib  CVCL_1098   \n",
       "01_001_175-lib_1000  [('Infigratinib', 0.5, 'uM')]  Infigratinib  CVCL_0131   \n",
       "01_001_181-lib_1000  [('Infigratinib', 0.5, 'uM')]  Infigratinib  CVCL_0399   \n",
       "\n",
       "                    sublibrary     BARCODE  pcnt_mito   S_score  G2M_score  \\\n",
       "BARCODE_SUB_LIB_ID                                                           \n",
       "01_001_053-lib_1000   lib_1000  01_001_053   0.016522 -0.265873  -0.313553   \n",
       "01_001_082-lib_1000   lib_1000  01_001_082   0.025843  0.400794   0.520879   \n",
       "01_001_145-lib_1000   lib_1000  01_001_145   0.029345 -0.019841  -0.032967   \n",
       "01_001_175-lib_1000   lib_1000  01_001_175   0.031587 -0.123016  -0.118498   \n",
       "01_001_181-lib_1000   lib_1000  01_001_181   0.015143  0.023810  -0.008791   \n",
       "\n",
       "                    phase pass_filter  cell_name   plate  \n",
       "BARCODE_SUB_LIB_ID                                        \n",
       "01_001_053-lib_1000    G1        full    CFPAC-1  plate2  \n",
       "01_001_082-lib_1000   G2M        full      HCT15  plate2  \n",
       "01_001_145-lib_1000    G1        full  HepG2/C3A  plate2  \n",
       "01_001_175-lib_1000    G1        full      A-172  plate2  \n",
       "01_001_181-lib_1000     S        full       LoVo  plate2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate2_adata.obs.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c772fca6-b268-4f44-8061-f84f7a19b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 06:48:44,899\tINFO worker.py:1951 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=434446)\u001b[0m ✓ Applied AnnDataFileManager patch\n",
      "\u001b[36m(TrainTrainable pid=434446)\u001b[0m ✓ Applied AnnDataFileManager patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=434446)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=434446)\u001b[0m - (node_id=fc843557d0630d6a1c076c5905064061a13e15ca1dae506f17e46d07, ip=192.168.1.226, pid=434570) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m ✓ Applied AnnDataFileManager patch\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m ✓ Applied AnnDataFileManager patch\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m =========Starting the training on 0 with num threads: 12=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.11 /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.1 ...\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/6336 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/6336 [00:22<39:42:14,  0.04it/s, v_num=0, train_loss=4.070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 5/6336 [00:23<8:16:49,  0.21it/s, v_num=0, train_loss=2.600] \n",
      "Epoch 0:   0%|          | 10/6336 [00:23<4:09:25,  0.42it/s, v_num=0, train_loss=1.590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:107: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 16/6336 [00:25<2:46:26,  0.63it/s, v_num=0, train_loss=0.498]\n",
      "Epoch 0:   0%|          | 23/6336 [00:25<1:56:09,  0.91it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:   0%|          | 30/6336 [00:25<1:29:20,  1.18it/s, v_num=0, train_loss=0.593]\n",
      "Epoch 0:   1%|          | 36/6336 [00:25<1:14:42,  1.41it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:   1%|          | 44/6336 [00:25<1:01:19,  1.71it/s, v_num=0, train_loss=0.360]\n",
      "Epoch 0:   1%|          | 51/6336 [00:25<53:03,  1.97it/s, v_num=0, train_loss=0.388]  \n",
      "Epoch 0:   1%|          | 52/6336 [00:25<52:03,  2.01it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:   1%|          | 59/6336 [00:25<46:00,  2.27it/s, v_num=0, train_loss=0.226] \n",
      "Epoch 0:   1%|          | 60/6336 [00:25<45:15,  2.31it/s, v_num=0, train_loss=0.296]\n",
      "Epoch 0:   1%|          | 66/6336 [00:26<41:16,  2.53it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:   1%|          | 73/6336 [00:26<37:27,  2.79it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:   1%|          | 79/6336 [00:26<34:43,  3.00it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:   1%|▏         | 84/6336 [00:26<32:46,  3.18it/s, v_num=0, train_loss=0.320]\n",
      "Epoch 0:   1%|▏         | 85/6336 [00:26<32:24,  3.21it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:   1%|▏         | 91/6336 [00:26<30:22,  3.43it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:   2%|▏         | 98/6336 [00:26<28:17,  3.67it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:   2%|▏         | 104/6336 [00:26<26:44,  3.88it/s, v_num=0, train_loss=0.0625]\n",
      "Epoch 0:   2%|▏         | 105/6336 [00:26<26:30,  3.92it/s, v_num=0, train_loss=0.396] \n",
      "Epoch 0:   2%|▏         | 109/6336 [00:26<25:36,  4.05it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:   2%|▏         | 116/6336 [00:27<24:09,  4.29it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:   2%|▏         | 117/6336 [00:27<23:57,  4.33it/s, v_num=0, train_loss=0.265]\n",
      "Epoch 0:   2%|▏         | 124/6336 [00:27<22:40,  4.57it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:   2%|▏         | 131/6336 [00:27<21:31,  4.80it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:   2%|▏         | 137/6336 [00:27<20:38,  5.00it/s, v_num=0, train_loss=0.0734]\n",
      "Epoch 0:   2%|▏         | 138/6336 [00:27<20:30,  5.04it/s, v_num=0, train_loss=0.199] \n",
      "Epoch 0:   2%|▏         | 143/6336 [00:27<19:50,  5.20it/s, v_num=0, train_loss=0.064] \n",
      "Epoch 0:   2%|▏         | 144/6336 [00:27<19:43,  5.23it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:   2%|▏         | 145/6336 [00:27<19:35,  5.27it/s, v_num=0, train_loss=0.311]\n",
      "Epoch 0:   2%|▏         | 151/6336 [00:27<18:52,  5.46it/s, v_num=0, train_loss=0.267] \n",
      "Epoch 0:   2%|▏         | 156/6336 [00:27<18:18,  5.62it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:   3%|▎         | 162/6336 [00:27<17:41,  5.82it/s, v_num=0, train_loss=0.369] \n",
      "Epoch 0:   3%|▎         | 163/6336 [00:27<17:35,  5.85it/s, v_num=0, train_loss=0.229]\n",
      "Epoch 0:   3%|▎         | 171/6336 [00:27<16:48,  6.11it/s, v_num=0, train_loss=0.0553]\n",
      "Epoch 0:   3%|▎         | 172/6336 [00:27<16:43,  6.14it/s, v_num=0, train_loss=0.280] \n",
      "Epoch 0:   3%|▎         | 180/6336 [00:28<16:01,  6.40it/s, v_num=0, train_loss=0.414] \n",
      "Epoch 0:   3%|▎         | 186/6336 [00:28<15:32,  6.60it/s, v_num=0, train_loss=0.209] \n",
      "Epoch 0:   3%|▎         | 187/6336 [00:28<15:28,  6.63it/s, v_num=0, train_loss=0.234]\n",
      "Epoch 0:   3%|▎         | 193/6336 [00:28<15:01,  6.81it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:   3%|▎         | 194/6336 [00:28<14:57,  6.84it/s, v_num=0, train_loss=0.177]\n",
      "Epoch 0:   3%|▎         | 200/6336 [00:28<14:33,  7.03it/s, v_num=0, train_loss=0.282] \n",
      "Epoch 0:   3%|▎         | 207/6336 [00:28<14:06,  7.24it/s, v_num=0, train_loss=0.0324]\n",
      "Epoch 0:   3%|▎         | 208/6336 [00:28<14:02,  7.27it/s, v_num=0, train_loss=0.256] \n",
      "Epoch 0:   3%|▎         | 214/6336 [00:28<13:40,  7.46it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:   3%|▎         | 215/6336 [00:28<13:37,  7.49it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:   3%|▎         | 221/6336 [00:28<13:17,  7.66it/s, v_num=0, train_loss=0.0411]\n",
      "Epoch 0:   4%|▎         | 227/6336 [00:28<12:58,  7.84it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:   4%|▎         | 228/6336 [00:28<12:55,  7.87it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:   4%|▎         | 228/6336 [00:28<12:55,  7.87it/s, v_num=0, train_loss=0.247]\n",
      "Epoch 0:   4%|▎         | 233/6336 [00:29<12:41,  8.02it/s, v_num=0, train_loss=0.213] \n",
      "Epoch 0:   4%|▎         | 234/6336 [00:29<12:38,  8.05it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:   4%|▍         | 240/6336 [00:29<12:21,  8.22it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:   4%|▍         | 241/6336 [00:29<12:18,  8.25it/s, v_num=0, train_loss=0.383]\n",
      "Epoch 0:   4%|▍         | 246/6336 [00:29<12:05,  8.40it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:   4%|▍         | 247/6336 [00:29<12:02,  8.42it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:   4%|▍         | 253/6336 [00:29<11:47,  8.60it/s, v_num=0, train_loss=0.514]\n",
      "Epoch 0:   4%|▍         | 254/6336 [00:29<11:44,  8.63it/s, v_num=0, train_loss=0.108]\n",
      "Epoch 0:   4%|▍         | 261/6336 [00:29<11:27,  8.83it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:   4%|▍         | 262/6336 [00:29<11:25,  8.86it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:   4%|▍         | 263/6336 [00:29<11:23,  8.89it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:   4%|▍         | 270/6336 [00:29<11:07,  9.09it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:   4%|▍         | 271/6336 [00:29<11:04,  9.12it/s, v_num=0, train_loss=0.080]\n",
      "Epoch 0:   4%|▍         | 277/6336 [00:29<10:52,  9.29it/s, v_num=0, train_loss=0.298] \n",
      "Epoch 0:   4%|▍         | 278/6336 [00:29<10:50,  9.32it/s, v_num=0, train_loss=0.0354]\n",
      "Epoch 0:   4%|▍         | 285/6336 [00:29<10:35,  9.52it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:   5%|▍         | 286/6336 [00:29<10:33,  9.55it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:   5%|▍         | 292/6336 [00:30<10:22,  9.71it/s, v_num=0, train_loss=0.450] \n",
      "Epoch 0:   5%|▍         | 298/6336 [00:30<10:11,  9.87it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:   5%|▍         | 304/6336 [00:30<10:00, 10.04it/s, v_num=0, train_loss=0.407] \n",
      "Epoch 0:   5%|▍         | 305/6336 [00:30<09:59, 10.06it/s, v_num=0, train_loss=0.0689]\n",
      "Epoch 0:   5%|▍         | 312/6336 [00:30<09:47, 10.25it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:   5%|▍         | 313/6336 [00:30<09:45, 10.28it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:   5%|▍         | 313/6336 [00:30<09:45, 10.28it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:   5%|▌         | 320/6336 [00:30<09:34, 10.48it/s, v_num=0, train_loss=0.0384]\n",
      "Epoch 0:   5%|▌         | 321/6336 [00:30<09:32, 10.50it/s, v_num=0, train_loss=0.365] \n",
      "Epoch 0:   5%|▌         | 327/6336 [00:30<09:23, 10.66it/s, v_num=0, train_loss=0.0763]\n",
      "Epoch 0:   5%|▌         | 333/6336 [00:30<09:15, 10.82it/s, v_num=0, train_loss=0.298] \n",
      "Epoch 0:   5%|▌         | 339/6336 [00:30<09:06, 10.97it/s, v_num=0, train_loss=0.0953]\n",
      "Epoch 0:   5%|▌         | 345/6336 [00:31<08:58, 11.12it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:   6%|▌         | 351/6336 [00:31<08:50, 11.27it/s, v_num=0, train_loss=0.0734]\n",
      "Epoch 0:   6%|▌         | 352/6336 [00:31<08:49, 11.30it/s, v_num=0, train_loss=0.209] \n",
      "Epoch 0:   6%|▌         | 357/6336 [00:31<08:43, 11.42it/s, v_num=0, train_loss=0.194] \n",
      "Epoch 0:   6%|▌         | 358/6336 [00:31<08:42, 11.44it/s, v_num=0, train_loss=0.0414]\n",
      "Epoch 0:   6%|▌         | 363/6336 [00:31<08:36, 11.56it/s, v_num=0, train_loss=0.0729]\n",
      "Epoch 0:   6%|▌         | 368/6336 [00:31<08:30, 11.68it/s, v_num=0, train_loss=0.098] \n",
      "Epoch 0:   6%|▌         | 369/6336 [00:31<08:29, 11.71it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:   6%|▌         | 373/6336 [00:31<08:25, 11.79it/s, v_num=0, train_loss=0.209] \n",
      "Epoch 0:   6%|▌         | 378/6336 [00:31<08:20, 11.90it/s, v_num=0, train_loss=0.0515]\n",
      "Epoch 0:   6%|▌         | 383/6336 [00:31<08:15, 12.02it/s, v_num=0, train_loss=0.0573]\n",
      "Epoch 0:   6%|▌         | 384/6336 [00:31<08:14, 12.04it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:   6%|▌         | 385/6336 [00:35<09:01, 10.99it/s, v_num=0, train_loss=0.161]\n",
      "Epoch 0:   6%|▌         | 386/6336 [00:35<09:03, 10.95it/s, v_num=0, train_loss=0.305]\n",
      "Epoch 0:   6%|▌         | 387/6336 [00:35<09:03, 10.95it/s, v_num=0, train_loss=0.211]\n",
      "Epoch 0:   6%|▌         | 388/6336 [00:35<09:09, 10.83it/s, v_num=0, train_loss=0.161]\n",
      "Epoch 0:   6%|▌         | 392/6336 [00:35<09:05, 10.89it/s, v_num=0, train_loss=0.081] \n",
      "Epoch 0:   6%|▌         | 393/6336 [00:35<09:04, 10.92it/s, v_num=0, train_loss=0.398]\n",
      "Epoch 0:   6%|▌         | 394/6336 [00:36<09:03, 10.94it/s, v_num=0, train_loss=0.141]\n",
      "Epoch 0:   6%|▋         | 397/6336 [00:36<09:03, 10.93it/s, v_num=0, train_loss=0.275] \n",
      "Epoch 0:   6%|▋         | 398/6336 [00:36<09:02, 10.95it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:   6%|▋         | 406/6336 [00:36<08:52, 11.14it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:   6%|▋         | 407/6336 [00:36<08:51, 11.16it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:   7%|▋         | 416/6336 [00:36<08:40, 11.37it/s, v_num=0, train_loss=0.0272]\n",
      "Epoch 0:   7%|▋         | 417/6336 [00:36<08:39, 11.39it/s, v_num=0, train_loss=0.0272]\n",
      "Epoch 0:   7%|▋         | 417/6336 [00:36<08:39, 11.39it/s, v_num=0, train_loss=0.293] \n",
      "Epoch 0:   7%|▋         | 425/6336 [00:36<08:30, 11.58it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:   7%|▋         | 426/6336 [00:36<08:29, 11.60it/s, v_num=0, train_loss=0.549]\n",
      "Epoch 0:   7%|▋         | 435/6336 [00:36<08:19, 11.81it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:   7%|▋         | 435/6336 [00:36<08:19, 11.81it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:   7%|▋         | 436/6336 [00:36<08:18, 11.83it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:   7%|▋         | 444/6336 [00:36<08:10, 12.01it/s, v_num=0, train_loss=0.0417]\n",
      "Epoch 0:   7%|▋         | 445/6336 [00:36<08:09, 12.03it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:   7%|▋         | 451/6336 [00:37<08:04, 12.16it/s, v_num=0, train_loss=0.0579]\n",
      "Epoch 0:   7%|▋         | 457/6336 [00:37<07:58, 12.28it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:   7%|▋         | 463/6336 [00:37<07:53, 12.41it/s, v_num=0, train_loss=0.0372]\n",
      "Epoch 0:   7%|▋         | 464/6336 [00:37<07:52, 12.42it/s, v_num=0, train_loss=0.0372]\n",
      "Epoch 0:   7%|▋         | 464/6336 [00:37<07:52, 12.42it/s, v_num=0, train_loss=0.0273]\n",
      "Epoch 0:   7%|▋         | 471/6336 [00:37<07:46, 12.57it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:   7%|▋         | 472/6336 [00:37<07:45, 12.60it/s, v_num=0, train_loss=0.0613]\n",
      "Epoch 0:   8%|▊         | 478/6336 [00:37<07:40, 12.72it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:   8%|▊         | 479/6336 [00:37<07:39, 12.74it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:   8%|▊         | 485/6336 [00:37<07:34, 12.86it/s, v_num=0, train_loss=0.0384]\n",
      "Epoch 0:   8%|▊         | 486/6336 [00:37<07:34, 12.88it/s, v_num=0, train_loss=0.275] \n",
      "Epoch 0:   8%|▊         | 491/6336 [00:37<07:30, 12.98it/s, v_num=0, train_loss=0.0414]\n",
      "Epoch 0:   8%|▊         | 492/6336 [00:37<07:29, 13.00it/s, v_num=0, train_loss=0.0808]\n",
      "Epoch 0:   8%|▊         | 498/6336 [00:37<07:24, 13.12it/s, v_num=0, train_loss=0.187] \n",
      "Epoch 0:   8%|▊         | 499/6336 [00:37<07:24, 13.14it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:   8%|▊         | 505/6336 [00:38<07:19, 13.26it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:   8%|▊         | 510/6336 [00:38<07:16, 13.35it/s, v_num=0, train_loss=0.293] \n",
      "Epoch 0:   8%|▊         | 511/6336 [00:38<07:15, 13.37it/s, v_num=0, train_loss=0.074]\n",
      "Epoch 0:   8%|▊         | 517/6336 [00:38<07:11, 13.49it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:   8%|▊         | 518/6336 [00:38<07:10, 13.51it/s, v_num=0, train_loss=0.0985]\n",
      "Epoch 0:   8%|▊         | 519/6336 [00:38<07:09, 13.53it/s, v_num=0, train_loss=0.243] \n",
      "Epoch 0:   8%|▊         | 525/6336 [00:38<07:05, 13.65it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:   8%|▊         | 526/6336 [00:38<07:04, 13.67it/s, v_num=0, train_loss=0.0824]\n",
      "Epoch 0:   8%|▊         | 532/6336 [00:38<07:00, 13.79it/s, v_num=0, train_loss=0.0906]\n",
      "Epoch 0:   9%|▊         | 539/6336 [00:38<06:56, 13.93it/s, v_num=0, train_loss=0.0564]\n",
      "Epoch 0:   9%|▊         | 546/6336 [00:38<06:51, 14.06it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:   9%|▊         | 552/6336 [00:38<06:48, 14.17it/s, v_num=0, train_loss=0.0426] \n",
      "Epoch 0:   9%|▉         | 558/6336 [00:39<06:44, 14.29it/s, v_num=0, train_loss=0.209] \n",
      "Epoch 0:   9%|▉         | 559/6336 [00:39<06:43, 14.31it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:   9%|▉         | 565/6336 [00:39<06:40, 14.42it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:   9%|▉         | 566/6336 [00:39<06:39, 14.44it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:   9%|▉         | 573/6336 [00:39<06:35, 14.58it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:   9%|▉         | 580/6336 [00:39<06:31, 14.71it/s, v_num=0, train_loss=0.0616]\n",
      "Epoch 0:   9%|▉         | 586/6336 [00:39<06:27, 14.82it/s, v_num=0, train_loss=0.0708]\n",
      "Epoch 0:   9%|▉         | 592/6336 [00:39<06:24, 14.93it/s, v_num=0, train_loss=0.0616]\n",
      "Epoch 0:   9%|▉         | 599/6336 [00:39<06:20, 15.06it/s, v_num=0, train_loss=0.0506]\n",
      "Epoch 0:   9%|▉         | 600/6336 [00:39<06:20, 15.08it/s, v_num=0, train_loss=0.0737]\n",
      "Epoch 0:  10%|▉         | 605/6336 [00:39<06:17, 15.16it/s, v_num=0, train_loss=0.0375]\n",
      "Epoch 0:  10%|▉         | 606/6336 [00:39<06:17, 15.18it/s, v_num=0, train_loss=0.215] \n",
      "Epoch 0:  10%|▉         | 613/6336 [00:40<06:13, 15.31it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  10%|▉         | 619/6336 [00:40<06:10, 15.42it/s, v_num=0, train_loss=0.201] \n",
      "Epoch 0:  10%|▉         | 620/6336 [00:40<06:10, 15.44it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  10%|▉         | 621/6336 [00:40<06:09, 15.46it/s, v_num=0, train_loss=0.405]\n",
      "Epoch 0:  10%|▉         | 626/6336 [00:40<06:07, 15.55it/s, v_num=0, train_loss=0.258] \n",
      "Epoch 0:  10%|▉         | 627/6336 [00:40<06:06, 15.56it/s, v_num=0, train_loss=0.141]\n",
      "Epoch 0:  10%|▉         | 628/6336 [00:40<06:06, 15.58it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  10%|█         | 634/6336 [00:40<06:03, 15.69it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  10%|█         | 635/6336 [00:40<06:02, 15.71it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  10%|█         | 635/6336 [00:40<06:02, 15.71it/s, v_num=0, train_loss=0.0714]\n",
      "Epoch 0:  10%|█         | 636/6336 [00:40<06:02, 15.72it/s, v_num=0, train_loss=0.0688]\n",
      "Epoch 0:  10%|█         | 641/6336 [00:40<06:00, 15.81it/s, v_num=0, train_loss=0.0578]\n",
      "Epoch 0:  10%|█         | 642/6336 [00:40<05:59, 15.83it/s, v_num=0, train_loss=0.213] \n",
      "Epoch 0:  10%|█         | 648/6336 [00:40<05:57, 15.93it/s, v_num=0, train_loss=0.0792]\n",
      "Epoch 0:  10%|█         | 652/6336 [00:40<05:55, 15.99it/s, v_num=0, train_loss=0.0936]\n",
      "Epoch 0:  10%|█         | 658/6336 [00:40<05:52, 16.09it/s, v_num=0, train_loss=0.0229]\n",
      "Epoch 0:  10%|█         | 665/6336 [00:41<05:49, 16.21it/s, v_num=0, train_loss=0.0278]\n",
      "Epoch 0:  11%|█         | 672/6336 [00:41<05:46, 16.34it/s, v_num=0, train_loss=0.0922]\n",
      "Epoch 0:  11%|█         | 673/6336 [00:41<05:46, 16.36it/s, v_num=0, train_loss=0.238] \n",
      "Epoch 0:  11%|█         | 678/6336 [00:41<05:44, 16.44it/s, v_num=0, train_loss=0.303] \n",
      "Epoch 0:  11%|█         | 679/6336 [00:41<05:43, 16.46it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  11%|█         | 684/6336 [00:41<05:41, 16.54it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  11%|█         | 690/6336 [00:41<05:39, 16.64it/s, v_num=0, train_loss=0.389] \n",
      "Epoch 0:  11%|█         | 691/6336 [00:41<05:38, 16.65it/s, v_num=0, train_loss=0.0831]\n",
      "Epoch 0:  11%|█         | 696/6336 [00:41<05:37, 16.73it/s, v_num=0, train_loss=0.251] \n",
      "Epoch 0:  11%|█         | 702/6336 [00:41<05:34, 16.83it/s, v_num=0, train_loss=0.268] \n",
      "Epoch 0:  11%|█         | 703/6336 [00:41<05:34, 16.85it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  11%|█         | 709/6336 [00:41<05:31, 16.95it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  11%|█▏        | 716/6336 [00:41<05:29, 17.07it/s, v_num=0, train_loss=0.246] \n",
      "Epoch 0:  11%|█▏        | 722/6336 [00:42<05:27, 17.16it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  11%|█▏        | 727/6336 [00:42<05:25, 17.24it/s, v_num=0, train_loss=0.244] \n",
      "Epoch 0:  12%|█▏        | 733/6336 [00:42<05:23, 17.33it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  12%|█▏        | 741/6336 [00:42<05:20, 17.47it/s, v_num=0, train_loss=0.226] \n",
      "Epoch 0:  12%|█▏        | 741/6336 [00:42<05:20, 17.47it/s, v_num=0, train_loss=0.0742]\n",
      "Epoch 0:  12%|█▏        | 742/6336 [00:42<05:19, 17.49it/s, v_num=0, train_loss=0.222] \n",
      "Epoch 0:  12%|█▏        | 748/6336 [00:42<05:17, 17.58it/s, v_num=0, train_loss=0.0532]\n",
      "Epoch 0:  12%|█▏        | 753/6336 [00:42<05:16, 17.65it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  12%|█▏        | 754/6336 [00:42<05:15, 17.67it/s, v_num=0, train_loss=0.0916]\n",
      "Epoch 0:  12%|█▏        | 758/6336 [00:42<05:14, 17.72it/s, v_num=0, train_loss=0.0705]\n",
      "Epoch 0:  12%|█▏        | 759/6336 [00:42<05:14, 17.73it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  12%|█▏        | 765/6336 [00:42<05:12, 17.82it/s, v_num=0, train_loss=0.0722]\n",
      "Epoch 0:  12%|█▏        | 768/6336 [00:42<05:11, 17.86it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  12%|█▏        | 770/6336 [00:46<05:33, 16.69it/s, v_num=0, train_loss=0.0805]\n",
      "Epoch 0:  12%|█▏        | 772/6336 [00:46<05:36, 16.54it/s, v_num=0, train_loss=0.0405]\n",
      "Epoch 0:  12%|█▏        | 779/6336 [00:46<05:33, 16.64it/s, v_num=0, train_loss=0.0611]\n",
      "Epoch 0:  12%|█▏        | 785/6336 [00:46<05:31, 16.73it/s, v_num=0, train_loss=0.0678]\n",
      "Epoch 0:  12%|█▏        | 786/6336 [00:46<05:31, 16.75it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  13%|█▎        | 793/6336 [00:47<05:28, 16.86it/s, v_num=0, train_loss=0.0393]\n",
      "Epoch 0:  13%|█▎        | 794/6336 [00:47<05:28, 16.88it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  13%|█▎        | 802/6336 [00:47<05:25, 17.01it/s, v_num=0, train_loss=0.338]\n",
      "Epoch 0:  13%|█▎        | 809/6336 [00:47<05:22, 17.11it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  13%|█▎        | 810/6336 [00:47<05:22, 17.13it/s, v_num=0, train_loss=0.177]\n",
      "Epoch 0:  13%|█▎        | 817/6336 [00:47<05:20, 17.24it/s, v_num=0, train_loss=0.0072]\n",
      "Epoch 0:  13%|█▎        | 825/6336 [00:47<05:17, 17.37it/s, v_num=0, train_loss=0.0635]\n",
      "Epoch 0:  13%|█▎        | 826/6336 [00:47<05:16, 17.38it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  13%|█▎        | 832/6336 [00:47<05:15, 17.47it/s, v_num=0, train_loss=0.0393]\n",
      "Epoch 0:  13%|█▎        | 833/6336 [00:47<05:14, 17.48it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  13%|█▎        | 839/6336 [00:47<05:12, 17.57it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  13%|█▎        | 845/6336 [00:47<05:11, 17.65it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  13%|█▎        | 851/6336 [00:47<05:09, 17.74it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  13%|█▎        | 852/6336 [00:48<05:08, 17.75it/s, v_num=0, train_loss=0.0115]\n",
      "Epoch 0:  14%|█▎        | 858/6336 [00:48<05:07, 17.84it/s, v_num=0, train_loss=0.0967]\n",
      "Epoch 0:  14%|█▎        | 859/6336 [00:48<05:06, 17.85it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  14%|█▎        | 864/6336 [00:48<05:05, 17.92it/s, v_num=0, train_loss=0.0341]\n",
      "Epoch 0:  14%|█▎        | 869/6336 [00:48<05:04, 17.98it/s, v_num=0, train_loss=0.0958]\n",
      "Epoch 0:  14%|█▍        | 874/6336 [00:48<05:02, 18.04it/s, v_num=0, train_loss=0.0809]\n",
      "Epoch 0:  14%|█▍        | 879/6336 [00:48<05:01, 18.10it/s, v_num=0, train_loss=0.0398]\n",
      "Epoch 0:  14%|█▍        | 880/6336 [00:48<05:01, 18.11it/s, v_num=0, train_loss=0.0625]\n",
      "Epoch 0:  14%|█▍        | 881/6336 [00:48<05:00, 18.13it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  14%|█▍        | 887/6336 [00:48<04:59, 18.21it/s, v_num=0, train_loss=0.0581]\n",
      "Epoch 0:  14%|█▍        | 892/6336 [00:48<04:57, 18.27it/s, v_num=0, train_loss=0.0498]\n",
      "Epoch 0:  14%|█▍        | 897/6336 [00:48<04:56, 18.33it/s, v_num=0, train_loss=0.0319]\n",
      "Epoch 0:  14%|█▍        | 902/6336 [00:49<04:55, 18.39it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  14%|█▍        | 903/6336 [00:49<04:55, 18.40it/s, v_num=0, train_loss=0.039]\n",
      "Epoch 0:  14%|█▍        | 910/6336 [00:49<04:53, 18.50it/s, v_num=0, train_loss=0.0719]\n",
      "Epoch 0:  14%|█▍        | 916/6336 [00:49<04:51, 18.58it/s, v_num=0, train_loss=0.0606]\n",
      "Epoch 0:  15%|█▍        | 923/6336 [00:49<04:49, 18.67it/s, v_num=0, train_loss=0.0689]\n",
      "Epoch 0:  15%|█▍        | 929/6336 [00:49<04:48, 18.76it/s, v_num=0, train_loss=0.248] \n",
      "Epoch 0:  15%|█▍        | 930/6336 [00:49<04:48, 18.77it/s, v_num=0, train_loss=0.248]\n",
      "Epoch 0:  15%|█▍        | 930/6336 [00:49<04:48, 18.77it/s, v_num=0, train_loss=0.0426]\n",
      "Epoch 0:  15%|█▍        | 935/6336 [00:49<04:46, 18.83it/s, v_num=0, train_loss=0.0865]\n",
      "Epoch 0:  15%|█▍        | 936/6336 [00:49<04:46, 18.84it/s, v_num=0, train_loss=0.0313]\n",
      "Epoch 0:  15%|█▍        | 942/6336 [00:49<04:45, 18.93it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  15%|█▍        | 943/6336 [00:49<04:44, 18.94it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  15%|█▍        | 950/6336 [00:49<04:42, 19.04it/s, v_num=0, train_loss=0.357] \n",
      "Epoch 0:  15%|█▌        | 957/6336 [00:50<04:41, 19.13it/s, v_num=0, train_loss=0.095] \n",
      "Epoch 0:  15%|█▌        | 962/6336 [00:50<04:40, 19.19it/s, v_num=0, train_loss=0.310] \n",
      "Epoch 0:  15%|█▌        | 968/6336 [00:50<04:38, 19.26it/s, v_num=0, train_loss=0.0774]\n",
      "Epoch 0:  15%|█▌        | 974/6336 [00:50<04:37, 19.34it/s, v_num=0, train_loss=0.218] \n",
      "Epoch 0:  15%|█▌        | 981/6336 [00:50<04:35, 19.44it/s, v_num=0, train_loss=0.0803]\n",
      "Epoch 0:  15%|█▌        | 982/6336 [00:50<04:35, 19.45it/s, v_num=0, train_loss=0.0868]\n",
      "Epoch 0:  16%|█▌        | 988/6336 [00:50<04:33, 19.53it/s, v_num=0, train_loss=0.064] \n",
      "Epoch 0:  16%|█▌        | 989/6336 [00:50<04:33, 19.54it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  16%|█▌        | 994/6336 [00:50<04:32, 19.60it/s, v_num=0, train_loss=0.0905]\n",
      "Epoch 0:  16%|█▌        | 995/6336 [00:50<04:32, 19.61it/s, v_num=0, train_loss=0.0887]\n",
      "Epoch 0:  16%|█▌        | 999/6336 [00:50<04:31, 19.65it/s, v_num=0, train_loss=0.0415]\n",
      "Epoch 0:  16%|█▌        | 1005/6336 [00:50<04:30, 19.72it/s, v_num=0, train_loss=0.0795]\n",
      "Epoch 0:  16%|█▌        | 1012/6336 [00:51<04:28, 19.81it/s, v_num=0, train_loss=0.0542]\n",
      "Epoch 0:  16%|█▌        | 1019/6336 [00:51<04:27, 19.90it/s, v_num=0, train_loss=0.0676]\n",
      "Epoch 0:  16%|█▌        | 1026/6336 [00:51<04:25, 19.99it/s, v_num=0, train_loss=0.193] \n",
      "Epoch 0:  16%|█▋        | 1033/6336 [00:51<04:24, 20.08it/s, v_num=0, train_loss=0.0349]\n",
      "Epoch 0:  16%|█▋        | 1034/6336 [00:51<04:23, 20.09it/s, v_num=0, train_loss=0.548] \n",
      "Epoch 0:  16%|█▋        | 1039/6336 [00:51<04:22, 20.15it/s, v_num=0, train_loss=0.0769]\n",
      "Epoch 0:  16%|█▋        | 1045/6336 [00:51<04:21, 20.22it/s, v_num=0, train_loss=0.0438]\n",
      "Epoch 0:  17%|█▋        | 1046/6336 [00:51<04:21, 20.23it/s, v_num=0, train_loss=0.493] \n",
      "Epoch 0:  17%|█▋        | 1051/6336 [00:51<04:20, 20.30it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  17%|█▋        | 1052/6336 [00:51<04:20, 20.30it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  17%|█▋        | 1058/6336 [00:51<04:19, 20.38it/s, v_num=0, train_loss=0.384] \n",
      "Epoch 0:  17%|█▋        | 1064/6336 [00:52<04:17, 20.45it/s, v_num=0, train_loss=0.0943]\n",
      "Epoch 0:  17%|█▋        | 1065/6336 [00:52<04:17, 20.46it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  17%|█▋        | 1070/6336 [00:52<04:16, 20.52it/s, v_num=0, train_loss=0.271] \n",
      "Epoch 0:  17%|█▋        | 1076/6336 [00:52<04:15, 20.58it/s, v_num=0, train_loss=0.0576]\n",
      "Epoch 0:  17%|█▋        | 1081/6336 [00:52<04:14, 20.64it/s, v_num=0, train_loss=0.0865]\n",
      "Epoch 0:  17%|█▋        | 1082/6336 [00:52<04:14, 20.65it/s, v_num=0, train_loss=0.286] \n",
      "Epoch 0:  17%|█▋        | 1087/6336 [00:52<04:13, 20.71it/s, v_num=0, train_loss=0.0903] \n",
      "Epoch 0:  17%|█▋        | 1088/6336 [00:52<04:13, 20.72it/s, v_num=0, train_loss=0.0923]\n",
      "Epoch 0:  17%|█▋        | 1089/6336 [00:52<04:13, 20.73it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  17%|█▋        | 1095/6336 [00:52<04:11, 20.80it/s, v_num=0, train_loss=0.0391]\n",
      "Epoch 0:  17%|█▋        | 1101/6336 [00:52<04:10, 20.87it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  17%|█▋        | 1106/6336 [00:52<04:10, 20.91it/s, v_num=0, train_loss=0.321] \n",
      "Epoch 0:  18%|█▊        | 1111/6336 [00:53<04:09, 20.96it/s, v_num=0, train_loss=0.0962]\n",
      "Epoch 0:  18%|█▊        | 1118/6336 [00:53<04:07, 21.05it/s, v_num=0, train_loss=0.323] \n",
      "Epoch 0:  18%|█▊        | 1122/6336 [00:53<04:07, 21.07it/s, v_num=0, train_loss=0.0652]\n",
      "Epoch 0:  18%|█▊        | 1127/6336 [00:53<04:06, 21.13it/s, v_num=0, train_loss=0.0686]\n",
      "Epoch 0:  18%|█▊        | 1128/6336 [00:53<04:06, 21.14it/s, v_num=0, train_loss=0.232] \n",
      "Epoch 0:  18%|█▊        | 1132/6336 [00:53<04:05, 21.17it/s, v_num=0, train_loss=0.0494]\n",
      "Epoch 0:  18%|█▊        | 1133/6336 [00:53<04:05, 21.18it/s, v_num=0, train_loss=0.0481]\n",
      "Epoch 0:  18%|█▊        | 1139/6336 [00:53<04:04, 21.24it/s, v_num=0, train_loss=0.224] \n",
      "Epoch 0:  18%|█▊        | 1143/6336 [00:53<04:04, 21.28it/s, v_num=0, train_loss=0.0771]\n",
      "Epoch 0:  18%|█▊        | 1147/6336 [00:53<04:03, 21.31it/s, v_num=0, train_loss=0.0575]\n",
      "Epoch 0:  18%|█▊        | 1148/6336 [00:53<04:03, 21.32it/s, v_num=0, train_loss=0.0508]\n",
      "Epoch 0:  18%|█▊        | 1151/6336 [00:53<04:03, 21.34it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  18%|█▊        | 1152/6336 [00:53<04:02, 21.34it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  18%|█▊        | 1153/6336 [00:56<04:15, 20.28it/s, v_num=0, train_loss=0.0464]\n",
      "Epoch 0:  18%|█▊        | 1154/6336 [00:57<04:18, 20.05it/s, v_num=0, train_loss=0.0851]\n",
      "Epoch 0:  18%|█▊        | 1162/6336 [00:57<04:16, 20.14it/s, v_num=0, train_loss=0.055] \n",
      "Epoch 0:  18%|█▊        | 1168/6336 [00:57<04:15, 20.20it/s, v_num=0, train_loss=0.090] \n",
      "Epoch 0:  18%|█▊        | 1169/6336 [00:57<04:15, 20.21it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  19%|█▊        | 1177/6336 [00:57<04:13, 20.31it/s, v_num=0, train_loss=0.0726]\n",
      "Epoch 0:  19%|█▊        | 1184/6336 [00:58<04:12, 20.39it/s, v_num=0, train_loss=0.480] \n",
      "Epoch 0:  19%|█▉        | 1191/6336 [00:58<04:11, 20.47it/s, v_num=0, train_loss=0.0243]\n",
      "Epoch 0:  19%|█▉        | 1192/6336 [00:58<04:11, 20.49it/s, v_num=0, train_loss=0.0647]\n",
      "Epoch 0:  19%|█▉        | 1200/6336 [00:58<04:09, 20.58it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  19%|█▉        | 1206/6336 [00:58<04:08, 20.64it/s, v_num=0, train_loss=0.086] \n",
      "Epoch 0:  19%|█▉        | 1211/6336 [00:58<04:07, 20.69it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  19%|█▉        | 1212/6336 [00:58<04:07, 20.70it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  19%|█▉        | 1217/6336 [00:58<04:06, 20.74it/s, v_num=0, train_loss=0.0769]\n",
      "Epoch 0:  19%|█▉        | 1224/6336 [00:58<04:05, 20.82it/s, v_num=0, train_loss=0.220] \n",
      "Epoch 0:  19%|█▉        | 1230/6336 [00:58<04:04, 20.88it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  20%|█▉        | 1236/6336 [00:59<04:03, 20.94it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  20%|█▉        | 1240/6336 [00:59<04:03, 20.97it/s, v_num=0, train_loss=0.0486]\n",
      "Epoch 0:  20%|█▉        | 1241/6336 [00:59<04:02, 20.98it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  20%|█▉        | 1247/6336 [00:59<04:01, 21.04it/s, v_num=0, train_loss=0.233] \n",
      "Epoch 0:  20%|█▉        | 1252/6336 [00:59<04:01, 21.08it/s, v_num=0, train_loss=0.0471]\n",
      "Epoch 0:  20%|█▉        | 1253/6336 [00:59<04:00, 21.09it/s, v_num=0, train_loss=0.177] \n",
      "Epoch 0:  20%|█▉        | 1258/6336 [00:59<04:00, 21.14it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  20%|█▉        | 1259/6336 [00:59<04:00, 21.15it/s, v_num=0, train_loss=0.271]\n",
      "Epoch 0:  20%|█▉        | 1264/6336 [00:59<03:59, 21.19it/s, v_num=0, train_loss=0.0303]\n",
      "Epoch 0:  20%|██        | 1271/6336 [00:59<03:58, 21.27it/s, v_num=0, train_loss=0.335] \n",
      "Epoch 0:  20%|██        | 1272/6336 [00:59<03:57, 21.28it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  20%|██        | 1276/6336 [00:59<03:57, 21.31it/s, v_num=0, train_loss=0.0529]\n",
      "Epoch 0:  20%|██        | 1277/6336 [00:59<03:57, 21.32it/s, v_num=0, train_loss=0.0423]\n",
      "Epoch 0:  20%|██        | 1284/6336 [01:00<03:56, 21.39it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  20%|██        | 1289/6336 [01:00<03:55, 21.43it/s, v_num=0, train_loss=0.0542]\n",
      "Epoch 0:  20%|██        | 1296/6336 [01:00<03:54, 21.51it/s, v_num=0, train_loss=0.0578]\n",
      "Epoch 0:  21%|██        | 1302/6336 [01:00<03:53, 21.56it/s, v_num=0, train_loss=0.361] \n",
      "Epoch 0:  21%|██        | 1307/6336 [01:00<03:52, 21.60it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  21%|██        | 1312/6336 [01:00<03:52, 21.64it/s, v_num=0, train_loss=0.0609]\n",
      "Epoch 0:  21%|██        | 1318/6336 [01:00<03:51, 21.70it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  21%|██        | 1324/6336 [01:00<03:50, 21.76it/s, v_num=0, train_loss=0.0924]\n",
      "Epoch 0:  21%|██        | 1331/6336 [01:00<03:49, 21.83it/s, v_num=0, train_loss=0.190] \n",
      "Epoch 0:  21%|██        | 1337/6336 [01:01<03:48, 21.88it/s, v_num=0, train_loss=0.0977]\n",
      "Epoch 0:  21%|██        | 1343/6336 [01:01<03:47, 21.94it/s, v_num=0, train_loss=0.234] \n",
      "Epoch 0:  21%|██▏       | 1348/6336 [01:01<03:46, 21.98it/s, v_num=0, train_loss=0.0327]\n",
      "Epoch 0:  21%|██▏       | 1349/6336 [01:01<03:46, 21.99it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  21%|██▏       | 1355/6336 [01:01<03:45, 22.05it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  21%|██▏       | 1361/6336 [01:01<03:45, 22.10it/s, v_num=0, train_loss=0.0912]\n",
      "Epoch 0:  22%|██▏       | 1367/6336 [01:01<03:44, 22.16it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  22%|██▏       | 1368/6336 [01:01<03:44, 22.17it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  22%|██▏       | 1374/6336 [01:01<03:43, 22.22it/s, v_num=0, train_loss=0.0783]\n",
      "Epoch 0:  22%|██▏       | 1380/6336 [01:01<03:42, 22.28it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  22%|██▏       | 1387/6336 [01:02<03:41, 22.35it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  22%|██▏       | 1393/6336 [01:02<03:40, 22.40it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  22%|██▏       | 1394/6336 [01:02<03:40, 22.41it/s, v_num=0, train_loss=0.0294]\n",
      "Epoch 0:  22%|██▏       | 1401/6336 [01:02<03:39, 22.48it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  22%|██▏       | 1407/6336 [01:02<03:38, 22.54it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  22%|██▏       | 1408/6336 [01:02<03:38, 22.55it/s, v_num=0, train_loss=0.209]\n",
      "Epoch 0:  22%|██▏       | 1414/6336 [01:02<03:37, 22.61it/s, v_num=0, train_loss=0.203] \n",
      "Epoch 0:  22%|██▏       | 1415/6336 [01:02<03:37, 22.62it/s, v_num=0, train_loss=0.058]\n",
      "Epoch 0:  22%|██▏       | 1416/6336 [01:02<03:37, 22.63it/s, v_num=0, train_loss=0.270]\n",
      "Epoch 0:  22%|██▏       | 1421/6336 [01:02<03:36, 22.67it/s, v_num=0, train_loss=0.0989]\n",
      "Epoch 0:  23%|██▎       | 1428/6336 [01:02<03:35, 22.73it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:  23%|██▎       | 1429/6336 [01:02<03:35, 22.74it/s, v_num=0, train_loss=0.091]\n",
      "Epoch 0:  23%|██▎       | 1435/6336 [01:02<03:34, 22.80it/s, v_num=0, train_loss=0.193] \n",
      "Epoch 0:  23%|██▎       | 1440/6336 [01:03<03:34, 22.84it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  23%|██▎       | 1441/6336 [01:03<03:34, 22.84it/s, v_num=0, train_loss=0.0904]\n",
      "Epoch 0:  23%|██▎       | 1447/6336 [01:03<03:33, 22.90it/s, v_num=0, train_loss=0.0611]\n",
      "Epoch 0:  23%|██▎       | 1453/6336 [01:03<03:32, 22.96it/s, v_num=0, train_loss=0.0814]\n",
      "Epoch 0:  23%|██▎       | 1460/6336 [01:03<03:31, 23.02it/s, v_num=0, train_loss=0.279] \n",
      "Epoch 0:  23%|██▎       | 1466/6336 [01:03<03:31, 23.07it/s, v_num=0, train_loss=0.0604]\n",
      "Epoch 0:  23%|██▎       | 1471/6336 [01:03<03:30, 23.11it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  23%|██▎       | 1472/6336 [01:03<03:30, 23.12it/s, v_num=0, train_loss=0.198]\n",
      "Epoch 0:  23%|██▎       | 1478/6336 [01:03<03:29, 23.18it/s, v_num=0, train_loss=0.0275]\n",
      "Epoch 0:  23%|██▎       | 1479/6336 [01:03<03:29, 23.18it/s, v_num=0, train_loss=0.189] \n",
      "Epoch 0:  23%|██▎       | 1484/6336 [01:03<03:28, 23.22it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  23%|██▎       | 1488/6336 [01:04<03:28, 23.25it/s, v_num=0, train_loss=0.0918]\n",
      "Epoch 0:  24%|██▎       | 1489/6336 [01:04<03:28, 23.25it/s, v_num=0, train_loss=0.0868]\n",
      "Epoch 0:  24%|██▎       | 1494/6336 [01:04<03:27, 23.29it/s, v_num=0, train_loss=0.0684]\n",
      "Epoch 0:  24%|██▎       | 1501/6336 [01:04<03:27, 23.35it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  24%|██▍       | 1506/6336 [01:04<03:26, 23.39it/s, v_num=0, train_loss=0.0441]\n",
      "Epoch 0:  24%|██▍       | 1506/6336 [01:04<03:26, 23.39it/s, v_num=0, train_loss=0.0222]\n",
      "Epoch 0:  24%|██▍       | 1507/6336 [01:04<03:26, 23.40it/s, v_num=0, train_loss=0.327] \n",
      "Epoch 0:  24%|██▍       | 1513/6336 [01:04<03:25, 23.45it/s, v_num=0, train_loss=0.038] \n",
      "Epoch 0:  24%|██▍       | 1519/6336 [01:04<03:24, 23.50it/s, v_num=0, train_loss=0.320] \n",
      "Epoch 0:  24%|██▍       | 1520/6336 [01:04<03:24, 23.51it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  24%|██▍       | 1524/6336 [01:04<03:24, 23.53it/s, v_num=0, train_loss=0.0158]\n",
      "Epoch 0:  24%|██▍       | 1525/6336 [01:04<03:24, 23.54it/s, v_num=0, train_loss=0.0647]\n",
      "Epoch 0:  24%|██▍       | 1528/6336 [01:04<03:24, 23.55it/s, v_num=0, train_loss=0.316] \n",
      "Epoch 0:  24%|██▍       | 1529/6336 [01:04<03:24, 23.55it/s, v_num=0, train_loss=0.0608]\n",
      "Epoch 0:  24%|██▍       | 1533/6336 [01:05<03:23, 23.57it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  24%|██▍       | 1534/6336 [01:05<03:23, 23.58it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  24%|██▍       | 1536/6336 [01:05<03:23, 23.59it/s, v_num=0, train_loss=0.0487]\n",
      "Epoch 0:  24%|██▍       | 1537/6336 [01:07<03:31, 22.68it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  24%|██▍       | 1538/6336 [01:08<03:32, 22.53it/s, v_num=0, train_loss=0.141]\n",
      "Epoch 0:  24%|██▍       | 1545/6336 [01:08<03:33, 22.44it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  24%|██▍       | 1546/6336 [01:08<03:33, 22.45it/s, v_num=0, train_loss=0.0877]\n",
      "Epoch 0:  24%|██▍       | 1552/6336 [01:08<03:32, 22.50it/s, v_num=0, train_loss=0.075] \n",
      "Epoch 0:  25%|██▍       | 1553/6336 [01:08<03:32, 22.51it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  25%|██▍       | 1562/6336 [01:09<03:31, 22.61it/s, v_num=0, train_loss=0.0712]\n",
      "Epoch 0:  25%|██▍       | 1571/6336 [01:09<03:29, 22.70it/s, v_num=0, train_loss=0.0811]\n",
      "Epoch 0:  25%|██▍       | 1572/6336 [01:09<03:29, 22.71it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  25%|██▍       | 1573/6336 [01:09<03:29, 22.72it/s, v_num=0, train_loss=0.346]\n",
      "Epoch 0:  25%|██▍       | 1581/6336 [01:09<03:28, 22.79it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  25%|██▌       | 1588/6336 [01:09<03:27, 22.86it/s, v_num=0, train_loss=0.326] \n",
      "Epoch 0:  25%|██▌       | 1589/6336 [01:09<03:27, 22.87it/s, v_num=0, train_loss=0.0146]\n",
      "Epoch 0:  25%|██▌       | 1595/6336 [01:09<03:26, 22.92it/s, v_num=0, train_loss=0.0689]\n",
      "Epoch 0:  25%|██▌       | 1596/6336 [01:09<03:26, 22.93it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  25%|██▌       | 1601/6336 [01:09<03:26, 22.97it/s, v_num=0, train_loss=0.0577] \n",
      "Epoch 0:  25%|██▌       | 1602/6336 [01:09<03:26, 22.97it/s, v_num=0, train_loss=0.0338]\n",
      "Epoch 0:  25%|██▌       | 1608/6336 [01:09<03:25, 23.02it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  25%|██▌       | 1613/6336 [01:09<03:24, 23.06it/s, v_num=0, train_loss=0.0889]\n",
      "Epoch 0:  26%|██▌       | 1621/6336 [01:10<03:23, 23.13it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  26%|██▌       | 1627/6336 [01:10<03:23, 23.18it/s, v_num=0, train_loss=0.368] \n",
      "Epoch 0:  26%|██▌       | 1632/6336 [01:10<03:22, 23.21it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  26%|██▌       | 1639/6336 [01:10<03:21, 23.27it/s, v_num=0, train_loss=0.468] \n",
      "Epoch 0:  26%|██▌       | 1640/6336 [01:10<03:21, 23.28it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  26%|██▌       | 1646/6336 [01:10<03:21, 23.33it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  26%|██▌       | 1653/6336 [01:10<03:20, 23.39it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  26%|██▌       | 1659/6336 [01:10<03:19, 23.43it/s, v_num=0, train_loss=0.0392]\n",
      "Epoch 0:  26%|██▌       | 1660/6336 [01:10<03:19, 23.44it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  26%|██▋       | 1666/6336 [01:10<03:18, 23.49it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  26%|██▋       | 1667/6336 [01:10<03:18, 23.50it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  26%|██▋       | 1672/6336 [01:11<03:18, 23.54it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  26%|██▋       | 1673/6336 [01:11<03:18, 23.54it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  26%|██▋       | 1679/6336 [01:11<03:17, 23.59it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  27%|██▋       | 1685/6336 [01:11<03:16, 23.64it/s, v_num=0, train_loss=0.0813]\n",
      "Epoch 0:  27%|██▋       | 1686/6336 [01:11<03:16, 23.64it/s, v_num=0, train_loss=0.0799]\n",
      "Epoch 0:  27%|██▋       | 1693/6336 [01:11<03:15, 23.71it/s, v_num=0, train_loss=0.084] \n",
      "Epoch 0:  27%|██▋       | 1699/6336 [01:11<03:15, 23.75it/s, v_num=0, train_loss=0.732] \n",
      "Epoch 0:  27%|██▋       | 1700/6336 [01:11<03:15, 23.76it/s, v_num=0, train_loss=0.217]\n",
      "Epoch 0:  27%|██▋       | 1706/6336 [01:11<03:14, 23.81it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  27%|██▋       | 1712/6336 [01:11<03:13, 23.86it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  27%|██▋       | 1713/6336 [01:11<03:13, 23.86it/s, v_num=0, train_loss=0.0914]\n",
      "Epoch 0:  27%|██▋       | 1718/6336 [01:11<03:13, 23.90it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  27%|██▋       | 1719/6336 [01:11<03:13, 23.91it/s, v_num=0, train_loss=0.0199]\n",
      "Epoch 0:  27%|██▋       | 1726/6336 [01:12<03:12, 23.97it/s, v_num=0, train_loss=0.0863]\n",
      "Epoch 0:  27%|██▋       | 1727/6336 [01:12<03:12, 23.98it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  27%|██▋       | 1733/6336 [01:12<03:11, 24.02it/s, v_num=0, train_loss=0.190] \n",
      "Epoch 0:  27%|██▋       | 1740/6336 [01:12<03:10, 24.08it/s, v_num=0, train_loss=0.051] \n",
      "Epoch 0:  27%|██▋       | 1741/6336 [01:12<03:10, 24.09it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  27%|██▋       | 1742/6336 [01:12<03:10, 24.10it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  28%|██▊       | 1748/6336 [01:12<03:10, 24.14it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  28%|██▊       | 1754/6336 [01:12<03:09, 24.19it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  28%|██▊       | 1761/6336 [01:12<03:08, 24.24it/s, v_num=0, train_loss=0.0867]\n",
      "Epoch 0:  28%|██▊       | 1762/6336 [01:12<03:08, 24.25it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  28%|██▊       | 1768/6336 [01:12<03:08, 24.30it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  28%|██▊       | 1769/6336 [01:12<03:07, 24.31it/s, v_num=0, train_loss=0.0913]\n",
      "Epoch 0:  28%|██▊       | 1774/6336 [01:12<03:07, 24.34it/s, v_num=0, train_loss=0.180] \n",
      "Epoch 0:  28%|██▊       | 1780/6336 [01:13<03:06, 24.38it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  28%|██▊       | 1786/6336 [01:13<03:06, 24.42it/s, v_num=0, train_loss=0.259] \n",
      "Epoch 0:  28%|██▊       | 1792/6336 [01:13<03:05, 24.46it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  28%|██▊       | 1793/6336 [01:13<03:05, 24.47it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  28%|██▊       | 1793/6336 [01:13<03:05, 24.47it/s, v_num=0, train_loss=0.108]\n",
      "Epoch 0:  28%|██▊       | 1799/6336 [01:13<03:05, 24.52it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  28%|██▊       | 1805/6336 [01:13<03:04, 24.56it/s, v_num=0, train_loss=0.0469]\n",
      "Epoch 0:  29%|██▊       | 1813/6336 [01:13<03:03, 24.63it/s, v_num=0, train_loss=0.0461]\n",
      "Epoch 0:  29%|██▊       | 1820/6336 [01:13<03:02, 24.68it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  29%|██▊       | 1821/6336 [01:13<03:02, 24.69it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  29%|██▊       | 1821/6336 [01:13<03:02, 24.69it/s, v_num=0, train_loss=0.0355]\n",
      "Epoch 0:  29%|██▉       | 1826/6336 [01:13<03:02, 24.72it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  29%|██▉       | 1827/6336 [01:13<03:02, 24.73it/s, v_num=0, train_loss=0.0689]\n",
      "Epoch 0:  29%|██▉       | 1828/6336 [01:13<03:02, 24.74it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  29%|██▉       | 1834/6336 [01:13<03:01, 24.79it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  29%|██▉       | 1835/6336 [01:14<03:01, 24.79it/s, v_num=0, train_loss=0.0978]\n",
      "Epoch 0:  29%|██▉       | 1840/6336 [01:14<03:01, 24.83it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  29%|██▉       | 1846/6336 [01:14<03:00, 24.87it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  29%|██▉       | 1847/6336 [01:14<03:00, 24.88it/s, v_num=0, train_loss=0.0667]\n",
      "Epoch 0:  29%|██▉       | 1853/6336 [01:14<02:59, 24.92it/s, v_num=0, train_loss=0.0661]\n",
      "Epoch 0:  29%|██▉       | 1859/6336 [01:14<02:59, 24.96it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  29%|██▉       | 1860/6336 [01:14<02:59, 24.97it/s, v_num=0, train_loss=0.0802]\n",
      "Epoch 0:  29%|██▉       | 1866/6336 [01:14<02:58, 25.01it/s, v_num=0, train_loss=0.0918]\n",
      "Epoch 0:  29%|██▉       | 1867/6336 [01:14<02:58, 25.02it/s, v_num=0, train_loss=0.823] \n",
      "Epoch 0:  30%|██▉       | 1873/6336 [01:14<02:58, 25.06it/s, v_num=0, train_loss=0.0769]\n",
      "Epoch 0:  30%|██▉       | 1878/6336 [01:14<02:57, 25.09it/s, v_num=0, train_loss=0.0842]\n",
      "Epoch 0:  30%|██▉       | 1879/6336 [01:14<02:57, 25.10it/s, v_num=0, train_loss=0.513] \n",
      "Epoch 0:  30%|██▉       | 1885/6336 [01:14<02:57, 25.14it/s, v_num=0, train_loss=0.0796]\n",
      "Epoch 0:  30%|██▉       | 1889/6336 [01:15<02:56, 25.16it/s, v_num=0, train_loss=0.0393]\n",
      "Epoch 0:  30%|██▉       | 1894/6336 [01:15<02:56, 25.19it/s, v_num=0, train_loss=0.272] \n",
      "Epoch 0:  30%|██▉       | 1895/6336 [01:15<02:56, 25.19it/s, v_num=0, train_loss=0.221]\n",
      "Epoch 0:  30%|██▉       | 1899/6336 [01:15<02:56, 25.20it/s, v_num=0, train_loss=0.0956]\n",
      "Epoch 0:  30%|███       | 1904/6336 [01:15<02:55, 25.23it/s, v_num=0, train_loss=0.0427]\n",
      "Epoch 0:  30%|███       | 1910/6336 [01:15<02:55, 25.27it/s, v_num=0, train_loss=0.282] \n",
      "Epoch 0:  30%|███       | 1915/6336 [01:15<02:54, 25.30it/s, v_num=0, train_loss=0.355] \n",
      "Epoch 0:  30%|███       | 1916/6336 [01:15<02:54, 25.30it/s, v_num=0, train_loss=0.0174]\n",
      "Epoch 0:  30%|███       | 1920/6336 [01:15<02:54, 25.32it/s, v_num=0, train_loss=0.0355]\n",
      "Epoch 0:  30%|███       | 1921/6336 [01:17<02:59, 24.64it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  30%|███       | 1922/6336 [01:19<03:01, 24.31it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  30%|███       | 1923/6336 [01:19<03:02, 24.24it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  30%|███       | 1930/6336 [01:20<03:03, 24.03it/s, v_num=0, train_loss=0.0516]\n",
      "Epoch 0:  31%|███       | 1937/6336 [01:20<03:02, 24.08it/s, v_num=0, train_loss=0.511] \n",
      "Epoch 0:  31%|███       | 1945/6336 [01:20<03:01, 24.15it/s, v_num=0, train_loss=0.309] \n",
      "Epoch 0:  31%|███       | 1953/6336 [01:20<03:01, 24.21it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  31%|███       | 1961/6336 [01:20<03:00, 24.27it/s, v_num=0, train_loss=0.275]  \n",
      "Epoch 0:  31%|███       | 1969/6336 [01:20<02:59, 24.34it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:  31%|███       | 1975/6336 [01:21<02:58, 24.38it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  31%|███       | 1976/6336 [01:21<02:58, 24.38it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  31%|███▏      | 1981/6336 [01:21<02:58, 24.42it/s, v_num=0, train_loss=0.214]\n",
      "Epoch 0:  31%|███▏      | 1982/6336 [01:21<02:58, 24.42it/s, v_num=0, train_loss=0.225]\n",
      "Epoch 0:  31%|███▏      | 1988/6336 [01:21<02:57, 24.46it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  31%|███▏      | 1994/6336 [01:21<02:57, 24.50it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  32%|███▏      | 1999/6336 [01:21<02:56, 24.53it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  32%|███▏      | 2000/6336 [01:21<02:56, 24.53it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  32%|███▏      | 2006/6336 [01:21<02:56, 24.57it/s, v_num=0, train_loss=0.257]\n",
      "Epoch 0:  32%|███▏      | 2012/6336 [01:21<02:55, 24.61it/s, v_num=0, train_loss=0.0955] \n",
      "Epoch 0:  32%|███▏      | 2013/6336 [01:21<02:55, 24.62it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  32%|███▏      | 2014/6336 [01:21<02:55, 24.63it/s, v_num=0, train_loss=0.302]\n",
      "Epoch 0:  32%|███▏      | 2019/6336 [01:21<02:55, 24.66it/s, v_num=0, train_loss=0.0715]\n",
      "Epoch 0:  32%|███▏      | 2025/6336 [01:22<02:54, 24.69it/s, v_num=0, train_loss=0.085] \n",
      "Epoch 0:  32%|███▏      | 2026/6336 [01:22<02:54, 24.70it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  32%|███▏      | 2032/6336 [01:22<02:53, 24.74it/s, v_num=0, train_loss=0.00122]\n",
      "Epoch 0:  32%|███▏      | 2033/6336 [01:22<02:53, 24.74it/s, v_num=0, train_loss=0.235]  \n",
      "Epoch 0:  32%|███▏      | 2039/6336 [01:22<02:53, 24.78it/s, v_num=0, train_loss=0.381] \n",
      "Epoch 0:  32%|███▏      | 2045/6336 [01:22<02:52, 24.82it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  32%|███▏      | 2051/6336 [01:22<02:52, 24.86it/s, v_num=0, train_loss=0.473] \n",
      "Epoch 0:  32%|███▏      | 2052/6336 [01:22<02:52, 24.87it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  32%|███▏      | 2058/6336 [01:22<02:51, 24.90it/s, v_num=0, train_loss=0.0242]\n",
      "Epoch 0:  32%|███▏      | 2059/6336 [01:22<02:51, 24.91it/s, v_num=0, train_loss=0.0726]\n",
      "Epoch 0:  33%|███▎      | 2065/6336 [01:22<02:51, 24.95it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  33%|███▎      | 2072/6336 [01:22<02:50, 25.00it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  33%|███▎      | 2079/6336 [01:22<02:49, 25.05it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  33%|███▎      | 2086/6336 [01:23<02:49, 25.10it/s, v_num=0, train_loss=0.0613]\n",
      "Epoch 0:  33%|███▎      | 2087/6336 [01:23<02:49, 25.10it/s, v_num=0, train_loss=0.195] \n",
      "Epoch 0:  33%|███▎      | 2094/6336 [01:23<02:48, 25.16it/s, v_num=0, train_loss=0.0138]\n",
      "Epoch 0:  33%|███▎      | 2095/6336 [01:23<02:48, 25.16it/s, v_num=0, train_loss=0.270] \n",
      "Epoch 0:  33%|███▎      | 2103/6336 [01:23<02:47, 25.23it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  33%|███▎      | 2109/6336 [01:23<02:47, 25.27it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  33%|███▎      | 2110/6336 [01:23<02:47, 25.27it/s, v_num=0, train_loss=0.0705]\n",
      "Epoch 0:  33%|███▎      | 2116/6336 [01:23<02:46, 25.31it/s, v_num=0, train_loss=0.025] \n",
      "Epoch 0:  33%|███▎      | 2121/6336 [01:23<02:46, 25.33it/s, v_num=0, train_loss=0.0783]\n",
      "Epoch 0:  33%|███▎      | 2122/6336 [01:23<02:46, 25.34it/s, v_num=0, train_loss=0.0412]\n",
      "Epoch 0:  34%|███▎      | 2129/6336 [01:23<02:45, 25.39it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:  34%|███▎      | 2135/6336 [01:23<02:45, 25.42it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  34%|███▍      | 2140/6336 [01:24<02:44, 25.45it/s, v_num=0, train_loss=0.0721]\n",
      "Epoch 0:  34%|███▍      | 2141/6336 [01:24<02:44, 25.45it/s, v_num=0, train_loss=0.177] \n",
      "Epoch 0:  34%|███▍      | 2148/6336 [01:24<02:44, 25.50it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  34%|███▍      | 2149/6336 [01:24<02:44, 25.51it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  34%|███▍      | 2149/6336 [01:24<02:44, 25.51it/s, v_num=0, train_loss=0.392]\n",
      "Epoch 0:  34%|███▍      | 2154/6336 [01:24<02:43, 25.54it/s, v_num=0, train_loss=0.0631]\n",
      "Epoch 0:  34%|███▍      | 2155/6336 [01:24<02:43, 25.54it/s, v_num=0, train_loss=0.166] \n",
      "Epoch 0:  34%|███▍      | 2161/6336 [01:24<02:43, 25.58it/s, v_num=0, train_loss=0.297] \n",
      "Epoch 0:  34%|███▍      | 2167/6336 [01:24<02:42, 25.62it/s, v_num=0, train_loss=0.223] \n",
      "Epoch 0:  34%|███▍      | 2172/6336 [01:24<02:42, 25.64it/s, v_num=0, train_loss=0.188] \n",
      "Epoch 0:  34%|███▍      | 2173/6336 [01:24<02:42, 25.65it/s, v_num=0, train_loss=0.201]\n",
      "Epoch 0:  34%|███▍      | 2178/6336 [01:24<02:41, 25.68it/s, v_num=0, train_loss=0.0591]\n",
      "Epoch 0:  34%|███▍      | 2179/6336 [01:24<02:41, 25.68it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  35%|███▍      | 2186/6336 [01:24<02:41, 25.73it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  35%|███▍      | 2192/6336 [01:25<02:40, 25.76it/s, v_num=0, train_loss=0.0717]\n",
      "Epoch 0:  35%|███▍      | 2193/6336 [01:25<02:40, 25.77it/s, v_num=0, train_loss=0.0512]\n",
      "Epoch 0:  35%|███▍      | 2199/6336 [01:25<02:40, 25.81it/s, v_num=0, train_loss=0.0289]\n",
      "Epoch 0:  35%|███▍      | 2204/6336 [01:25<02:39, 25.84it/s, v_num=0, train_loss=0.0629]\n",
      "Epoch 0:  35%|███▍      | 2205/6336 [01:25<02:39, 25.84it/s, v_num=0, train_loss=0.063] \n",
      "Epoch 0:  35%|███▍      | 2210/6336 [01:25<02:39, 25.87it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  35%|███▍      | 2211/6336 [01:25<02:39, 25.87it/s, v_num=0, train_loss=0.045]\n",
      "Epoch 0:  35%|███▍      | 2216/6336 [01:25<02:39, 25.90it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  35%|███▌      | 2221/6336 [01:25<02:38, 25.92it/s, v_num=0, train_loss=0.0823]\n",
      "Epoch 0:  35%|███▌      | 2222/6336 [01:25<02:38, 25.93it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  35%|███▌      | 2227/6336 [01:25<02:38, 25.95it/s, v_num=0, train_loss=0.0948] \n",
      "Epoch 0:  35%|███▌      | 2232/6336 [01:25<02:38, 25.97it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  35%|███▌      | 2237/6336 [01:26<02:37, 26.00it/s, v_num=0, train_loss=0.0726]\n",
      "Epoch 0:  35%|███▌      | 2238/6336 [01:26<02:37, 26.01it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  35%|███▌      | 2244/6336 [01:26<02:37, 26.04it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  35%|███▌      | 2245/6336 [01:26<02:37, 26.05it/s, v_num=0, train_loss=0.0858]\n",
      "Epoch 0:  36%|███▌      | 2251/6336 [01:26<02:36, 26.09it/s, v_num=0, train_loss=0.0435]\n",
      "Epoch 0:  36%|███▌      | 2256/6336 [01:26<02:36, 26.11it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  36%|███▌      | 2257/6336 [01:26<02:36, 26.12it/s, v_num=0, train_loss=0.0771]\n",
      "Epoch 0:  36%|███▌      | 2263/6336 [01:26<02:35, 26.15it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  36%|███▌      | 2268/6336 [01:26<02:35, 26.18it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  36%|███▌      | 2269/6336 [01:26<02:35, 26.18it/s, v_num=0, train_loss=0.089]\n",
      "Epoch 0:  36%|███▌      | 2272/6336 [01:26<02:35, 26.19it/s, v_num=0, train_loss=0.0238]\n",
      "Epoch 0:  36%|███▌      | 2273/6336 [01:26<02:35, 26.19it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  36%|███▌      | 2277/6336 [01:26<02:34, 26.21it/s, v_num=0, train_loss=0.0671]\n",
      "Epoch 0:  36%|███▌      | 2278/6336 [01:26<02:34, 26.21it/s, v_num=0, train_loss=0.0532]\n",
      "Epoch 0:  36%|███▌      | 2282/6336 [01:27<02:34, 26.22it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  36%|███▌      | 2287/6336 [01:27<02:34, 26.25it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  36%|███▌      | 2288/6336 [01:27<02:34, 26.25it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  36%|███▌      | 2293/6336 [01:27<02:33, 26.28it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  36%|███▋      | 2297/6336 [01:27<02:33, 26.29it/s, v_num=0, train_loss=0.0849]\n",
      "Epoch 0:  36%|███▋      | 2298/6336 [01:27<02:33, 26.29it/s, v_num=0, train_loss=0.0789]\n",
      "Epoch 0:  36%|███▋      | 2303/6336 [01:27<02:33, 26.31it/s, v_num=0, train_loss=0.0962]\n",
      "Epoch 0:  36%|███▋      | 2304/6336 [01:27<02:33, 26.32it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  36%|███▋      | 2305/6336 [01:29<02:35, 25.85it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  36%|███▋      | 2307/6336 [01:30<02:38, 25.45it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  36%|███▋      | 2310/6336 [01:30<02:38, 25.47it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  36%|███▋      | 2311/6336 [01:30<02:38, 25.45it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  36%|███▋      | 2312/6336 [01:31<02:38, 25.31it/s, v_num=0, train_loss=0.041]\n",
      "Epoch 0:  37%|███▋      | 2316/6336 [01:31<02:38, 25.32it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  37%|███▋      | 2323/6336 [01:31<02:38, 25.37it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  37%|███▋      | 2324/6336 [01:31<02:38, 25.38it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  37%|███▋      | 2331/6336 [01:31<02:37, 25.43it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  37%|███▋      | 2332/6336 [01:31<02:37, 25.43it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  37%|███▋      | 2339/6336 [01:31<02:36, 25.48it/s, v_num=0, train_loss=0.0402]\n",
      "Epoch 0:  37%|███▋      | 2347/6336 [01:31<02:36, 25.54it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  37%|███▋      | 2355/6336 [01:32<02:35, 25.59it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  37%|███▋      | 2362/6336 [01:32<02:35, 25.64it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  37%|███▋      | 2370/6336 [01:32<02:34, 25.69it/s, v_num=0, train_loss=0.231] \n",
      "Epoch 0:  38%|███▊      | 2376/6336 [01:32<02:33, 25.72it/s, v_num=0, train_loss=0.252] \n",
      "Epoch 0:  38%|███▊      | 2377/6336 [01:32<02:33, 25.73it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  38%|███▊      | 2384/6336 [01:32<02:33, 25.77it/s, v_num=0, train_loss=0.0349]\n",
      "Epoch 0:  38%|███▊      | 2385/6336 [01:32<02:33, 25.78it/s, v_num=0, train_loss=0.323] \n",
      "Epoch 0:  38%|███▊      | 2391/6336 [01:32<02:32, 25.81it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  38%|███▊      | 2398/6336 [01:32<02:32, 25.86it/s, v_num=0, train_loss=0.051] \n",
      "Epoch 0:  38%|███▊      | 2404/6336 [01:32<02:31, 25.89it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  38%|███▊      | 2405/6336 [01:32<02:31, 25.90it/s, v_num=0, train_loss=0.0899]\n",
      "Epoch 0:  38%|███▊      | 2412/6336 [01:32<02:31, 25.94it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:  38%|███▊      | 2419/6336 [01:33<02:30, 25.98it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  38%|███▊      | 2425/6336 [01:33<02:30, 26.02it/s, v_num=0, train_loss=0.0936]\n",
      "Epoch 0:  38%|███▊      | 2426/6336 [01:33<02:30, 26.02it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  38%|███▊      | 2433/6336 [01:33<02:29, 26.06it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  39%|███▊      | 2440/6336 [01:33<02:29, 26.11it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  39%|███▊      | 2441/6336 [01:33<02:29, 26.11it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  39%|███▊      | 2442/6336 [01:33<02:29, 26.12it/s, v_num=0, train_loss=0.398]\n",
      "Epoch 0:  39%|███▊      | 2448/6336 [01:33<02:28, 26.15it/s, v_num=0, train_loss=0.248] \n",
      "Epoch 0:  39%|███▊      | 2455/6336 [01:33<02:28, 26.20it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  39%|███▉      | 2461/6336 [01:33<02:27, 26.22it/s, v_num=0, train_loss=0.190] \n",
      "Epoch 0:  39%|███▉      | 2468/6336 [01:33<02:27, 26.27it/s, v_num=0, train_loss=0.0122]\n",
      "Epoch 0:  39%|███▉      | 2473/6336 [01:34<02:26, 26.29it/s, v_num=0, train_loss=0.232]  \n",
      "Epoch 0:  39%|███▉      | 2474/6336 [01:34<02:26, 26.29it/s, v_num=0, train_loss=0.0619]\n",
      "Epoch 0:  39%|███▉      | 2479/6336 [01:34<02:26, 26.32it/s, v_num=0, train_loss=0.0956]\n",
      "Epoch 0:  39%|███▉      | 2484/6336 [01:34<02:26, 26.33it/s, v_num=0, train_loss=0.102]  \n",
      "Epoch 0:  39%|███▉      | 2490/6336 [01:34<02:25, 26.37it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  39%|███▉      | 2491/6336 [01:34<02:25, 26.37it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  39%|███▉      | 2497/6336 [01:34<02:25, 26.41it/s, v_num=0, train_loss=0.392]  \n",
      "Epoch 0:  40%|███▉      | 2504/6336 [01:34<02:24, 26.45it/s, v_num=0, train_loss=0.0588]\n",
      "Epoch 0:  40%|███▉      | 2505/6336 [01:34<02:24, 26.45it/s, v_num=0, train_loss=0.201] \n",
      "Epoch 0:  40%|███▉      | 2511/6336 [01:34<02:24, 26.49it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  40%|███▉      | 2512/6336 [01:34<02:24, 26.49it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  40%|███▉      | 2518/6336 [01:34<02:23, 26.52it/s, v_num=0, train_loss=0.0706]\n",
      "Epoch 0:  40%|███▉      | 2524/6336 [01:35<02:23, 26.56it/s, v_num=0, train_loss=0.224] \n",
      "Epoch 0:  40%|███▉      | 2525/6336 [01:35<02:23, 26.56it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  40%|███▉      | 2532/6336 [01:35<02:22, 26.60it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  40%|████      | 2539/6336 [01:35<02:22, 26.65it/s, v_num=0, train_loss=0.059]\n",
      "Epoch 0:  40%|████      | 2545/6336 [01:35<02:22, 26.68it/s, v_num=0, train_loss=0.195]  \n",
      "Epoch 0:  40%|████      | 2551/6336 [01:35<02:21, 26.71it/s, v_num=0, train_loss=0.0603]\n",
      "Epoch 0:  40%|████      | 2557/6336 [01:35<02:21, 26.74it/s, v_num=0, train_loss=0.307] \n",
      "Epoch 0:  40%|████      | 2563/6336 [01:35<02:20, 26.77it/s, v_num=0, train_loss=0.0522]\n",
      "Epoch 0:  41%|████      | 2568/6336 [01:35<02:20, 26.79it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  41%|████      | 2569/6336 [01:35<02:20, 26.80it/s, v_num=0, train_loss=0.289]\n",
      "Epoch 0:  41%|████      | 2575/6336 [01:35<02:20, 26.83it/s, v_num=0, train_loss=0.00657]\n",
      "Epoch 0:  41%|████      | 2576/6336 [01:35<02:20, 26.83it/s, v_num=0, train_loss=0.0128] \n",
      "Epoch 0:  41%|████      | 2584/6336 [01:36<02:19, 26.88it/s, v_num=0, train_loss=0.513] \n",
      "Epoch 0:  41%|████      | 2585/6336 [01:36<02:19, 26.89it/s, v_num=0, train_loss=0.401]\n",
      "Epoch 0:  41%|████      | 2586/6336 [01:36<02:19, 26.90it/s, v_num=0, train_loss=0.320]\n",
      "Epoch 0:  41%|████      | 2592/6336 [01:36<02:19, 26.93it/s, v_num=0, train_loss=0.371]  \n",
      "Epoch 0:  41%|████      | 2598/6336 [01:36<02:18, 26.96it/s, v_num=0, train_loss=0.418] \n",
      "Epoch 0:  41%|████      | 2599/6336 [01:36<02:18, 26.97it/s, v_num=0, train_loss=0.0281]\n",
      "Epoch 0:  41%|████      | 2606/6336 [01:36<02:18, 27.01it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  41%|████      | 2612/6336 [01:36<02:17, 27.04it/s, v_num=0, train_loss=0.0149]\n",
      "Epoch 0:  41%|████      | 2613/6336 [01:36<02:17, 27.05it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  41%|████▏     | 2617/6336 [01:36<02:17, 27.06it/s, v_num=0, train_loss=0.269] \n",
      "Epoch 0:  41%|████▏     | 2618/6336 [01:36<02:17, 27.06it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  41%|████▏     | 2623/6336 [01:36<02:17, 27.08it/s, v_num=0, train_loss=0.0433]\n",
      "Epoch 0:  41%|████▏     | 2628/6336 [01:36<02:16, 27.10it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  41%|████▏     | 2629/6336 [01:36<02:16, 27.11it/s, v_num=0, train_loss=0.0876]\n",
      "Epoch 0:  42%|████▏     | 2635/6336 [01:37<02:16, 27.14it/s, v_num=0, train_loss=0.0643]\n",
      "Epoch 0:  42%|████▏     | 2640/6336 [01:37<02:16, 27.16it/s, v_num=0, train_loss=0.0964]\n",
      "Epoch 0:  42%|████▏     | 2646/6336 [01:37<02:15, 27.19it/s, v_num=0, train_loss=0.303] \n",
      "Epoch 0:  42%|████▏     | 2647/6336 [01:37<02:15, 27.19it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  42%|████▏     | 2652/6336 [01:37<02:15, 27.22it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  42%|████▏     | 2658/6336 [01:37<02:14, 27.25it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:  42%|████▏     | 2662/6336 [01:37<02:14, 27.26it/s, v_num=0, train_loss=0.0305]\n",
      "Epoch 0:  42%|████▏     | 2663/6336 [01:37<02:14, 27.26it/s, v_num=0, train_loss=0.0516]\n",
      "Epoch 0:  42%|████▏     | 2667/6336 [01:37<02:14, 27.27it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  42%|████▏     | 2668/6336 [01:37<02:14, 27.27it/s, v_num=0, train_loss=0.355]\n",
      "Epoch 0:  42%|████▏     | 2672/6336 [01:37<02:14, 27.28it/s, v_num=0, train_loss=0.0629]\n",
      "Epoch 0:  42%|████▏     | 2676/6336 [01:38<02:14, 27.30it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  42%|████▏     | 2677/6336 [01:38<02:14, 27.30it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  42%|████▏     | 2682/6336 [01:38<02:13, 27.32it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  42%|████▏     | 2683/6336 [01:38<02:13, 27.32it/s, v_num=0, train_loss=0.0807]\n",
      "Epoch 0:  42%|████▏     | 2687/6336 [01:38<02:13, 27.34it/s, v_num=0, train_loss=0.214]  \n",
      "Epoch 0:  42%|████▏     | 2688/6336 [01:38<02:13, 27.34it/s, v_num=0, train_loss=0.0464]\n",
      "Epoch 0:  42%|████▏     | 2689/6336 [01:40<02:16, 26.73it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  42%|████▏     | 2690/6336 [01:41<02:17, 26.46it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  42%|████▏     | 2692/6336 [01:42<02:18, 26.36it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  43%|████▎     | 2699/6336 [01:42<02:17, 26.40it/s, v_num=0, train_loss=0.320] \n",
      "Epoch 0:  43%|████▎     | 2700/6336 [01:42<02:17, 26.41it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  43%|████▎     | 2707/6336 [01:42<02:17, 26.45it/s, v_num=0, train_loss=0.0745]\n",
      "Epoch 0:  43%|████▎     | 2714/6336 [01:42<02:16, 26.49it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  43%|████▎     | 2715/6336 [01:42<02:16, 26.50it/s, v_num=0, train_loss=0.0853]\n",
      "Epoch 0:  43%|████▎     | 2722/6336 [01:42<02:16, 26.54it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  43%|████▎     | 2723/6336 [01:42<02:16, 26.55it/s, v_num=0, train_loss=0.433]\n",
      "Epoch 0:  43%|████▎     | 2724/6336 [01:42<02:16, 26.55it/s, v_num=0, train_loss=0.0853]\n",
      "Epoch 0:  43%|████▎     | 2732/6336 [01:42<02:15, 26.60it/s, v_num=0, train_loss=0.383] \n",
      "Epoch 0:  43%|████▎     | 2738/6336 [01:42<02:15, 26.64it/s, v_num=0, train_loss=0.191]  \n",
      "Epoch 0:  43%|████▎     | 2744/6336 [01:42<02:14, 26.66it/s, v_num=0, train_loss=0.541]\n",
      "Epoch 0:  43%|████▎     | 2750/6336 [01:43<02:14, 26.69it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  43%|████▎     | 2756/6336 [01:43<02:13, 26.72it/s, v_num=0, train_loss=0.285] \n",
      "Epoch 0:  44%|████▎     | 2763/6336 [01:43<02:13, 26.75it/s, v_num=0, train_loss=0.0358]\n",
      "Epoch 0:  44%|████▎     | 2764/6336 [01:43<02:13, 26.76it/s, v_num=0, train_loss=0.0508]\n",
      "Epoch 0:  44%|████▎     | 2770/6336 [01:43<02:13, 26.79it/s, v_num=0, train_loss=0.0647]\n",
      "Epoch 0:  44%|████▍     | 2776/6336 [01:43<02:12, 26.81it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  44%|████▍     | 2781/6336 [01:43<02:12, 26.84it/s, v_num=0, train_loss=0.0285]\n",
      "Epoch 0:  44%|████▍     | 2782/6336 [01:43<02:12, 26.84it/s, v_num=0, train_loss=0.0777]\n",
      "Epoch 0:  44%|████▍     | 2788/6336 [01:43<02:12, 26.87it/s, v_num=0, train_loss=0.0751]\n",
      "Epoch 0:  44%|████▍     | 2788/6336 [01:43<02:12, 26.87it/s, v_num=0, train_loss=0.0764]\n",
      "Epoch 0:  44%|████▍     | 2794/6336 [01:43<02:11, 26.89it/s, v_num=0, train_loss=0.0967]\n",
      "Epoch 0:  44%|████▍     | 2794/6336 [01:43<02:11, 26.89it/s, v_num=0, train_loss=0.0741]\n",
      "Epoch 0:  44%|████▍     | 2795/6336 [01:43<02:11, 26.90it/s, v_num=0, train_loss=0.253] \n",
      "Epoch 0:  44%|████▍     | 2801/6336 [01:44<02:11, 26.93it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  44%|████▍     | 2802/6336 [01:44<02:11, 26.94it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  44%|████▍     | 2808/6336 [01:44<02:10, 26.97it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  44%|████▍     | 2809/6336 [01:44<02:10, 26.97it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  44%|████▍     | 2815/6336 [01:44<02:10, 27.00it/s, v_num=0, train_loss=0.0665]\n",
      "Epoch 0:  45%|████▍     | 2822/6336 [01:44<02:09, 27.04it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  45%|████▍     | 2827/6336 [01:44<02:09, 27.06it/s, v_num=0, train_loss=0.0473]\n",
      "Epoch 0:  45%|████▍     | 2828/6336 [01:44<02:09, 27.06it/s, v_num=0, train_loss=0.397] \n",
      "Epoch 0:  45%|████▍     | 2834/6336 [01:44<02:09, 27.09it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  45%|████▍     | 2840/6336 [01:44<02:08, 27.11it/s, v_num=0, train_loss=0.018] \n",
      "Epoch 0:  45%|████▍     | 2840/6336 [01:44<02:08, 27.11it/s, v_num=0, train_loss=0.418]\n",
      "Epoch 0:  45%|████▍     | 2846/6336 [01:44<02:08, 27.14it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  45%|████▍     | 2851/6336 [01:44<02:08, 27.16it/s, v_num=0, train_loss=0.0993]\n",
      "Epoch 0:  45%|████▌     | 2852/6336 [01:44<02:08, 27.16it/s, v_num=0, train_loss=0.395] \n",
      "Epoch 0:  45%|████▌     | 2856/6336 [01:45<02:08, 27.18it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  45%|████▌     | 2857/6336 [01:45<02:08, 27.18it/s, v_num=0, train_loss=0.259]\n",
      "Epoch 0:  45%|████▌     | 2863/6336 [01:45<02:07, 27.21it/s, v_num=0, train_loss=0.0903]\n",
      "Epoch 0:  45%|████▌     | 2869/6336 [01:45<02:07, 27.23it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  45%|████▌     | 2874/6336 [01:45<02:07, 27.26it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  45%|████▌     | 2875/6336 [01:45<02:06, 27.26it/s, v_num=0, train_loss=0.0817]\n",
      "Epoch 0:  45%|████▌     | 2881/6336 [01:45<02:06, 27.29it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  46%|████▌     | 2884/6336 [01:45<02:06, 27.29it/s, v_num=0, train_loss=0.207]  \n",
      "Epoch 0:  46%|████▌     | 2885/6336 [01:45<02:06, 27.29it/s, v_num=0, train_loss=0.041]\n",
      "Epoch 0:  46%|████▌     | 2891/6336 [01:45<02:06, 27.32it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  46%|████▌     | 2897/6336 [01:45<02:05, 27.35it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  46%|████▌     | 2903/6336 [01:46<02:05, 27.37it/s, v_num=0, train_loss=0.182] \n",
      "Epoch 0:  46%|████▌     | 2909/6336 [01:46<02:05, 27.40it/s, v_num=0, train_loss=0.0389]\n",
      "Epoch 0:  46%|████▌     | 2915/6336 [01:46<02:04, 27.43it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  46%|████▌     | 2916/6336 [01:46<02:04, 27.43it/s, v_num=0, train_loss=0.0644]\n",
      "Epoch 0:  46%|████▌     | 2922/6336 [01:46<02:04, 27.46it/s, v_num=0, train_loss=0.0735]\n",
      "Epoch 0:  46%|████▌     | 2929/6336 [01:46<02:03, 27.49it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  46%|████▋     | 2934/6336 [01:46<02:03, 27.51it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  46%|████▋     | 2939/6336 [01:46<02:03, 27.53it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  46%|████▋     | 2944/6336 [01:46<02:03, 27.55it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  46%|████▋     | 2945/6336 [01:46<02:03, 27.55it/s, v_num=0, train_loss=0.0638]\n",
      "Epoch 0:  47%|████▋     | 2951/6336 [01:47<02:02, 27.57it/s, v_num=0, train_loss=0.252] \n",
      "Epoch 0:  47%|████▋     | 2956/6336 [01:47<02:02, 27.59it/s, v_num=0, train_loss=0.0374]\n",
      "Epoch 0:  47%|████▋     | 2960/6336 [01:47<02:02, 27.60it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  47%|████▋     | 2961/6336 [01:47<02:02, 27.61it/s, v_num=0, train_loss=0.041]\n",
      "Epoch 0:  47%|████▋     | 2967/6336 [01:47<02:01, 27.63it/s, v_num=0, train_loss=0.0627]\n",
      "Epoch 0:  47%|████▋     | 2973/6336 [01:47<02:01, 27.66it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  47%|████▋     | 2974/6336 [01:47<02:01, 27.66it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  47%|████▋     | 2980/6336 [01:47<02:01, 27.69it/s, v_num=0, train_loss=0.038] \n",
      "Epoch 0:  47%|████▋     | 2985/6336 [01:47<02:00, 27.71it/s, v_num=0, train_loss=0.263] \n",
      "Epoch 0:  47%|████▋     | 2990/6336 [01:47<02:00, 27.72it/s, v_num=0, train_loss=0.0985]\n",
      "Epoch 0:  47%|████▋     | 2996/6336 [01:47<02:00, 27.75it/s, v_num=0, train_loss=0.218] \n",
      "Epoch 0:  47%|████▋     | 3002/6336 [01:48<02:00, 27.77it/s, v_num=0, train_loss=0.0676]\n",
      "Epoch 0:  47%|████▋     | 3007/6336 [01:48<01:59, 27.79it/s, v_num=0, train_loss=0.0915]\n",
      "Epoch 0:  47%|████▋     | 3008/6336 [01:48<01:59, 27.80it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  48%|████▊     | 3013/6336 [01:48<01:59, 27.81it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  48%|████▊     | 3018/6336 [01:48<01:59, 27.83it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  48%|████▊     | 3023/6336 [01:48<01:58, 27.85it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  48%|████▊     | 3024/6336 [01:48<01:58, 27.85it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  48%|████▊     | 3030/6336 [01:48<01:58, 27.88it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  48%|████▊     | 3034/6336 [01:48<01:58, 27.89it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  48%|████▊     | 3035/6336 [01:48<01:58, 27.89it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  48%|████▊     | 3039/6336 [01:48<01:58, 27.90it/s, v_num=0, train_loss=0.071] \n",
      "Epoch 0:  48%|████▊     | 3044/6336 [01:49<01:57, 27.92it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  48%|████▊     | 3048/6336 [01:49<01:57, 27.93it/s, v_num=0, train_loss=0.0638]\n",
      "Epoch 0:  48%|████▊     | 3052/6336 [01:49<01:57, 27.94it/s, v_num=0, train_loss=0.0911]\n",
      "Epoch 0:  48%|████▊     | 3056/6336 [01:49<01:57, 27.94it/s, v_num=0, train_loss=0.244] \n",
      "Epoch 0:  48%|████▊     | 3057/6336 [01:49<01:57, 27.95it/s, v_num=0, train_loss=0.206]\n",
      "Epoch 0:  48%|████▊     | 3061/6336 [01:49<01:57, 27.95it/s, v_num=0, train_loss=0.0526]\n",
      "Epoch 0:  48%|████▊     | 3065/6336 [01:49<01:56, 27.96it/s, v_num=0, train_loss=0.0447]\n",
      "Epoch 0:  48%|████▊     | 3069/6336 [01:49<01:56, 27.97it/s, v_num=0, train_loss=0.205] \n",
      "Epoch 0:  48%|████▊     | 3072/6336 [01:49<01:56, 27.97it/s, v_num=0, train_loss=0.0704]\n",
      "Epoch 0:  49%|████▊     | 3074/6336 [01:52<01:59, 27.36it/s, v_num=0, train_loss=0.214] \n",
      "Epoch 0:  49%|████▊     | 3075/6336 [01:52<01:59, 27.36it/s, v_num=0, train_loss=0.252]\n",
      "Epoch 0:  49%|████▊     | 3077/6336 [01:53<01:59, 27.22it/s, v_num=0, train_loss=0.319] \n",
      "Epoch 0:  49%|████▊     | 3081/6336 [01:53<01:59, 27.17it/s, v_num=0, train_loss=0.049] \n",
      "Epoch 0:  49%|████▉     | 3089/6336 [01:53<01:59, 27.21it/s, v_num=0, train_loss=0.268] \n",
      "Epoch 0:  49%|████▉     | 3097/6336 [01:53<01:58, 27.26it/s, v_num=0, train_loss=0.0712] \n",
      "Epoch 0:  49%|████▉     | 3098/6336 [01:53<01:58, 27.26it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  49%|████▉     | 3105/6336 [01:53<01:58, 27.30it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  49%|████▉     | 3106/6336 [01:53<01:58, 27.30it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  49%|████▉     | 3114/6336 [01:53<01:57, 27.34it/s, v_num=0, train_loss=0.0406]\n",
      "Epoch 0:  49%|████▉     | 3123/6336 [01:54<01:57, 27.39it/s, v_num=0, train_loss=0.220] \n",
      "Epoch 0:  49%|████▉     | 3123/6336 [01:54<01:57, 27.39it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  49%|████▉     | 3129/6336 [01:54<01:56, 27.42it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  49%|████▉     | 3130/6336 [01:54<01:56, 27.43it/s, v_num=0, train_loss=0.201]\n",
      "Epoch 0:  50%|████▉     | 3137/6336 [01:54<01:56, 27.46it/s, v_num=0, train_loss=0.211] \n",
      "Epoch 0:  50%|████▉     | 3142/6336 [01:54<01:56, 27.48it/s, v_num=0, train_loss=0.237] \n",
      "Epoch 0:  50%|████▉     | 3143/6336 [01:54<01:56, 27.48it/s, v_num=0, train_loss=0.0327]\n",
      "Epoch 0:  50%|████▉     | 3149/6336 [01:54<01:55, 27.51it/s, v_num=0, train_loss=0.0652]\n",
      "Epoch 0:  50%|████▉     | 3156/6336 [01:54<01:55, 27.54it/s, v_num=0, train_loss=0.0715]\n",
      "Epoch 0:  50%|████▉     | 3157/6336 [01:54<01:55, 27.55it/s, v_num=0, train_loss=0.0629]\n",
      "Epoch 0:  50%|████▉     | 3165/6336 [01:54<01:54, 27.59it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  50%|█████     | 3171/6336 [01:54<01:54, 27.61it/s, v_num=0, train_loss=0.272] \n",
      "Epoch 0:  50%|█████     | 3172/6336 [01:54<01:54, 27.62it/s, v_num=0, train_loss=0.0996]\n",
      "Epoch 0:  50%|█████     | 3178/6336 [01:54<01:54, 27.64it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  50%|█████     | 3179/6336 [01:54<01:54, 27.65it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  50%|█████     | 3186/6336 [01:55<01:53, 27.68it/s, v_num=0, train_loss=0.0252]\n",
      "Epoch 0:  50%|█████     | 3191/6336 [01:55<01:53, 27.70it/s, v_num=0, train_loss=0.0679]\n",
      "Epoch 0:  50%|█████     | 3197/6336 [01:55<01:53, 27.72it/s, v_num=0, train_loss=0.570] \n",
      "Epoch 0:  51%|█████     | 3204/6336 [01:55<01:52, 27.76it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  51%|█████     | 3205/6336 [01:55<01:52, 27.76it/s, v_num=0, train_loss=0.0545]\n",
      "Epoch 0:  51%|█████     | 3212/6336 [01:55<01:52, 27.79it/s, v_num=0, train_loss=0.0266]\n",
      "Epoch 0:  51%|█████     | 3219/6336 [01:55<01:52, 27.82it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:  51%|█████     | 3225/6336 [01:55<01:51, 27.85it/s, v_num=0, train_loss=0.0416]\n",
      "Epoch 0:  51%|█████     | 3226/6336 [01:55<01:51, 27.85it/s, v_num=0, train_loss=0.350] \n",
      "Epoch 0:  51%|█████     | 3232/6336 [01:55<01:51, 27.88it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  51%|█████     | 3240/6336 [01:56<01:50, 27.92it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  51%|█████▏    | 3248/6336 [01:56<01:50, 27.96it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  51%|█████▏    | 3256/6336 [01:56<01:50, 28.00it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  51%|█████▏    | 3262/6336 [01:56<01:49, 28.02it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  51%|█████▏    | 3263/6336 [01:56<01:49, 28.03it/s, v_num=0, train_loss=0.326]\n",
      "Epoch 0:  52%|█████▏    | 3269/6336 [01:56<01:49, 28.05it/s, v_num=0, train_loss=0.203] \n",
      "Epoch 0:  52%|█████▏    | 3270/6336 [01:56<01:49, 28.06it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  52%|█████▏    | 3270/6336 [01:56<01:49, 28.06it/s, v_num=0, train_loss=0.138]\n",
      "Epoch 0:  52%|█████▏    | 3276/6336 [01:56<01:48, 28.08it/s, v_num=0, train_loss=0.230] \n",
      "Epoch 0:  52%|█████▏    | 3282/6336 [01:56<01:48, 28.10it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  52%|█████▏    | 3283/6336 [01:56<01:48, 28.11it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  52%|█████▏    | 3289/6336 [01:56<01:48, 28.13it/s, v_num=0, train_loss=0.297] \n",
      "Epoch 0:  52%|█████▏    | 3289/6336 [01:56<01:48, 28.13it/s, v_num=0, train_loss=0.0805]\n",
      "Epoch 0:  52%|█████▏    | 3295/6336 [01:57<01:48, 28.16it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  52%|█████▏    | 3296/6336 [01:57<01:47, 28.16it/s, v_num=0, train_loss=0.0655]\n",
      "Epoch 0:  52%|█████▏    | 3303/6336 [01:57<01:47, 28.19it/s, v_num=0, train_loss=0.268] \n",
      "Epoch 0:  52%|█████▏    | 3304/6336 [01:57<01:47, 28.20it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  52%|█████▏    | 3309/6336 [01:57<01:47, 28.21it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  52%|█████▏    | 3310/6336 [01:57<01:47, 28.22it/s, v_num=0, train_loss=0.313]\n",
      "Epoch 0:  52%|█████▏    | 3317/6336 [01:57<01:46, 28.25it/s, v_num=0, train_loss=0.252] \n",
      "Epoch 0:  52%|█████▏    | 3318/6336 [01:57<01:46, 28.26it/s, v_num=0, train_loss=0.0369]\n",
      "Epoch 0:  52%|█████▏    | 3325/6336 [01:57<01:46, 28.29it/s, v_num=0, train_loss=0.0811]\n",
      "Epoch 0:  53%|█████▎    | 3330/6336 [01:57<01:46, 28.30it/s, v_num=0, train_loss=0.0946]\n",
      "Epoch 0:  53%|█████▎    | 3331/6336 [01:57<01:46, 28.31it/s, v_num=0, train_loss=0.0805]\n",
      "Epoch 0:  53%|█████▎    | 3337/6336 [01:57<01:45, 28.33it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  53%|█████▎    | 3338/6336 [01:57<01:45, 28.34it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  53%|█████▎    | 3344/6336 [01:57<01:45, 28.36it/s, v_num=0, train_loss=0.0586]\n",
      "Epoch 0:  53%|█████▎    | 3345/6336 [01:57<01:45, 28.37it/s, v_num=0, train_loss=0.0126]\n",
      "Epoch 0:  53%|█████▎    | 3351/6336 [01:58<01:45, 28.39it/s, v_num=0, train_loss=0.251] \n",
      "Epoch 0:  53%|█████▎    | 3357/6336 [01:58<01:44, 28.41it/s, v_num=0, train_loss=0.0427]\n",
      "Epoch 0:  53%|█████▎    | 3357/6336 [01:58<01:44, 28.41it/s, v_num=0, train_loss=0.00453]\n",
      "Epoch 0:  53%|█████▎    | 3364/6336 [01:58<01:44, 28.44it/s, v_num=0, train_loss=0.0459] \n",
      "Epoch 0:  53%|█████▎    | 3369/6336 [01:58<01:44, 28.46it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  53%|█████▎    | 3376/6336 [01:58<01:43, 28.48it/s, v_num=0, train_loss=0.044] \n",
      "Epoch 0:  53%|█████▎    | 3381/6336 [01:58<01:43, 28.50it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  53%|█████▎    | 3382/6336 [01:58<01:43, 28.50it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  53%|█████▎    | 3383/6336 [01:58<01:43, 28.51it/s, v_num=0, train_loss=0.342]\n",
      "Epoch 0:  53%|█████▎    | 3389/6336 [01:58<01:43, 28.53it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  54%|█████▎    | 3390/6336 [01:58<01:43, 28.54it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  54%|█████▎    | 3395/6336 [01:58<01:42, 28.55it/s, v_num=0, train_loss=0.343] \n",
      "Epoch 0:  54%|█████▎    | 3396/6336 [01:58<01:42, 28.56it/s, v_num=0, train_loss=0.455]\n",
      "Epoch 0:  54%|█████▎    | 3402/6336 [01:59<01:42, 28.58it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:  54%|█████▍    | 3408/6336 [01:59<01:42, 28.61it/s, v_num=0, train_loss=0.269] \n",
      "Epoch 0:  54%|█████▍    | 3409/6336 [01:59<01:42, 28.61it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  54%|█████▍    | 3416/6336 [01:59<01:41, 28.64it/s, v_num=0, train_loss=0.0973]\n",
      "Epoch 0:  54%|█████▍    | 3417/6336 [01:59<01:41, 28.65it/s, v_num=0, train_loss=0.0885]\n",
      "Epoch 0:  54%|█████▍    | 3423/6336 [01:59<01:41, 28.67it/s, v_num=0, train_loss=0.296] \n",
      "Epoch 0:  54%|█████▍    | 3424/6336 [01:59<01:41, 28.67it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  54%|█████▍    | 3429/6336 [01:59<01:41, 28.69it/s, v_num=0, train_loss=0.0178]\n",
      "Epoch 0:  54%|█████▍    | 3435/6336 [01:59<01:41, 28.71it/s, v_num=0, train_loss=0.272] \n",
      "Epoch 0:  54%|█████▍    | 3439/6336 [01:59<01:40, 28.72it/s, v_num=0, train_loss=0.0826]\n",
      "Epoch 0:  54%|█████▍    | 3440/6336 [01:59<01:40, 28.72it/s, v_num=0, train_loss=0.0849]\n",
      "Epoch 0:  54%|█████▍    | 3444/6336 [01:59<01:40, 28.73it/s, v_num=0, train_loss=0.250] \n",
      "Epoch 0:  54%|█████▍    | 3445/6336 [01:59<01:40, 28.73it/s, v_num=0, train_loss=0.149]\n",
      "Epoch 0:  54%|█████▍    | 3449/6336 [02:00<01:40, 28.74it/s, v_num=0, train_loss=0.173] \n",
      "Epoch 0:  54%|█████▍    | 3450/6336 [02:00<01:40, 28.74it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  55%|█████▍    | 3454/6336 [02:00<01:40, 28.75it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  55%|█████▍    | 3456/6336 [02:00<01:40, 28.76it/s, v_num=0, train_loss=0.332]\n",
      "Epoch 0:  55%|█████▍    | 3457/6336 [02:03<01:42, 28.02it/s, v_num=0, train_loss=0.0796]\n",
      "Epoch 0:  55%|█████▍    | 3460/6336 [02:04<01:43, 27.86it/s, v_num=0, train_loss=0.0679]\n",
      "Epoch 0:  55%|█████▍    | 3460/6336 [02:04<01:43, 27.86it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  55%|█████▍    | 3461/6336 [02:04<01:43, 27.86it/s, v_num=0, train_loss=0.0599]\n",
      "Epoch 0:  55%|█████▍    | 3463/6336 [02:04<01:43, 27.85it/s, v_num=0, train_loss=0.524] \n",
      "Epoch 0:  55%|█████▍    | 3466/6336 [02:04<01:43, 27.83it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  55%|█████▍    | 3473/6336 [02:04<01:42, 27.86it/s, v_num=0, train_loss=0.0578]\n",
      "Epoch 0:  55%|█████▍    | 3481/6336 [02:04<01:42, 27.90it/s, v_num=0, train_loss=0.0476]\n",
      "Epoch 0:  55%|█████▍    | 3482/6336 [02:04<01:42, 27.90it/s, v_num=0, train_loss=0.0476]\n",
      "Epoch 0:  55%|█████▍    | 3482/6336 [02:04<01:42, 27.90it/s, v_num=0, train_loss=0.227] \n",
      "Epoch 0:  55%|█████▍    | 3483/6336 [02:04<01:42, 27.91it/s, v_num=0, train_loss=0.0511]\n",
      "Epoch 0:  55%|█████▌    | 3491/6336 [02:04<01:41, 27.95it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  55%|█████▌    | 3499/6336 [02:05<01:41, 27.98it/s, v_num=0, train_loss=0.281] \n",
      "Epoch 0:  55%|█████▌    | 3500/6336 [02:05<01:41, 27.99it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  55%|█████▌    | 3501/6336 [02:05<01:41, 27.99it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  55%|█████▌    | 3508/6336 [02:05<01:40, 28.02it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  55%|█████▌    | 3509/6336 [02:05<01:40, 28.03it/s, v_num=0, train_loss=0.0725]\n",
      "Epoch 0:  55%|█████▌    | 3516/6336 [02:05<01:40, 28.06it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  56%|█████▌    | 3517/6336 [02:05<01:40, 28.06it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  56%|█████▌    | 3523/6336 [02:05<01:40, 28.09it/s, v_num=0, train_loss=0.326] \n",
      "Epoch 0:  56%|█████▌    | 3530/6336 [02:05<01:39, 28.11it/s, v_num=0, train_loss=0.0816]\n",
      "Epoch 0:  56%|█████▌    | 3537/6336 [02:05<01:39, 28.14it/s, v_num=0, train_loss=0.0654]\n",
      "Epoch 0:  56%|█████▌    | 3538/6336 [02:05<01:39, 28.15it/s, v_num=0, train_loss=0.0767]\n",
      "Epoch 0:  56%|█████▌    | 3544/6336 [02:05<01:39, 28.17it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  56%|█████▌    | 3551/6336 [02:05<01:38, 28.20it/s, v_num=0, train_loss=0.0457]\n",
      "Epoch 0:  56%|█████▌    | 3557/6336 [02:06<01:38, 28.22it/s, v_num=0, train_loss=0.0594]\n",
      "Epoch 0:  56%|█████▋    | 3564/6336 [02:06<01:38, 28.25it/s, v_num=0, train_loss=0.249]  \n",
      "Epoch 0:  56%|█████▋    | 3570/6336 [02:06<01:37, 28.27it/s, v_num=0, train_loss=0.073] \n",
      "Epoch 0:  56%|█████▋    | 3571/6336 [02:06<01:37, 28.28it/s, v_num=0, train_loss=0.206]\n",
      "Epoch 0:  56%|█████▋    | 3576/6336 [02:06<01:37, 28.29it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:  56%|█████▋    | 3577/6336 [02:06<01:37, 28.30it/s, v_num=0, train_loss=0.0461]\n",
      "Epoch 0:  57%|█████▋    | 3583/6336 [02:06<01:37, 28.32it/s, v_num=0, train_loss=0.222] \n",
      "Epoch 0:  57%|█████▋    | 3584/6336 [02:06<01:37, 28.33it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  57%|█████▋    | 3590/6336 [02:06<01:36, 28.35it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  57%|█████▋    | 3595/6336 [02:06<01:36, 28.36it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  57%|█████▋    | 3601/6336 [02:06<01:36, 28.39it/s, v_num=0, train_loss=0.0736]\n",
      "Epoch 0:  57%|█████▋    | 3607/6336 [02:06<01:36, 28.41it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  57%|█████▋    | 3614/6336 [02:07<01:35, 28.44it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  57%|█████▋    | 3615/6336 [02:07<01:35, 28.44it/s, v_num=0, train_loss=0.302]\n",
      "Epoch 0:  57%|█████▋    | 3622/6336 [02:07<01:35, 28.47it/s, v_num=0, train_loss=0.0924]\n",
      "Epoch 0:  57%|█████▋    | 3623/6336 [02:07<01:35, 28.47it/s, v_num=0, train_loss=0.0792]\n",
      "Epoch 0:  57%|█████▋    | 3629/6336 [02:07<01:35, 28.49it/s, v_num=0, train_loss=0.0789]\n",
      "Epoch 0:  57%|█████▋    | 3634/6336 [02:07<01:34, 28.51it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  57%|█████▋    | 3640/6336 [02:07<01:34, 28.53it/s, v_num=0, train_loss=0.0631]\n",
      "Epoch 0:  57%|█████▋    | 3641/6336 [02:07<01:34, 28.53it/s, v_num=0, train_loss=0.0522]\n",
      "Epoch 0:  58%|█████▊    | 3646/6336 [02:07<01:34, 28.55it/s, v_num=0, train_loss=0.0861]\n",
      "Epoch 0:  58%|█████▊    | 3652/6336 [02:07<01:33, 28.57it/s, v_num=0, train_loss=0.0926]\n",
      "Epoch 0:  58%|█████▊    | 3659/6336 [02:07<01:33, 28.60it/s, v_num=0, train_loss=0.0972]\n",
      "Epoch 0:  58%|█████▊    | 3659/6336 [02:07<01:33, 28.60it/s, v_num=0, train_loss=0.072] \n",
      "Epoch 0:  58%|█████▊    | 3665/6336 [02:08<01:33, 28.62it/s, v_num=0, train_loss=0.0394]\n",
      "Epoch 0:  58%|█████▊    | 3666/6336 [02:08<01:33, 28.62it/s, v_num=0, train_loss=0.266] \n",
      "Epoch 0:  58%|█████▊    | 3671/6336 [02:08<01:33, 28.64it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  58%|█████▊    | 3672/6336 [02:08<01:33, 28.64it/s, v_num=0, train_loss=0.0645]\n",
      "Epoch 0:  58%|█████▊    | 3678/6336 [02:08<01:32, 28.66it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  58%|█████▊    | 3679/6336 [02:08<01:32, 28.67it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  58%|█████▊    | 3684/6336 [02:08<01:32, 28.68it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  58%|█████▊    | 3685/6336 [02:08<01:32, 28.69it/s, v_num=0, train_loss=0.0699]\n",
      "Epoch 0:  58%|█████▊    | 3690/6336 [02:08<01:32, 28.70it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  58%|█████▊    | 3691/6336 [02:08<01:32, 28.71it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:  58%|█████▊    | 3697/6336 [02:08<01:31, 28.73it/s, v_num=0, train_loss=0.0913]\n",
      "Epoch 0:  58%|█████▊    | 3698/6336 [02:08<01:31, 28.73it/s, v_num=0, train_loss=0.074] \n",
      "Epoch 0:  58%|█████▊    | 3704/6336 [02:08<01:31, 28.75it/s, v_num=0, train_loss=0.0462]\n",
      "Epoch 0:  59%|█████▊    | 3710/6336 [02:08<01:31, 28.77it/s, v_num=0, train_loss=0.0665]\n",
      "Epoch 0:  59%|█████▊    | 3715/6336 [02:09<01:31, 28.79it/s, v_num=0, train_loss=0.359] \n",
      "Epoch 0:  59%|█████▊    | 3716/6336 [02:09<01:31, 28.79it/s, v_num=0, train_loss=0.0123]\n",
      "Epoch 0:  59%|█████▊    | 3717/6336 [02:09<01:30, 28.79it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  59%|█████▉    | 3723/6336 [02:09<01:30, 28.82it/s, v_num=0, train_loss=0.313] \n",
      "Epoch 0:  59%|█████▉    | 3724/6336 [02:09<01:30, 28.82it/s, v_num=0, train_loss=0.201]\n",
      "Epoch 0:  59%|█████▉    | 3730/6336 [02:09<01:30, 28.84it/s, v_num=0, train_loss=0.209] \n",
      "Epoch 0:  59%|█████▉    | 3736/6336 [02:09<01:30, 28.86it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  59%|█████▉    | 3737/6336 [02:09<01:30, 28.87it/s, v_num=0, train_loss=0.0764]\n",
      "Epoch 0:  59%|█████▉    | 3743/6336 [02:09<01:29, 28.89it/s, v_num=0, train_loss=0.0778]\n",
      "Epoch 0:  59%|█████▉    | 3744/6336 [02:09<01:29, 28.89it/s, v_num=0, train_loss=0.0875]\n",
      "Epoch 0:  59%|█████▉    | 3750/6336 [02:09<01:29, 28.92it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  59%|█████▉    | 3751/6336 [02:09<01:29, 28.92it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  59%|█████▉    | 3755/6336 [02:09<01:29, 28.93it/s, v_num=0, train_loss=0.0486]\n",
      "Epoch 0:  59%|█████▉    | 3756/6336 [02:09<01:29, 28.93it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  59%|█████▉    | 3762/6336 [02:09<01:28, 28.95it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  59%|█████▉    | 3767/6336 [02:10<01:28, 28.97it/s, v_num=0, train_loss=0.0134]\n",
      "Epoch 0:  59%|█████▉    | 3768/6336 [02:10<01:28, 28.97it/s, v_num=0, train_loss=0.0331]\n",
      "Epoch 0:  60%|█████▉    | 3774/6336 [02:10<01:28, 28.99it/s, v_num=0, train_loss=0.334] \n",
      "Epoch 0:  60%|█████▉    | 3775/6336 [02:10<01:28, 28.99it/s, v_num=0, train_loss=0.0623]\n",
      "Epoch 0:  60%|█████▉    | 3781/6336 [02:10<01:28, 29.01it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:  60%|█████▉    | 3788/6336 [02:10<01:27, 29.04it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:  60%|█████▉    | 3794/6336 [02:10<01:27, 29.06it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  60%|█████▉    | 3800/6336 [02:10<01:27, 29.09it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  60%|█████▉    | 3801/6336 [02:10<01:27, 29.09it/s, v_num=0, train_loss=0.0586]\n",
      "Epoch 0:  60%|██████    | 3806/6336 [02:10<01:26, 29.10it/s, v_num=0, train_loss=0.0848]\n",
      "Epoch 0:  60%|██████    | 3807/6336 [02:10<01:26, 29.11it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  60%|██████    | 3808/6336 [02:10<01:26, 29.11it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  60%|██████    | 3808/6336 [02:10<01:26, 29.11it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  60%|██████    | 3814/6336 [02:10<01:26, 29.13it/s, v_num=0, train_loss=0.465] \n",
      "Epoch 0:  60%|██████    | 3819/6336 [02:11<01:26, 29.14it/s, v_num=0, train_loss=0.269] \n",
      "Epoch 0:  60%|██████    | 3823/6336 [02:11<01:26, 29.15it/s, v_num=0, train_loss=0.071]\n",
      "Epoch 0:  60%|██████    | 3824/6336 [02:11<01:26, 29.15it/s, v_num=0, train_loss=0.0639]\n",
      "Epoch 0:  60%|██████    | 3829/6336 [02:11<01:25, 29.16it/s, v_num=0, train_loss=0.441] \n",
      "Epoch 0:  61%|██████    | 3834/6336 [02:11<01:25, 29.18it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  61%|██████    | 3835/6336 [02:11<01:25, 29.18it/s, v_num=0, train_loss=0.0906]\n",
      "Epoch 0:  61%|██████    | 3839/6336 [02:11<01:25, 29.18it/s, v_num=0, train_loss=0.0781]\n",
      "Epoch 0:  61%|██████    | 3840/6336 [02:11<01:25, 29.18it/s, v_num=0, train_loss=0.048] \n",
      "Epoch 0:  61%|██████    | 3841/6336 [02:12<01:26, 28.89it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  61%|██████    | 3842/6336 [02:13<01:26, 28.70it/s, v_num=0, train_loss=0.239]\n",
      "Epoch 0:  61%|██████    | 3845/6336 [02:14<01:27, 28.52it/s, v_num=0, train_loss=0.0198]\n",
      "Epoch 0:  61%|██████    | 3850/6336 [02:15<01:27, 28.51it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  61%|██████    | 3856/6336 [02:15<01:26, 28.51it/s, v_num=0, train_loss=0.195]\n",
      "Epoch 0:  61%|██████    | 3862/6336 [02:15<01:26, 28.53it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  61%|██████    | 3863/6336 [02:15<01:26, 28.53it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  61%|██████    | 3864/6336 [02:15<01:26, 28.54it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  61%|██████    | 3871/6336 [02:15<01:26, 28.57it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  61%|██████    | 3872/6336 [02:15<01:26, 28.57it/s, v_num=0, train_loss=0.0553]\n",
      "Epoch 0:  61%|██████    | 3880/6336 [02:15<01:25, 28.60it/s, v_num=0, train_loss=0.238] \n",
      "Epoch 0:  61%|██████▏   | 3887/6336 [02:15<01:25, 28.63it/s, v_num=0, train_loss=0.084] \n",
      "Epoch 0:  61%|██████▏   | 3895/6336 [02:15<01:25, 28.67it/s, v_num=0, train_loss=0.218] \n",
      "Epoch 0:  61%|██████▏   | 3896/6336 [02:15<01:25, 28.67it/s, v_num=0, train_loss=0.0597]\n",
      "Epoch 0:  62%|██████▏   | 3902/6336 [02:16<01:24, 28.69it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  62%|██████▏   | 3908/6336 [02:16<01:24, 28.71it/s, v_num=0, train_loss=0.0595]\n",
      "Epoch 0:  62%|██████▏   | 3914/6336 [02:16<01:24, 28.73it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  62%|██████▏   | 3920/6336 [02:16<01:24, 28.75it/s, v_num=0, train_loss=0.0942]\n",
      "Epoch 0:  62%|██████▏   | 3926/6336 [02:16<01:23, 28.77it/s, v_num=0, train_loss=0.293] \n",
      "Epoch 0:  62%|██████▏   | 3932/6336 [02:16<01:23, 28.79it/s, v_num=0, train_loss=0.0503]\n",
      "Epoch 0:  62%|██████▏   | 3933/6336 [02:16<01:23, 28.79it/s, v_num=0, train_loss=0.0905]\n",
      "Epoch 0:  62%|██████▏   | 3939/6336 [02:16<01:23, 28.81it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  62%|██████▏   | 3940/6336 [02:16<01:23, 28.82it/s, v_num=0, train_loss=0.276]\n",
      "Epoch 0:  62%|██████▏   | 3945/6336 [02:16<01:22, 28.83it/s, v_num=0, train_loss=0.0501]\n",
      "Epoch 0:  62%|██████▏   | 3950/6336 [02:16<01:22, 28.84it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  62%|██████▏   | 3951/6336 [02:16<01:22, 28.84it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  62%|██████▏   | 3957/6336 [02:17<01:22, 28.86it/s, v_num=0, train_loss=0.0267]\n",
      "Epoch 0:  63%|██████▎   | 3964/6336 [02:17<01:22, 28.89it/s, v_num=0, train_loss=0.478] \n",
      "Epoch 0:  63%|██████▎   | 3965/6336 [02:17<01:22, 28.89it/s, v_num=0, train_loss=0.0754]\n",
      "Epoch 0:  63%|██████▎   | 3971/6336 [02:17<01:21, 28.91it/s, v_num=0, train_loss=0.0471]\n",
      "Epoch 0:  63%|██████▎   | 3972/6336 [02:17<01:21, 28.92it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  63%|██████▎   | 3978/6336 [02:17<01:21, 28.94it/s, v_num=0, train_loss=0.034]\n",
      "Epoch 0:  63%|██████▎   | 3984/6336 [02:17<01:21, 28.96it/s, v_num=0, train_loss=0.293] \n",
      "Epoch 0:  63%|██████▎   | 3989/6336 [02:17<01:21, 28.97it/s, v_num=0, train_loss=0.0484]\n",
      "Epoch 0:  63%|██████▎   | 3990/6336 [02:17<01:20, 28.98it/s, v_num=0, train_loss=0.0461]\n",
      "Epoch 0:  63%|██████▎   | 3995/6336 [02:17<01:20, 28.99it/s, v_num=0, train_loss=0.228] \n",
      "Epoch 0:  63%|██████▎   | 3996/6336 [02:17<01:20, 28.99it/s, v_num=0, train_loss=0.276]\n",
      "Epoch 0:  63%|██████▎   | 4002/6336 [02:17<01:20, 29.01it/s, v_num=0, train_loss=0.0541]\n",
      "Epoch 0:  63%|██████▎   | 4008/6336 [02:18<01:20, 29.03it/s, v_num=0, train_loss=0.182] \n",
      "Epoch 0:  63%|██████▎   | 4014/6336 [02:18<01:19, 29.05it/s, v_num=0, train_loss=0.0708]\n",
      "Epoch 0:  63%|██████▎   | 4015/6336 [02:18<01:19, 29.06it/s, v_num=0, train_loss=0.0849]\n",
      "Epoch 0:  63%|██████▎   | 4021/6336 [02:18<01:19, 29.07it/s, v_num=0, train_loss=0.506] \n",
      "Epoch 0:  64%|██████▎   | 4027/6336 [02:18<01:19, 29.09it/s, v_num=0, train_loss=0.0482]\n",
      "Epoch 0:  64%|██████▎   | 4032/6336 [02:18<01:19, 29.11it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  64%|██████▎   | 4033/6336 [02:18<01:19, 29.11it/s, v_num=0, train_loss=0.592]\n",
      "Epoch 0:  64%|██████▎   | 4039/6336 [02:18<01:18, 29.13it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  64%|██████▍   | 4044/6336 [02:18<01:18, 29.14it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  64%|██████▍   | 4045/6336 [02:18<01:18, 29.14it/s, v_num=0, train_loss=0.451]\n",
      "Epoch 0:  64%|██████▍   | 4046/6336 [02:18<01:18, 29.15it/s, v_num=0, train_loss=0.451]\n",
      "Epoch 0:  64%|██████▍   | 4046/6336 [02:18<01:18, 29.15it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  64%|██████▍   | 4051/6336 [02:18<01:18, 29.16it/s, v_num=0, train_loss=0.0894]\n",
      "Epoch 0:  64%|██████▍   | 4052/6336 [02:18<01:18, 29.16it/s, v_num=0, train_loss=0.0607]\n",
      "Epoch 0:  64%|██████▍   | 4057/6336 [02:19<01:18, 29.18it/s, v_num=0, train_loss=0.301] \n",
      "Epoch 0:  64%|██████▍   | 4063/6336 [02:19<01:17, 29.20it/s, v_num=0, train_loss=0.0554]\n",
      "Epoch 0:  64%|██████▍   | 4064/6336 [02:19<01:17, 29.20it/s, v_num=0, train_loss=0.041] \n",
      "Epoch 0:  64%|██████▍   | 4069/6336 [02:19<01:17, 29.21it/s, v_num=0, train_loss=0.415] \n",
      "Epoch 0:  64%|██████▍   | 4075/6336 [02:19<01:17, 29.23it/s, v_num=0, train_loss=0.0476]\n",
      "Epoch 0:  64%|██████▍   | 4080/6336 [02:19<01:17, 29.24it/s, v_num=0, train_loss=0.0626]\n",
      "Epoch 0:  64%|██████▍   | 4086/6336 [02:19<01:16, 29.26it/s, v_num=0, train_loss=0.288] \n",
      "Epoch 0:  65%|██████▍   | 4092/6336 [02:19<01:16, 29.28it/s, v_num=0, train_loss=0.0563]\n",
      "Epoch 0:  65%|██████▍   | 4093/6336 [02:19<01:16, 29.28it/s, v_num=0, train_loss=0.387] \n",
      "Epoch 0:  65%|██████▍   | 4098/6336 [02:19<01:16, 29.30it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  65%|██████▍   | 4104/6336 [02:20<01:16, 29.31it/s, v_num=0, train_loss=0.0335]\n",
      "Epoch 0:  65%|██████▍   | 4104/6336 [02:20<01:16, 29.31it/s, v_num=0, train_loss=0.0628]\n",
      "Epoch 0:  65%|██████▍   | 4105/6336 [02:20<01:16, 29.31it/s, v_num=0, train_loss=0.323] \n",
      "Epoch 0:  65%|██████▍   | 4111/6336 [02:20<01:15, 29.34it/s, v_num=0, train_loss=0.244] \n",
      "Epoch 0:  65%|██████▍   | 4112/6336 [02:20<01:15, 29.34it/s, v_num=0, train_loss=0.365]\n",
      "Epoch 0:  65%|██████▍   | 4118/6336 [02:20<01:15, 29.36it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  65%|██████▌   | 4119/6336 [02:20<01:15, 29.36it/s, v_num=0, train_loss=0.085]\n",
      "Epoch 0:  65%|██████▌   | 4126/6336 [02:20<01:15, 29.39it/s, v_num=0, train_loss=0.391] \n",
      "Epoch 0:  65%|██████▌   | 4127/6336 [02:20<01:15, 29.39it/s, v_num=0, train_loss=0.0505]\n",
      "Epoch 0:  65%|██████▌   | 4134/6336 [02:20<01:14, 29.42it/s, v_num=0, train_loss=0.070] \n",
      "Epoch 0:  65%|██████▌   | 4140/6336 [02:20<01:14, 29.44it/s, v_num=0, train_loss=0.0637]\n",
      "Epoch 0:  65%|██████▌   | 4141/6336 [02:20<01:14, 29.44it/s, v_num=0, train_loss=0.248] \n",
      "Epoch 0:  65%|██████▌   | 4148/6336 [02:20<01:14, 29.47it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  66%|██████▌   | 4154/6336 [02:20<01:14, 29.48it/s, v_num=0, train_loss=0.222] \n",
      "Epoch 0:  66%|██████▌   | 4154/6336 [02:20<01:14, 29.48it/s, v_num=0, train_loss=0.354]\n",
      "Epoch 0:  66%|██████▌   | 4160/6336 [02:21<01:13, 29.50it/s, v_num=0, train_loss=0.250] \n",
      "Epoch 0:  66%|██████▌   | 4161/6336 [02:21<01:13, 29.51it/s, v_num=0, train_loss=0.160]\n",
      "Epoch 0:  66%|██████▌   | 4167/6336 [02:21<01:13, 29.53it/s, v_num=0, train_loss=0.0863]\n",
      "Epoch 0:  66%|██████▌   | 4173/6336 [02:21<01:13, 29.54it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  66%|██████▌   | 4178/6336 [02:21<01:13, 29.56it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  66%|██████▌   | 4183/6336 [02:21<01:12, 29.57it/s, v_num=0, train_loss=0.0902]\n",
      "Epoch 0:  66%|██████▌   | 4184/6336 [02:21<01:12, 29.57it/s, v_num=0, train_loss=0.190] \n",
      "Epoch 0:  66%|██████▌   | 4190/6336 [02:21<01:12, 29.59it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  66%|██████▌   | 4191/6336 [02:21<01:12, 29.59it/s, v_num=0, train_loss=0.0658]\n",
      "Epoch 0:  66%|██████▌   | 4196/6336 [02:21<01:12, 29.61it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  66%|██████▌   | 4197/6336 [02:21<01:12, 29.61it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  66%|██████▋   | 4202/6336 [02:21<01:12, 29.62it/s, v_num=0, train_loss=0.311] \n",
      "Epoch 0:  66%|██████▋   | 4203/6336 [02:21<01:11, 29.63it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  66%|██████▋   | 4207/6336 [02:21<01:11, 29.63it/s, v_num=0, train_loss=0.0346]\n",
      "Epoch 0:  66%|██████▋   | 4208/6336 [02:21<01:11, 29.63it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:  66%|██████▋   | 4212/6336 [02:22<01:11, 29.64it/s, v_num=0, train_loss=0.0403]\n",
      "Epoch 0:  66%|██████▋   | 4213/6336 [02:22<01:11, 29.64it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  67%|██████▋   | 4218/6336 [02:22<01:11, 29.65it/s, v_num=0, train_loss=0.0293]\n",
      "Epoch 0:  67%|██████▋   | 4223/6336 [02:22<01:11, 29.66it/s, v_num=0, train_loss=0.0453]\n",
      "Epoch 0:  67%|██████▋   | 4224/6336 [02:22<01:11, 29.67it/s, v_num=0, train_loss=0.0325]\n",
      "Epoch 0:  67%|██████▋   | 4225/6336 [02:24<01:11, 29.33it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  67%|██████▋   | 4226/6336 [02:26<01:12, 28.93it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  67%|██████▋   | 4226/6336 [02:26<01:12, 28.93it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  67%|██████▋   | 4227/6336 [02:26<01:12, 28.94it/s, v_num=0, train_loss=0.0707]\n",
      "Epoch 0:  67%|██████▋   | 4230/6336 [02:26<01:12, 28.94it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  67%|██████▋   | 4236/6336 [02:26<01:12, 28.91it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  67%|██████▋   | 4237/6336 [02:26<01:12, 28.91it/s, v_num=0, train_loss=0.238]\n",
      "Epoch 0:  67%|██████▋   | 4244/6336 [02:26<01:12, 28.94it/s, v_num=0, train_loss=0.0952]\n",
      "Epoch 0:  67%|██████▋   | 4251/6336 [02:26<01:11, 28.96it/s, v_num=0, train_loss=0.0438]\n",
      "Epoch 0:  67%|██████▋   | 4252/6336 [02:26<01:11, 28.97it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  67%|██████▋   | 4259/6336 [02:26<01:11, 28.99it/s, v_num=0, train_loss=0.0982]\n",
      "Epoch 0:  67%|██████▋   | 4260/6336 [02:26<01:11, 29.00it/s, v_num=0, train_loss=0.0827]\n",
      "Epoch 0:  67%|██████▋   | 4261/6336 [02:26<01:11, 29.00it/s, v_num=0, train_loss=0.0836]\n",
      "Epoch 0:  67%|██████▋   | 4267/6336 [02:27<01:11, 29.02it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  67%|██████▋   | 4268/6336 [02:27<01:11, 29.02it/s, v_num=0, train_loss=0.0906]\n",
      "Epoch 0:  67%|██████▋   | 4275/6336 [02:27<01:10, 29.05it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  67%|██████▋   | 4276/6336 [02:27<01:10, 29.05it/s, v_num=0, train_loss=0.0523]\n",
      "Epoch 0:  68%|██████▊   | 4282/6336 [02:27<01:10, 29.07it/s, v_num=0, train_loss=0.310] \n",
      "Epoch 0:  68%|██████▊   | 4288/6336 [02:27<01:10, 29.09it/s, v_num=0, train_loss=0.0716]\n",
      "Epoch 0:  68%|██████▊   | 4289/6336 [02:27<01:10, 29.09it/s, v_num=0, train_loss=0.0464]\n",
      "Epoch 0:  68%|██████▊   | 4294/6336 [02:27<01:10, 29.11it/s, v_num=0, train_loss=0.241] \n",
      "Epoch 0:  68%|██████▊   | 4300/6336 [02:27<01:09, 29.12it/s, v_num=0, train_loss=0.0916]\n",
      "Epoch 0:  68%|██████▊   | 4306/6336 [02:27<01:09, 29.14it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  68%|██████▊   | 4307/6336 [02:27<01:09, 29.14it/s, v_num=0, train_loss=0.204]\n",
      "Epoch 0:  68%|██████▊   | 4312/6336 [02:27<01:09, 29.16it/s, v_num=0, train_loss=0.0427]\n",
      "Epoch 0:  68%|██████▊   | 4313/6336 [02:27<01:09, 29.16it/s, v_num=0, train_loss=0.0427]\n",
      "Epoch 0:  68%|██████▊   | 4313/6336 [02:27<01:09, 29.16it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  68%|██████▊   | 4319/6336 [02:28<01:09, 29.18it/s, v_num=0, train_loss=0.0952]\n",
      "Epoch 0:  68%|██████▊   | 4324/6336 [02:28<01:08, 29.19it/s, v_num=0, train_loss=0.023] \n",
      "Epoch 0:  68%|██████▊   | 4330/6336 [02:28<01:08, 29.21it/s, v_num=0, train_loss=0.256] \n",
      "Epoch 0:  68%|██████▊   | 4331/6336 [02:28<01:08, 29.21it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  68%|██████▊   | 4336/6336 [02:28<01:08, 29.23it/s, v_num=0, train_loss=0.0426]\n",
      "Epoch 0:  68%|██████▊   | 4337/6336 [02:28<01:08, 29.23it/s, v_num=0, train_loss=0.0879]\n",
      "Epoch 0:  69%|██████▊   | 4343/6336 [02:28<01:08, 29.25it/s, v_num=0, train_loss=0.0686]\n",
      "Epoch 0:  69%|██████▊   | 4348/6336 [02:28<01:07, 29.27it/s, v_num=0, train_loss=0.0665]\n",
      "Epoch 0:  69%|██████▊   | 4349/6336 [02:28<01:07, 29.27it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  69%|██████▊   | 4355/6336 [02:28<01:07, 29.29it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  69%|██████▉   | 4360/6336 [02:28<01:07, 29.30it/s, v_num=0, train_loss=0.0406]\n",
      "Epoch 0:  69%|██████▉   | 4361/6336 [02:28<01:07, 29.30it/s, v_num=0, train_loss=0.061] \n",
      "Epoch 0:  69%|██████▉   | 4366/6336 [02:28<01:07, 29.32it/s, v_num=0, train_loss=0.443] \n",
      "Epoch 0:  69%|██████▉   | 4367/6336 [02:28<01:07, 29.32it/s, v_num=0, train_loss=0.221]\n",
      "Epoch 0:  69%|██████▉   | 4372/6336 [02:29<01:06, 29.33it/s, v_num=0, train_loss=0.0682]\n",
      "Epoch 0:  69%|██████▉   | 4378/6336 [02:29<01:06, 29.35it/s, v_num=0, train_loss=0.539] \n",
      "Epoch 0:  69%|██████▉   | 4384/6336 [02:29<01:06, 29.37it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  69%|██████▉   | 4390/6336 [02:29<01:06, 29.38it/s, v_num=0, train_loss=0.425] \n",
      "Epoch 0:  69%|██████▉   | 4391/6336 [02:29<01:06, 29.39it/s, v_num=0, train_loss=0.322]\n",
      "Epoch 0:  69%|██████▉   | 4396/6336 [02:29<01:05, 29.40it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  69%|██████▉   | 4401/6336 [02:29<01:05, 29.41it/s, v_num=0, train_loss=0.0697]\n",
      "Epoch 0:  69%|██████▉   | 4402/6336 [02:29<01:05, 29.41it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  70%|██████▉   | 4407/6336 [02:29<01:05, 29.42it/s, v_num=0, train_loss=0.209] \n",
      "Epoch 0:  70%|██████▉   | 4408/6336 [02:29<01:05, 29.43it/s, v_num=0, train_loss=0.0604]\n",
      "Epoch 0:  70%|██████▉   | 4414/6336 [02:29<01:05, 29.44it/s, v_num=0, train_loss=0.362] \n",
      "Epoch 0:  70%|██████▉   | 4420/6336 [02:30<01:05, 29.46it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  70%|██████▉   | 4421/6336 [02:30<01:04, 29.46it/s, v_num=0, train_loss=0.026]\n",
      "Epoch 0:  70%|██████▉   | 4427/6336 [02:30<01:04, 29.48it/s, v_num=0, train_loss=0.343] \n",
      "Epoch 0:  70%|██████▉   | 4428/6336 [02:30<01:04, 29.48it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  70%|██████▉   | 4434/6336 [02:30<01:04, 29.50it/s, v_num=0, train_loss=0.0763]\n",
      "Epoch 0:  70%|██████▉   | 4435/6336 [02:30<01:04, 29.51it/s, v_num=0, train_loss=0.0311]\n",
      "Epoch 0:  70%|███████   | 4441/6336 [02:30<01:04, 29.53it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  70%|███████   | 4442/6336 [02:30<01:04, 29.53it/s, v_num=0, train_loss=0.0277]\n",
      "Epoch 0:  70%|███████   | 4448/6336 [02:30<01:03, 29.55it/s, v_num=0, train_loss=0.0724]\n",
      "Epoch 0:  70%|███████   | 4453/6336 [02:30<01:03, 29.56it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  70%|███████   | 4458/6336 [02:30<01:03, 29.57it/s, v_num=0, train_loss=0.0607]\n",
      "Epoch 0:  70%|███████   | 4459/6336 [02:30<01:03, 29.57it/s, v_num=0, train_loss=0.0456]\n",
      "Epoch 0:  70%|███████   | 4465/6336 [02:30<01:03, 29.59it/s, v_num=0, train_loss=0.0872]\n",
      "Epoch 0:  70%|███████   | 4466/6336 [02:30<01:03, 29.59it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  71%|███████   | 4471/6336 [02:31<01:02, 29.60it/s, v_num=0, train_loss=0.00974]\n",
      "Epoch 0:  71%|███████   | 4477/6336 [02:31<01:02, 29.62it/s, v_num=0, train_loss=0.107]  \n",
      "Epoch 0:  71%|███████   | 4482/6336 [02:31<01:02, 29.63it/s, v_num=0, train_loss=0.089] \n",
      "Epoch 0:  71%|███████   | 4489/6336 [02:31<01:02, 29.65it/s, v_num=0, train_loss=0.0458]\n",
      "Epoch 0:  71%|███████   | 4494/6336 [02:31<01:02, 29.67it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  71%|███████   | 4495/6336 [02:31<01:02, 29.67it/s, v_num=0, train_loss=0.0211]\n",
      "Epoch 0:  71%|███████   | 4500/6336 [02:31<01:01, 29.68it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:  71%|███████   | 4501/6336 [02:31<01:01, 29.68it/s, v_num=0, train_loss=0.227]\n",
      "Epoch 0:  71%|███████   | 4506/6336 [02:31<01:01, 29.69it/s, v_num=0, train_loss=0.0446]\n",
      "Epoch 0:  71%|███████   | 4512/6336 [02:31<01:01, 29.71it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:  71%|███████   | 4513/6336 [02:31<01:01, 29.71it/s, v_num=0, train_loss=0.0844]\n",
      "Epoch 0:  71%|███████▏  | 4519/6336 [02:31<01:01, 29.73it/s, v_num=0, train_loss=0.0695]\n",
      "Epoch 0:  71%|███████▏  | 4524/6336 [02:32<01:00, 29.74it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  71%|███████▏  | 4525/6336 [02:32<01:00, 29.75it/s, v_num=0, train_loss=0.0966]\n",
      "Epoch 0:  71%|███████▏  | 4530/6336 [02:32<01:00, 29.76it/s, v_num=0, train_loss=0.0824]\n",
      "Epoch 0:  72%|███████▏  | 4535/6336 [02:32<01:00, 29.77it/s, v_num=0, train_loss=0.293] \n",
      "Epoch 0:  72%|███████▏  | 4536/6336 [02:32<01:00, 29.77it/s, v_num=0, train_loss=0.328]\n",
      "Epoch 0:  72%|███████▏  | 4542/6336 [02:32<01:00, 29.79it/s, v_num=0, train_loss=0.0599]\n",
      "Epoch 0:  72%|███████▏  | 4547/6336 [02:32<01:00, 29.80it/s, v_num=0, train_loss=0.288] \n",
      "Epoch 0:  72%|███████▏  | 4551/6336 [02:32<00:59, 29.80it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  72%|███████▏  | 4552/6336 [02:32<00:59, 29.81it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  72%|███████▏  | 4558/6336 [02:32<00:59, 29.83it/s, v_num=0, train_loss=0.220] \n",
      "Epoch 0:  72%|███████▏  | 4559/6336 [02:32<00:59, 29.83it/s, v_num=0, train_loss=0.274]\n",
      "Epoch 0:  72%|███████▏  | 4566/6336 [02:32<00:59, 29.85it/s, v_num=0, train_loss=0.0661]\n",
      "Epoch 0:  72%|███████▏  | 4571/6336 [02:33<00:59, 29.86it/s, v_num=0, train_loss=0.373] \n",
      "Epoch 0:  72%|███████▏  | 4576/6336 [02:33<00:58, 29.87it/s, v_num=0, train_loss=0.346]\n",
      "Epoch 0:  72%|███████▏  | 4577/6336 [02:33<00:58, 29.87it/s, v_num=0, train_loss=0.266]\n",
      "Epoch 0:  72%|███████▏  | 4581/6336 [02:33<00:58, 29.88it/s, v_num=0, train_loss=0.237] \n",
      "Epoch 0:  72%|███████▏  | 4581/6336 [02:33<00:58, 29.88it/s, v_num=0, train_loss=0.0747]\n",
      "Epoch 0:  72%|███████▏  | 4586/6336 [02:33<00:58, 29.89it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  72%|███████▏  | 4587/6336 [02:33<00:58, 29.89it/s, v_num=0, train_loss=0.462]\n",
      "Epoch 0:  72%|███████▏  | 4592/6336 [02:33<00:58, 29.90it/s, v_num=0, train_loss=0.229] \n",
      "Epoch 0:  73%|███████▎  | 4596/6336 [02:33<00:58, 29.90it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  73%|███████▎  | 4601/6336 [02:33<00:58, 29.91it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  73%|███████▎  | 4601/6336 [02:33<00:58, 29.91it/s, v_num=0, train_loss=0.0934]\n",
      "Epoch 0:  73%|███████▎  | 4605/6336 [02:33<00:57, 29.91it/s, v_num=0, train_loss=0.0408]\n",
      "Epoch 0:  73%|███████▎  | 4608/6336 [02:33<00:57, 29.92it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  73%|███████▎  | 4609/6336 [02:35<00:58, 29.63it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  73%|███████▎  | 4610/6336 [02:36<00:58, 29.40it/s, v_num=0, train_loss=0.0895]\n",
      "Epoch 0:  73%|███████▎  | 4614/6336 [02:37<00:58, 29.35it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  73%|███████▎  | 4615/6336 [02:37<00:58, 29.35it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  73%|███████▎  | 4615/6336 [02:37<00:58, 29.35it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  73%|███████▎  | 4620/6336 [02:37<00:58, 29.36it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  73%|███████▎  | 4621/6336 [02:37<00:58, 29.37it/s, v_num=0, train_loss=0.299]\n",
      "Epoch 0:  73%|███████▎  | 4622/6336 [02:37<00:58, 29.37it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  73%|███████▎  | 4628/6336 [02:37<00:58, 29.39it/s, v_num=0, train_loss=0.250] \n",
      "Epoch 0:  73%|███████▎  | 4636/6336 [02:37<00:57, 29.42it/s, v_num=0, train_loss=0.228] \n",
      "Epoch 0:  73%|███████▎  | 4644/6336 [02:37<00:57, 29.44it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  73%|███████▎  | 4645/6336 [02:37<00:57, 29.45it/s, v_num=0, train_loss=0.553]\n",
      "Epoch 0:  73%|███████▎  | 4652/6336 [02:37<00:57, 29.47it/s, v_num=0, train_loss=0.497] \n",
      "Epoch 0:  73%|███████▎  | 4653/6336 [02:37<00:57, 29.48it/s, v_num=0, train_loss=0.0484]\n",
      "Epoch 0:  74%|███████▎  | 4660/6336 [02:37<00:56, 29.50it/s, v_num=0, train_loss=0.227] \n",
      "Epoch 0:  74%|███████▎  | 4661/6336 [02:37<00:56, 29.50it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  74%|███████▎  | 4667/6336 [02:38<00:56, 29.52it/s, v_num=0, train_loss=0.462] \n",
      "Epoch 0:  74%|███████▍  | 4673/6336 [02:38<00:56, 29.54it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  74%|███████▍  | 4678/6336 [02:38<00:56, 29.54it/s, v_num=0, train_loss=0.279] \n",
      "Epoch 0:  74%|███████▍  | 4679/6336 [02:38<00:56, 29.55it/s, v_num=0, train_loss=0.403]\n",
      "Epoch 0:  74%|███████▍  | 4684/6336 [02:38<00:55, 29.56it/s, v_num=0, train_loss=0.493] \n",
      "Epoch 0:  74%|███████▍  | 4685/6336 [02:38<00:55, 29.56it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  74%|███████▍  | 4690/6336 [02:38<00:55, 29.57it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  74%|███████▍  | 4691/6336 [02:38<00:55, 29.58it/s, v_num=0, train_loss=0.422]\n",
      "Epoch 0:  74%|███████▍  | 4697/6336 [02:38<00:55, 29.59it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  74%|███████▍  | 4698/6336 [02:38<00:55, 29.60it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  74%|███████▍  | 4703/6336 [02:38<00:55, 29.61it/s, v_num=0, train_loss=0.288] \n",
      "Epoch 0:  74%|███████▍  | 4710/6336 [02:38<00:54, 29.63it/s, v_num=0, train_loss=0.203] \n",
      "Epoch 0:  74%|███████▍  | 4717/6336 [02:39<00:54, 29.65it/s, v_num=0, train_loss=0.315] \n",
      "Epoch 0:  74%|███████▍  | 4718/6336 [02:39<00:54, 29.65it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  75%|███████▍  | 4724/6336 [02:39<00:54, 29.67it/s, v_num=0, train_loss=0.0691]\n",
      "Epoch 0:  75%|███████▍  | 4724/6336 [02:39<00:54, 29.67it/s, v_num=0, train_loss=0.098] \n",
      "Epoch 0:  75%|███████▍  | 4730/6336 [02:39<00:54, 29.68it/s, v_num=0, train_loss=0.260] \n",
      "Epoch 0:  75%|███████▍  | 4736/6336 [02:39<00:53, 29.70it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  75%|███████▍  | 4737/6336 [02:39<00:53, 29.70it/s, v_num=0, train_loss=0.0448]\n",
      "Epoch 0:  75%|███████▍  | 4738/6336 [02:39<00:53, 29.71it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  75%|███████▍  | 4739/6336 [02:39<00:53, 29.71it/s, v_num=0, train_loss=0.243]\n",
      "Epoch 0:  75%|███████▍  | 4745/6336 [02:39<00:53, 29.73it/s, v_num=0, train_loss=0.0207]\n",
      "Epoch 0:  75%|███████▍  | 4746/6336 [02:39<00:53, 29.73it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  75%|███████▌  | 4753/6336 [02:39<00:53, 29.76it/s, v_num=0, train_loss=0.205] \n",
      "Epoch 0:  75%|███████▌  | 4760/6336 [02:39<00:52, 29.78it/s, v_num=0, train_loss=0.0847]\n",
      "Epoch 0:  75%|███████▌  | 4766/6336 [02:39<00:52, 29.79it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  75%|███████▌  | 4773/6336 [02:40<00:52, 29.82it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  75%|███████▌  | 4774/6336 [02:40<00:52, 29.82it/s, v_num=0, train_loss=0.250]\n",
      "Epoch 0:  75%|███████▌  | 4775/6336 [02:40<00:52, 29.82it/s, v_num=0, train_loss=0.209]\n",
      "Epoch 0:  75%|███████▌  | 4781/6336 [02:40<00:52, 29.84it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  75%|███████▌  | 4782/6336 [02:40<00:52, 29.84it/s, v_num=0, train_loss=0.0775]\n",
      "Epoch 0:  76%|███████▌  | 4790/6336 [02:40<00:51, 29.87it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  76%|███████▌  | 4797/6336 [02:40<00:51, 29.89it/s, v_num=0, train_loss=0.038] \n",
      "Epoch 0:  76%|███████▌  | 4798/6336 [02:40<00:51, 29.90it/s, v_num=0, train_loss=0.290]\n",
      "Epoch 0:  76%|███████▌  | 4805/6336 [02:40<00:51, 29.92it/s, v_num=0, train_loss=0.0533]\n",
      "Epoch 0:  76%|███████▌  | 4806/6336 [02:40<00:51, 29.93it/s, v_num=0, train_loss=0.0954]\n",
      "Epoch 0:  76%|███████▌  | 4813/6336 [02:40<00:50, 29.95it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  76%|███████▌  | 4814/6336 [02:40<00:50, 29.95it/s, v_num=0, train_loss=0.396]\n",
      "Epoch 0:  76%|███████▌  | 4820/6336 [02:40<00:50, 29.97it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  76%|███████▌  | 4828/6336 [02:40<00:50, 30.00it/s, v_num=0, train_loss=0.272] \n",
      "Epoch 0:  76%|███████▋  | 4834/6336 [02:41<00:50, 30.01it/s, v_num=0, train_loss=0.245] \n",
      "Epoch 0:  76%|███████▋  | 4841/6336 [02:41<00:49, 30.03it/s, v_num=0, train_loss=0.0428]\n",
      "Epoch 0:  76%|███████▋  | 4842/6336 [02:41<00:49, 30.04it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  77%|███████▋  | 4849/6336 [02:41<00:49, 30.06it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  77%|███████▋  | 4850/6336 [02:41<00:49, 30.06it/s, v_num=0, train_loss=0.214]\n",
      "Epoch 0:  77%|███████▋  | 4851/6336 [02:41<00:49, 30.07it/s, v_num=0, train_loss=0.206]\n",
      "Epoch 0:  77%|███████▋  | 4858/6336 [02:41<00:49, 30.09it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  77%|███████▋  | 4864/6336 [02:41<00:48, 30.10it/s, v_num=0, train_loss=0.254] \n",
      "Epoch 0:  77%|███████▋  | 4871/6336 [02:41<00:48, 30.13it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  77%|███████▋  | 4878/6336 [02:41<00:48, 30.15it/s, v_num=0, train_loss=0.0942]\n",
      "Epoch 0:  77%|███████▋  | 4883/6336 [02:41<00:48, 30.16it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  77%|███████▋  | 4889/6336 [02:42<00:47, 30.17it/s, v_num=0, train_loss=0.0784]\n",
      "Epoch 0:  77%|███████▋  | 4890/6336 [02:42<00:47, 30.18it/s, v_num=0, train_loss=0.208] \n",
      "Epoch 0:  77%|███████▋  | 4897/6336 [02:42<00:47, 30.20it/s, v_num=0, train_loss=0.493] \n",
      "Epoch 0:  77%|███████▋  | 4903/6336 [02:42<00:47, 30.21it/s, v_num=0, train_loss=0.098] \n",
      "Epoch 0:  77%|███████▋  | 4904/6336 [02:42<00:47, 30.22it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  77%|███████▋  | 4905/6336 [02:42<00:47, 30.22it/s, v_num=0, train_loss=0.0555]\n",
      "Epoch 0:  78%|███████▊  | 4912/6336 [02:42<00:47, 30.24it/s, v_num=0, train_loss=0.587] \n",
      "Epoch 0:  78%|███████▊  | 4917/6336 [02:42<00:46, 30.25it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  78%|███████▊  | 4918/6336 [02:42<00:46, 30.26it/s, v_num=0, train_loss=0.138]\n",
      "Epoch 0:  78%|███████▊  | 4924/6336 [02:42<00:46, 30.27it/s, v_num=0, train_loss=0.460] \n",
      "Epoch 0:  78%|███████▊  | 4925/6336 [02:42<00:46, 30.28it/s, v_num=0, train_loss=0.0589]\n",
      "Epoch 0:  78%|███████▊  | 4932/6336 [02:42<00:46, 30.30it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  78%|███████▊  | 4937/6336 [02:42<00:46, 30.30it/s, v_num=0, train_loss=0.0449]\n",
      "Epoch 0:  78%|███████▊  | 4938/6336 [02:42<00:46, 30.31it/s, v_num=0, train_loss=0.283] \n",
      "Epoch 0:  78%|███████▊  | 4943/6336 [02:43<00:45, 30.32it/s, v_num=0, train_loss=0.208] \n",
      "Epoch 0:  78%|███████▊  | 4944/6336 [02:43<00:45, 30.32it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  78%|███████▊  | 4950/6336 [02:43<00:45, 30.34it/s, v_num=0, train_loss=0.262] \n",
      "Epoch 0:  78%|███████▊  | 4951/6336 [02:43<00:45, 30.34it/s, v_num=0, train_loss=0.0445]\n",
      "Epoch 0:  78%|███████▊  | 4957/6336 [02:43<00:45, 30.36it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  78%|███████▊  | 4962/6336 [02:43<00:45, 30.37it/s, v_num=0, train_loss=0.316] \n",
      "Epoch 0:  78%|███████▊  | 4968/6336 [02:43<00:45, 30.38it/s, v_num=0, train_loss=0.0611]\n",
      "Epoch 0:  78%|███████▊  | 4972/6336 [02:43<00:44, 30.39it/s, v_num=0, train_loss=0.239] \n",
      "Epoch 0:  78%|███████▊  | 4973/6336 [02:43<00:44, 30.39it/s, v_num=0, train_loss=0.0235]\n",
      "Epoch 0:  79%|███████▊  | 4978/6336 [02:43<00:44, 30.40it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  79%|███████▊  | 4984/6336 [02:43<00:44, 30.41it/s, v_num=0, train_loss=0.241] \n",
      "Epoch 0:  79%|███████▊  | 4989/6336 [02:43<00:44, 30.42it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  79%|███████▉  | 4992/6336 [02:44<00:44, 30.43it/s, v_num=0, train_loss=0.510]\n",
      "Epoch 0:  79%|███████▉  | 4993/6336 [02:48<00:45, 29.70it/s, v_num=0, train_loss=0.0824]\n",
      "Epoch 0:  79%|███████▉  | 4994/6336 [02:48<00:45, 29.68it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  79%|███████▉  | 4999/6336 [02:48<00:45, 29.66it/s, v_num=0, train_loss=0.0798]\n",
      "Epoch 0:  79%|███████▉  | 5000/6336 [02:48<00:45, 29.67it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  79%|███████▉  | 5007/6336 [02:48<00:44, 29.69it/s, v_num=0, train_loss=0.0364]\n",
      "Epoch 0:  79%|███████▉  | 5014/6336 [02:48<00:44, 29.71it/s, v_num=0, train_loss=0.319] \n",
      "Epoch 0:  79%|███████▉  | 5015/6336 [02:48<00:44, 29.71it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  79%|███████▉  | 5022/6336 [02:48<00:44, 29.73it/s, v_num=0, train_loss=0.445] \n",
      "Epoch 0:  79%|███████▉  | 5023/6336 [02:48<00:44, 29.74it/s, v_num=0, train_loss=0.291]\n",
      "Epoch 0:  79%|███████▉  | 5030/6336 [02:49<00:43, 29.76it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  79%|███████▉  | 5037/6336 [02:49<00:43, 29.78it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  80%|███████▉  | 5044/6336 [02:49<00:43, 29.80it/s, v_num=0, train_loss=0.0439]\n",
      "Epoch 0:  80%|███████▉  | 5049/6336 [02:49<00:43, 29.81it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  80%|███████▉  | 5050/6336 [02:49<00:43, 29.81it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  80%|███████▉  | 5056/6336 [02:49<00:42, 29.83it/s, v_num=0, train_loss=0.0275]\n",
      "Epoch 0:  80%|███████▉  | 5062/6336 [02:49<00:42, 29.84it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:  80%|███████▉  | 5063/6336 [02:49<00:42, 29.85it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  80%|████████  | 5069/6336 [02:49<00:42, 29.86it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  80%|████████  | 5070/6336 [02:49<00:42, 29.87it/s, v_num=0, train_loss=0.160]\n",
      "Epoch 0:  80%|████████  | 5076/6336 [02:49<00:42, 29.88it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  80%|████████  | 5081/6336 [02:49<00:41, 29.89it/s, v_num=0, train_loss=0.057] \n",
      "Epoch 0:  80%|████████  | 5082/6336 [02:49<00:41, 29.89it/s, v_num=0, train_loss=0.173]\n",
      "Epoch 0:  80%|████████  | 5087/6336 [02:50<00:41, 29.90it/s, v_num=0, train_loss=0.190]  \n",
      "Epoch 0:  80%|████████  | 5088/6336 [02:50<00:41, 29.91it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  80%|████████  | 5093/6336 [02:50<00:41, 29.92it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  80%|████████  | 5099/6336 [02:50<00:41, 29.93it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  81%|████████  | 5104/6336 [02:50<00:41, 29.94it/s, v_num=0, train_loss=0.0547]\n",
      "Epoch 0:  81%|████████  | 5105/6336 [02:50<00:41, 29.94it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  81%|████████  | 5106/6336 [02:50<00:41, 29.95it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  81%|████████  | 5111/6336 [02:50<00:40, 29.96it/s, v_num=0, train_loss=0.364]\n",
      "Epoch 0:  81%|████████  | 5112/6336 [02:50<00:40, 29.96it/s, v_num=0, train_loss=0.364]\n",
      "Epoch 0:  81%|████████  | 5112/6336 [02:50<00:40, 29.96it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  81%|████████  | 5118/6336 [02:50<00:40, 29.98it/s, v_num=0, train_loss=0.193] \n",
      "Epoch 0:  81%|████████  | 5119/6336 [02:50<00:40, 29.98it/s, v_num=0, train_loss=0.436]\n",
      "Epoch 0:  81%|████████  | 5125/6336 [02:50<00:40, 30.00it/s, v_num=0, train_loss=0.0526]\n",
      "Epoch 0:  81%|████████  | 5126/6336 [02:50<00:40, 30.00it/s, v_num=0, train_loss=0.0454]\n",
      "Epoch 0:  81%|████████  | 5133/6336 [02:50<00:40, 30.02it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  81%|████████  | 5134/6336 [02:50<00:40, 30.02it/s, v_num=0, train_loss=0.514]\n",
      "Epoch 0:  81%|████████  | 5139/6336 [02:51<00:39, 30.04it/s, v_num=0, train_loss=0.0273]\n",
      "Epoch 0:  81%|████████  | 5140/6336 [02:51<00:39, 30.04it/s, v_num=0, train_loss=0.098] \n",
      "Epoch 0:  81%|████████  | 5146/6336 [02:51<00:39, 30.05it/s, v_num=0, train_loss=0.405] \n",
      "Epoch 0:  81%|████████▏ | 5151/6336 [02:51<00:39, 30.07it/s, v_num=0, train_loss=0.0306]\n",
      "Epoch 0:  81%|████████▏ | 5157/6336 [02:51<00:39, 30.08it/s, v_num=0, train_loss=0.225] \n",
      "Epoch 0:  81%|████████▏ | 5162/6336 [02:51<00:39, 30.09it/s, v_num=0, train_loss=0.0583]\n",
      "Epoch 0:  82%|████████▏ | 5168/6336 [02:51<00:38, 30.10it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  82%|████████▏ | 5169/6336 [02:51<00:38, 30.11it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  82%|████████▏ | 5174/6336 [02:51<00:38, 30.12it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  82%|████████▏ | 5179/6336 [02:51<00:38, 30.13it/s, v_num=0, train_loss=0.281] \n",
      "Epoch 0:  82%|████████▏ | 5180/6336 [02:51<00:38, 30.13it/s, v_num=0, train_loss=0.0747]\n",
      "Epoch 0:  82%|████████▏ | 5185/6336 [02:52<00:38, 30.14it/s, v_num=0, train_loss=0.0831]\n",
      "Epoch 0:  82%|████████▏ | 5189/6336 [02:52<00:38, 30.15it/s, v_num=0, train_loss=0.0812]\n",
      "Epoch 0:  82%|████████▏ | 5190/6336 [02:52<00:38, 30.15it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  82%|████████▏ | 5191/6336 [02:52<00:37, 30.15it/s, v_num=0, train_loss=0.515]\n",
      "Epoch 0:  82%|████████▏ | 5197/6336 [02:52<00:37, 30.16it/s, v_num=0, train_loss=0.0745]\n",
      "Epoch 0:  82%|████████▏ | 5201/6336 [02:52<00:37, 30.17it/s, v_num=0, train_loss=0.0712]\n",
      "Epoch 0:  82%|████████▏ | 5202/6336 [02:52<00:37, 30.17it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  82%|████████▏ | 5203/6336 [02:52<00:37, 30.17it/s, v_num=0, train_loss=0.225]\n",
      "Epoch 0:  82%|████████▏ | 5208/6336 [02:52<00:37, 30.19it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  82%|████████▏ | 5209/6336 [02:52<00:37, 30.19it/s, v_num=0, train_loss=0.0438]\n",
      "Epoch 0:  82%|████████▏ | 5215/6336 [02:52<00:37, 30.20it/s, v_num=0, train_loss=0.268] \n",
      "Epoch 0:  82%|████████▏ | 5216/6336 [02:52<00:37, 30.21it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  82%|████████▏ | 5221/6336 [02:52<00:36, 30.22it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  82%|████████▏ | 5222/6336 [02:52<00:36, 30.22it/s, v_num=0, train_loss=0.299]\n",
      "Epoch 0:  83%|████████▎ | 5228/6336 [02:52<00:36, 30.23it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  83%|████████▎ | 5233/6336 [02:53<00:36, 30.24it/s, v_num=0, train_loss=0.0399]\n",
      "Epoch 0:  83%|████████▎ | 5240/6336 [02:53<00:36, 30.26it/s, v_num=0, train_loss=0.152] \n",
      "Epoch 0:  83%|████████▎ | 5246/6336 [02:53<00:36, 30.28it/s, v_num=0, train_loss=0.0491]\n",
      "Epoch 0:  83%|████████▎ | 5246/6336 [02:53<00:36, 30.28it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  83%|████████▎ | 5247/6336 [02:53<00:35, 30.28it/s, v_num=0, train_loss=0.141]\n",
      "Epoch 0:  83%|████████▎ | 5247/6336 [02:53<00:35, 30.28it/s, v_num=0, train_loss=0.0349]\n",
      "Epoch 0:  83%|████████▎ | 5248/6336 [02:53<00:35, 30.28it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  83%|████████▎ | 5253/6336 [02:53<00:35, 30.29it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  83%|████████▎ | 5254/6336 [02:53<00:35, 30.29it/s, v_num=0, train_loss=0.208]\n",
      "Epoch 0:  83%|████████▎ | 5260/6336 [02:53<00:35, 30.31it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  83%|████████▎ | 5265/6336 [02:53<00:35, 30.32it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  83%|████████▎ | 5271/6336 [02:53<00:35, 30.33it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  83%|████████▎ | 5276/6336 [02:53<00:34, 30.34it/s, v_num=0, train_loss=0.240] \n",
      "Epoch 0:  83%|████████▎ | 5281/6336 [02:54<00:34, 30.35it/s, v_num=0, train_loss=0.0655]\n",
      "Epoch 0:  83%|████████▎ | 5288/6336 [02:54<00:34, 30.37it/s, v_num=0, train_loss=0.349] \n",
      "Epoch 0:  84%|████████▎ | 5293/6336 [02:54<00:34, 30.38it/s, v_num=0, train_loss=0.0331]\n",
      "Epoch 0:  84%|████████▎ | 5299/6336 [02:54<00:34, 30.39it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  84%|████████▎ | 5300/6336 [02:54<00:34, 30.39it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  84%|████████▎ | 5306/6336 [02:54<00:33, 30.41it/s, v_num=0, train_loss=0.0549]\n",
      "Epoch 0:  84%|████████▍ | 5312/6336 [02:54<00:33, 30.42it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  84%|████████▍ | 5313/6336 [02:54<00:33, 30.42it/s, v_num=0, train_loss=0.0398]\n",
      "Epoch 0:  84%|████████▍ | 5319/6336 [02:54<00:33, 30.44it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  84%|████████▍ | 5324/6336 [02:54<00:33, 30.45it/s, v_num=0, train_loss=0.0965]\n",
      "Epoch 0:  84%|████████▍ | 5325/6336 [02:54<00:33, 30.45it/s, v_num=0, train_loss=0.0632]\n",
      "Epoch 0:  84%|████████▍ | 5331/6336 [02:54<00:32, 30.46it/s, v_num=0, train_loss=0.0839]\n",
      "Epoch 0:  84%|████████▍ | 5336/6336 [02:55<00:32, 30.47it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  84%|████████▍ | 5341/6336 [02:55<00:32, 30.48it/s, v_num=0, train_loss=0.0866]\n",
      "Epoch 0:  84%|████████▍ | 5342/6336 [02:55<00:32, 30.48it/s, v_num=0, train_loss=0.0937]\n",
      "Epoch 0:  84%|████████▍ | 5346/6336 [02:55<00:32, 30.49it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  84%|████████▍ | 5350/6336 [02:55<00:32, 30.49it/s, v_num=0, train_loss=0.089] \n",
      "Epoch 0:  84%|████████▍ | 5351/6336 [02:55<00:32, 30.49it/s, v_num=0, train_loss=0.0982]\n",
      "Epoch 0:  85%|████████▍ | 5356/6336 [02:55<00:32, 30.50it/s, v_num=0, train_loss=0.337] \n",
      "Epoch 0:  85%|████████▍ | 5360/6336 [02:55<00:31, 30.50it/s, v_num=0, train_loss=0.0397]\n",
      "Epoch 0:  85%|████████▍ | 5361/6336 [02:55<00:31, 30.51it/s, v_num=0, train_loss=0.0599]\n",
      "Epoch 0:  85%|████████▍ | 5366/6336 [02:55<00:31, 30.51it/s, v_num=0, train_loss=0.082] \n",
      "Epoch 0:  85%|████████▍ | 5372/6336 [02:55<00:31, 30.53it/s, v_num=0, train_loss=0.049]\n",
      "Epoch 0:  85%|████████▍ | 5376/6336 [02:56<00:31, 30.53it/s, v_num=0, train_loss=0.0909]\n",
      "Epoch 0:  85%|████████▍ | 5377/6336 [02:58<00:31, 30.19it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  85%|████████▍ | 5380/6336 [02:59<00:31, 29.95it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  85%|████████▍ | 5381/6336 [02:59<00:31, 29.95it/s, v_num=0, train_loss=0.0883]\n",
      "Epoch 0:  85%|████████▍ | 5383/6336 [02:59<00:31, 29.95it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  85%|████████▍ | 5385/6336 [03:00<00:31, 29.92it/s, v_num=0, train_loss=0.0989]\n",
      "Epoch 0:  85%|████████▌ | 5392/6336 [03:00<00:31, 29.94it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  85%|████████▌ | 5393/6336 [03:00<00:31, 29.94it/s, v_num=0, train_loss=0.0534]\n",
      "Epoch 0:  85%|████████▌ | 5400/6336 [03:00<00:31, 29.96it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  85%|████████▌ | 5406/6336 [03:00<00:31, 29.98it/s, v_num=0, train_loss=0.0542]\n",
      "Epoch 0:  85%|████████▌ | 5407/6336 [03:00<00:30, 29.98it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  85%|████████▌ | 5414/6336 [03:00<00:30, 30.00it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  86%|████████▌ | 5420/6336 [03:00<00:30, 30.01it/s, v_num=0, train_loss=0.0865]\n",
      "Epoch 0:  86%|████████▌ | 5427/6336 [03:00<00:30, 30.03it/s, v_num=0, train_loss=0.189] \n",
      "Epoch 0:  86%|████████▌ | 5428/6336 [03:00<00:30, 30.04it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  86%|████████▌ | 5433/6336 [03:00<00:30, 30.05it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  86%|████████▌ | 5434/6336 [03:00<00:30, 30.05it/s, v_num=0, train_loss=0.082]\n",
      "Epoch 0:  86%|████████▌ | 5439/6336 [03:00<00:29, 30.06it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  86%|████████▌ | 5444/6336 [03:01<00:29, 30.07it/s, v_num=0, train_loss=0.0692]\n",
      "Epoch 0:  86%|████████▌ | 5449/6336 [03:01<00:29, 30.08it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  86%|████████▌ | 5450/6336 [03:01<00:29, 30.08it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  86%|████████▌ | 5450/6336 [03:01<00:29, 30.08it/s, v_num=0, train_loss=0.0343]\n",
      "Epoch 0:  86%|████████▌ | 5456/6336 [03:01<00:29, 30.09it/s, v_num=0, train_loss=0.0394]\n",
      "Epoch 0:  86%|████████▌ | 5462/6336 [03:01<00:29, 30.11it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:  86%|████████▌ | 5463/6336 [03:01<00:28, 30.11it/s, v_num=0, train_loss=0.0857]\n",
      "Epoch 0:  86%|████████▋ | 5468/6336 [03:01<00:28, 30.12it/s, v_num=0, train_loss=0.0285]\n",
      "Epoch 0:  86%|████████▋ | 5473/6336 [03:01<00:28, 30.13it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  86%|████████▋ | 5477/6336 [03:01<00:28, 30.13it/s, v_num=0, train_loss=0.0753]\n",
      "Epoch 0:  87%|████████▋ | 5483/6336 [03:01<00:28, 30.14it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  87%|████████▋ | 5488/6336 [03:01<00:28, 30.15it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  87%|████████▋ | 5489/6336 [03:02<00:28, 30.16it/s, v_num=0, train_loss=0.070]\n",
      "Epoch 0:  87%|████████▋ | 5494/6336 [03:02<00:27, 30.16it/s, v_num=0, train_loss=0.187] \n",
      "Epoch 0:  87%|████████▋ | 5495/6336 [03:02<00:27, 30.17it/s, v_num=0, train_loss=0.289]\n",
      "Epoch 0:  87%|████████▋ | 5502/6336 [03:02<00:27, 30.19it/s, v_num=0, train_loss=0.040] \n",
      "Epoch 0:  87%|████████▋ | 5508/6336 [03:02<00:27, 30.20it/s, v_num=0, train_loss=0.0595]\n",
      "Epoch 0:  87%|████████▋ | 5514/6336 [03:02<00:27, 30.21it/s, v_num=0, train_loss=0.0963]\n",
      "Epoch 0:  87%|████████▋ | 5519/6336 [03:02<00:27, 30.22it/s, v_num=0, train_loss=0.365] \n",
      "Epoch 0:  87%|████████▋ | 5525/6336 [03:02<00:26, 30.24it/s, v_num=0, train_loss=0.0198]\n",
      "Epoch 0:  87%|████████▋ | 5531/6336 [03:02<00:26, 30.25it/s, v_num=0, train_loss=0.177] \n",
      "Epoch 0:  87%|████████▋ | 5536/6336 [03:02<00:26, 30.26it/s, v_num=0, train_loss=0.276] \n",
      "Epoch 0:  87%|████████▋ | 5537/6336 [03:02<00:26, 30.26it/s, v_num=0, train_loss=0.276]\n",
      "Epoch 0:  87%|████████▋ | 5537/6336 [03:02<00:26, 30.26it/s, v_num=0, train_loss=0.0549]\n",
      "Epoch 0:  87%|████████▋ | 5542/6336 [03:03<00:26, 30.27it/s, v_num=0, train_loss=0.256] \n",
      "Epoch 0:  87%|████████▋ | 5543/6336 [03:03<00:26, 30.27it/s, v_num=0, train_loss=0.227]\n",
      "Epoch 0:  88%|████████▊ | 5548/6336 [03:03<00:26, 30.28it/s, v_num=0, train_loss=0.234] \n",
      "Epoch 0:  88%|████████▊ | 5549/6336 [03:03<00:25, 30.28it/s, v_num=0, train_loss=0.0186]\n",
      "Epoch 0:  88%|████████▊ | 5555/6336 [03:03<00:25, 30.30it/s, v_num=0, train_loss=0.215] \n",
      "Epoch 0:  88%|████████▊ | 5561/6336 [03:03<00:25, 30.31it/s, v_num=0, train_loss=0.0242]\n",
      "Epoch 0:  88%|████████▊ | 5566/6336 [03:03<00:25, 30.32it/s, v_num=0, train_loss=0.301] \n",
      "Epoch 0:  88%|████████▊ | 5567/6336 [03:03<00:25, 30.32it/s, v_num=0, train_loss=0.257]\n",
      "Epoch 0:  88%|████████▊ | 5572/6336 [03:03<00:25, 30.33it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  88%|████████▊ | 5576/6336 [03:03<00:25, 30.34it/s, v_num=0, train_loss=0.0559]\n",
      "Epoch 0:  88%|████████▊ | 5577/6336 [03:03<00:25, 30.34it/s, v_num=0, train_loss=0.237] \n",
      "Epoch 0:  88%|████████▊ | 5582/6336 [03:03<00:24, 30.35it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  88%|████████▊ | 5583/6336 [03:03<00:24, 30.35it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  88%|████████▊ | 5589/6336 [03:04<00:24, 30.36it/s, v_num=0, train_loss=0.445] \n",
      "Epoch 0:  88%|████████▊ | 5594/6336 [03:04<00:24, 30.37it/s, v_num=0, train_loss=0.0831]\n",
      "Epoch 0:  88%|████████▊ | 5600/6336 [03:04<00:24, 30.38it/s, v_num=0, train_loss=0.0148]\n",
      "Epoch 0:  88%|████████▊ | 5601/6336 [03:04<00:24, 30.39it/s, v_num=0, train_loss=0.444] \n",
      "Epoch 0:  88%|████████▊ | 5607/6336 [03:04<00:23, 30.40it/s, v_num=0, train_loss=0.0961]\n",
      "Epoch 0:  89%|████████▊ | 5608/6336 [03:04<00:23, 30.41it/s, v_num=0, train_loss=0.0913]\n",
      "Epoch 0:  89%|████████▊ | 5614/6336 [03:04<00:23, 30.42it/s, v_num=0, train_loss=0.316] \n",
      "Epoch 0:  89%|████████▊ | 5615/6336 [03:04<00:23, 30.42it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  89%|████████▊ | 5616/6336 [03:04<00:23, 30.43it/s, v_num=0, train_loss=0.336]\n",
      "Epoch 0:  89%|████████▊ | 5622/6336 [03:04<00:23, 30.44it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  89%|████████▊ | 5623/6336 [03:04<00:23, 30.44it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  89%|████████▉ | 5629/6336 [03:04<00:23, 30.46it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  89%|████████▉ | 5635/6336 [03:04<00:23, 30.47it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  89%|████████▉ | 5641/6336 [03:05<00:22, 30.49it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  89%|████████▉ | 5642/6336 [03:05<00:22, 30.49it/s, v_num=0, train_loss=0.0327]\n",
      "Epoch 0:  89%|████████▉ | 5647/6336 [03:05<00:22, 30.50it/s, v_num=0, train_loss=0.0241]\n",
      "Epoch 0:  89%|████████▉ | 5648/6336 [03:05<00:22, 30.50it/s, v_num=0, train_loss=0.0174]\n",
      "Epoch 0:  89%|████████▉ | 5655/6336 [03:05<00:22, 30.52it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  89%|████████▉ | 5660/6336 [03:05<00:22, 30.53it/s, v_num=0, train_loss=0.00958]\n",
      "Epoch 0:  89%|████████▉ | 5661/6336 [03:05<00:22, 30.53it/s, v_num=0, train_loss=0.195]  \n",
      "Epoch 0:  89%|████████▉ | 5668/6336 [03:05<00:21, 30.55it/s, v_num=0, train_loss=0.0472]\n",
      "Epoch 0:  90%|████████▉ | 5674/6336 [03:05<00:21, 30.56it/s, v_num=0, train_loss=0.344] \n",
      "Epoch 0:  90%|████████▉ | 5675/6336 [03:05<00:21, 30.56it/s, v_num=0, train_loss=0.344]\n",
      "Epoch 0:  90%|████████▉ | 5675/6336 [03:05<00:21, 30.56it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  90%|████████▉ | 5681/6336 [03:05<00:21, 30.58it/s, v_num=0, train_loss=0.0702]\n",
      "Epoch 0:  90%|████████▉ | 5682/6336 [03:05<00:21, 30.58it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:  90%|████████▉ | 5687/6336 [03:05<00:21, 30.59it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  90%|████████▉ | 5688/6336 [03:05<00:21, 30.59it/s, v_num=0, train_loss=0.0405]\n",
      "Epoch 0:  90%|████████▉ | 5693/6336 [03:06<00:21, 30.60it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  90%|████████▉ | 5694/6336 [03:06<00:20, 30.61it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  90%|████████▉ | 5699/6336 [03:06<00:20, 30.61it/s, v_num=0, train_loss=0.0719]\n",
      "Epoch 0:  90%|████████▉ | 5700/6336 [03:06<00:20, 30.62it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  90%|█████████ | 5707/6336 [03:06<00:20, 30.64it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  90%|█████████ | 5712/6336 [03:06<00:20, 30.65it/s, v_num=0, train_loss=0.0479]\n",
      "Epoch 0:  90%|█████████ | 5717/6336 [03:06<00:20, 30.65it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  90%|█████████ | 5722/6336 [03:06<00:20, 30.66it/s, v_num=0, train_loss=0.375] \n",
      "Epoch 0:  90%|█████████ | 5727/6336 [03:06<00:19, 30.67it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  90%|█████████ | 5731/6336 [03:06<00:19, 30.67it/s, v_num=0, train_loss=0.0415]\n",
      "Epoch 0:  90%|█████████ | 5732/6336 [03:06<00:19, 30.67it/s, v_num=0, train_loss=0.0153]\n",
      "Epoch 0:  91%|█████████ | 5736/6336 [03:06<00:19, 30.68it/s, v_num=0, train_loss=0.0581]\n",
      "Epoch 0:  91%|█████████ | 5740/6336 [03:07<00:19, 30.68it/s, v_num=0, train_loss=0.0999]\n",
      "Epoch 0:  91%|█████████ | 5744/6336 [03:07<00:19, 30.68it/s, v_num=0, train_loss=0.0652]\n",
      "Epoch 0:  91%|█████████ | 5749/6336 [03:07<00:19, 30.69it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  91%|█████████ | 5753/6336 [03:07<00:18, 30.69it/s, v_num=0, train_loss=0.064] \n",
      "Epoch 0:  91%|█████████ | 5758/6336 [03:07<00:18, 30.70it/s, v_num=0, train_loss=0.337] \n",
      "Epoch 0:  91%|█████████ | 5760/6336 [03:07<00:18, 30.70it/s, v_num=0, train_loss=0.0598]\n",
      "Epoch 0:  91%|█████████ | 5766/6336 [03:10<00:18, 30.22it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  91%|█████████ | 5768/6336 [03:10<00:18, 30.21it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  91%|█████████ | 5769/6336 [03:10<00:18, 30.21it/s, v_num=0, train_loss=0.132]\n",
      "Epoch 0:  91%|█████████ | 5774/6336 [03:11<00:18, 30.20it/s, v_num=0, train_loss=0.199] \n",
      "Epoch 0:  91%|█████████ | 5781/6336 [03:11<00:18, 30.22it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  91%|█████████▏| 5782/6336 [03:11<00:18, 30.22it/s, v_num=0, train_loss=0.0588]\n",
      "Epoch 0:  91%|█████████▏| 5783/6336 [03:11<00:18, 30.23it/s, v_num=0, train_loss=0.0638]\n",
      "Epoch 0:  91%|█████████▏| 5790/6336 [03:11<00:18, 30.25it/s, v_num=0, train_loss=0.261] \n",
      "Epoch 0:  91%|█████████▏| 5791/6336 [03:11<00:18, 30.25it/s, v_num=0, train_loss=0.320]\n",
      "Epoch 0:  91%|█████████▏| 5792/6336 [03:11<00:17, 30.25it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  92%|█████████▏| 5798/6336 [03:11<00:17, 30.27it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  92%|█████████▏| 5799/6336 [03:11<00:17, 30.27it/s, v_num=0, train_loss=0.0574]\n",
      "Epoch 0:  92%|█████████▏| 5806/6336 [03:11<00:17, 30.29it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  92%|█████████▏| 5807/6336 [03:11<00:17, 30.29it/s, v_num=0, train_loss=0.0876]\n",
      "Epoch 0:  92%|█████████▏| 5808/6336 [03:11<00:17, 30.29it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  92%|█████████▏| 5815/6336 [03:11<00:17, 30.31it/s, v_num=0, train_loss=0.226] \n",
      "Epoch 0:  92%|█████████▏| 5816/6336 [03:11<00:17, 30.32it/s, v_num=0, train_loss=0.0798]\n",
      "Epoch 0:  92%|█████████▏| 5822/6336 [03:11<00:16, 30.33it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  92%|█████████▏| 5823/6336 [03:11<00:16, 30.33it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  92%|█████████▏| 5829/6336 [03:12<00:16, 30.35it/s, v_num=0, train_loss=0.369]\n",
      "Epoch 0:  92%|█████████▏| 5830/6336 [03:12<00:16, 30.35it/s, v_num=0, train_loss=0.0771]\n",
      "Epoch 0:  92%|█████████▏| 5836/6336 [03:12<00:16, 30.36it/s, v_num=0, train_loss=0.0954]\n",
      "Epoch 0:  92%|█████████▏| 5842/6336 [03:12<00:16, 30.38it/s, v_num=0, train_loss=0.0756]\n",
      "Epoch 0:  92%|█████████▏| 5848/6336 [03:12<00:16, 30.39it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  92%|█████████▏| 5853/6336 [03:12<00:15, 30.40it/s, v_num=0, train_loss=0.251] \n",
      "Epoch 0:  92%|█████████▏| 5859/6336 [03:12<00:15, 30.41it/s, v_num=0, train_loss=0.0578]\n",
      "Epoch 0:  93%|█████████▎| 5864/6336 [03:12<00:15, 30.41it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  93%|█████████▎| 5868/6336 [03:12<00:15, 30.42it/s, v_num=0, train_loss=0.216] \n",
      "Epoch 0:  93%|█████████▎| 5869/6336 [03:12<00:15, 30.42it/s, v_num=0, train_loss=0.0216]\n",
      "Epoch 0:  93%|█████████▎| 5874/6336 [03:13<00:15, 30.43it/s, v_num=0, train_loss=0.0747]\n",
      "Epoch 0:  93%|█████████▎| 5880/6336 [03:13<00:14, 30.44it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  93%|█████████▎| 5886/6336 [03:13<00:14, 30.46it/s, v_num=0, train_loss=0.0432]\n",
      "Epoch 0:  93%|█████████▎| 5887/6336 [03:13<00:14, 30.46it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  93%|█████████▎| 5892/6336 [03:13<00:14, 30.47it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  93%|█████████▎| 5893/6336 [03:13<00:14, 30.47it/s, v_num=0, train_loss=0.0273]\n",
      "Epoch 0:  93%|█████████▎| 5894/6336 [03:13<00:14, 30.47it/s, v_num=0, train_loss=0.264] \n",
      "Epoch 0:  93%|█████████▎| 5900/6336 [03:13<00:14, 30.49it/s, v_num=0, train_loss=0.174] \n",
      "Epoch 0:  93%|█████████▎| 5901/6336 [03:13<00:14, 30.49it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  93%|█████████▎| 5907/6336 [03:13<00:14, 30.50it/s, v_num=0, train_loss=0.0459]\n",
      "Epoch 0:  93%|█████████▎| 5908/6336 [03:13<00:14, 30.51it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  93%|█████████▎| 5914/6336 [03:13<00:13, 30.52it/s, v_num=0, train_loss=0.0423]\n",
      "Epoch 0:  93%|█████████▎| 5920/6336 [03:13<00:13, 30.53it/s, v_num=0, train_loss=0.288] \n",
      "Epoch 0:  94%|█████████▎| 5927/6336 [03:14<00:13, 30.55it/s, v_num=0, train_loss=0.0499]\n",
      "Epoch 0:  94%|█████████▎| 5932/6336 [03:14<00:13, 30.56it/s, v_num=0, train_loss=0.205] \n",
      "Epoch 0:  94%|█████████▎| 5933/6336 [03:14<00:13, 30.56it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  94%|█████████▎| 5939/6336 [03:14<00:12, 30.58it/s, v_num=0, train_loss=0.0956]\n",
      "Epoch 0:  94%|█████████▍| 5940/6336 [03:14<00:12, 30.58it/s, v_num=0, train_loss=0.272] \n",
      "Epoch 0:  94%|█████████▍| 5946/6336 [03:14<00:12, 30.59it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  94%|█████████▍| 5947/6336 [03:14<00:12, 30.59it/s, v_num=0, train_loss=0.0274]\n",
      "Epoch 0:  94%|█████████▍| 5954/6336 [03:14<00:12, 30.61it/s, v_num=0, train_loss=0.339] \n",
      "Epoch 0:  94%|█████████▍| 5955/6336 [03:14<00:12, 30.62it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  94%|█████████▍| 5956/6336 [03:14<00:12, 30.62it/s, v_num=0, train_loss=0.366]\n",
      "Epoch 0:  94%|█████████▍| 5962/6336 [03:14<00:12, 30.63it/s, v_num=0, train_loss=0.0855]\n",
      "Epoch 0:  94%|█████████▍| 5963/6336 [03:14<00:12, 30.64it/s, v_num=0, train_loss=0.0863]\n",
      "Epoch 0:  94%|█████████▍| 5964/6336 [03:14<00:12, 30.64it/s, v_num=0, train_loss=0.194] \n",
      "Epoch 0:  94%|█████████▍| 5970/6336 [03:14<00:11, 30.65it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  94%|█████████▍| 5971/6336 [03:14<00:11, 30.65it/s, v_num=0, train_loss=0.0577]\n",
      "Epoch 0:  94%|█████████▍| 5978/6336 [03:14<00:11, 30.67it/s, v_num=0, train_loss=0.479] \n",
      "Epoch 0:  94%|█████████▍| 5985/6336 [03:15<00:11, 30.69it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  95%|█████████▍| 5991/6336 [03:15<00:11, 30.70it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  95%|█████████▍| 5997/6336 [03:15<00:11, 30.71it/s, v_num=0, train_loss=0.294] \n",
      "Epoch 0:  95%|█████████▍| 5998/6336 [03:15<00:11, 30.72it/s, v_num=0, train_loss=0.0943]\n",
      "Epoch 0:  95%|█████████▍| 6004/6336 [03:15<00:10, 30.73it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  95%|█████████▍| 6011/6336 [03:15<00:10, 30.75it/s, v_num=0, train_loss=0.0666]\n",
      "Epoch 0:  95%|█████████▍| 6012/6336 [03:15<00:10, 30.75it/s, v_num=0, train_loss=0.409] \n",
      "Epoch 0:  95%|█████████▌| 6020/6336 [03:15<00:10, 30.77it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:  95%|█████████▌| 6026/6336 [03:15<00:10, 30.79it/s, v_num=0, train_loss=0.286] \n",
      "Epoch 0:  95%|█████████▌| 6027/6336 [03:15<00:10, 30.79it/s, v_num=0, train_loss=0.224]\n",
      "Epoch 0:  95%|█████████▌| 6028/6336 [03:15<00:10, 30.79it/s, v_num=0, train_loss=0.224]\n",
      "Epoch 0:  95%|█████████▌| 6028/6336 [03:15<00:10, 30.79it/s, v_num=0, train_loss=0.287]\n",
      "Epoch 0:  95%|█████████▌| 6034/6336 [03:15<00:09, 30.80it/s, v_num=0, train_loss=0.0582]\n",
      "Epoch 0:  95%|█████████▌| 6035/6336 [03:15<00:09, 30.81it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  95%|█████████▌| 6043/6336 [03:16<00:09, 30.83it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  95%|█████████▌| 6044/6336 [03:16<00:09, 30.83it/s, v_num=0, train_loss=0.248]\n",
      "Epoch 0:  96%|█████████▌| 6051/6336 [03:16<00:09, 30.85it/s, v_num=0, train_loss=0.298] \n",
      "Epoch 0:  96%|█████████▌| 6052/6336 [03:16<00:09, 30.85it/s, v_num=0, train_loss=0.618]\n",
      "Epoch 0:  96%|█████████▌| 6059/6336 [03:16<00:08, 30.87it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  96%|█████████▌| 6066/6336 [03:16<00:08, 30.89it/s, v_num=0, train_loss=0.283] \n",
      "Epoch 0:  96%|█████████▌| 6067/6336 [03:16<00:08, 30.89it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  96%|█████████▌| 6074/6336 [03:16<00:08, 30.91it/s, v_num=0, train_loss=0.257] \n",
      "Epoch 0:  96%|█████████▌| 6075/6336 [03:16<00:08, 30.91it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  96%|█████████▌| 6082/6336 [03:16<00:08, 30.93it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  96%|█████████▌| 6088/6336 [03:16<00:08, 30.94it/s, v_num=0, train_loss=0.373] \n",
      "Epoch 0:  96%|█████████▌| 6089/6336 [03:16<00:07, 30.95it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  96%|█████████▌| 6094/6336 [03:16<00:07, 30.95it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  96%|█████████▌| 6095/6336 [03:16<00:07, 30.96it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:  96%|█████████▋| 6101/6336 [03:16<00:07, 30.97it/s, v_num=0, train_loss=0.0984]\n",
      "Epoch 0:  96%|█████████▋| 6102/6336 [03:17<00:07, 30.97it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  96%|█████████▋| 6108/6336 [03:17<00:07, 30.99it/s, v_num=0, train_loss=0.227] \n",
      "Epoch 0:  96%|█████████▋| 6109/6336 [03:17<00:07, 30.99it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  96%|█████████▋| 6114/6336 [03:17<00:07, 31.00it/s, v_num=0, train_loss=0.149]\n",
      "Epoch 0:  97%|█████████▋| 6120/6336 [03:17<00:06, 31.01it/s, v_num=0, train_loss=0.402] \n",
      "Epoch 0:  97%|█████████▋| 6125/6336 [03:17<00:06, 31.02it/s, v_num=0, train_loss=0.319]\n",
      "Epoch 0:  97%|█████████▋| 6126/6336 [03:17<00:06, 31.02it/s, v_num=0, train_loss=0.201]\n",
      "Epoch 0:  97%|█████████▋| 6130/6336 [03:17<00:06, 31.02it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  97%|█████████▋| 6135/6336 [03:17<00:06, 31.03it/s, v_num=0, train_loss=0.479]\n",
      "Epoch 0:  97%|█████████▋| 6136/6336 [03:17<00:06, 31.03it/s, v_num=0, train_loss=0.308]\n",
      "Epoch 0:  97%|█████████▋| 6140/6336 [03:17<00:06, 31.03it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  97%|█████████▋| 6141/6336 [03:17<00:06, 31.03it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  97%|█████████▋| 6144/6336 [03:17<00:06, 31.04it/s, v_num=0, train_loss=0.321]\n",
      "Epoch 0:  97%|█████████▋| 6145/6336 [03:19<00:06, 30.74it/s, v_num=0, train_loss=0.215]\n",
      "Epoch 0:  97%|█████████▋| 6146/6336 [03:20<00:06, 30.66it/s, v_num=0, train_loss=0.301]\n",
      "Epoch 0:  97%|█████████▋| 6147/6336 [03:20<00:06, 30.66it/s, v_num=0, train_loss=0.301]\n",
      "Epoch 0:  97%|█████████▋| 6147/6336 [03:20<00:06, 30.66it/s, v_num=0, train_loss=0.302]\n",
      "Epoch 0:  97%|█████████▋| 6153/6336 [03:20<00:05, 30.68it/s, v_num=0, train_loss=0.418] \n",
      "Epoch 0:  97%|█████████▋| 6154/6336 [03:20<00:05, 30.68it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  97%|█████████▋| 6161/6336 [03:20<00:05, 30.70it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  97%|█████████▋| 6167/6336 [03:20<00:05, 30.71it/s, v_num=0, train_loss=0.264] \n",
      "Epoch 0:  97%|█████████▋| 6168/6336 [03:20<00:05, 30.71it/s, v_num=0, train_loss=0.0472]\n",
      "Epoch 0:  97%|█████████▋| 6174/6336 [03:20<00:05, 30.72it/s, v_num=0, train_loss=0.0277]\n",
      "Epoch 0:  98%|█████████▊| 6181/6336 [03:21<00:05, 30.74it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  98%|█████████▊| 6182/6336 [03:21<00:05, 30.74it/s, v_num=0, train_loss=0.160]\n",
      "Epoch 0:  98%|█████████▊| 6183/6336 [03:21<00:04, 30.75it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:  98%|█████████▊| 6189/6336 [03:21<00:04, 30.76it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  98%|█████████▊| 6195/6336 [03:21<00:04, 30.77it/s, v_num=0, train_loss=0.227] \n",
      "Epoch 0:  98%|█████████▊| 6196/6336 [03:21<00:04, 30.77it/s, v_num=0, train_loss=0.0432]\n",
      "Epoch 0:  98%|█████████▊| 6201/6336 [03:21<00:04, 30.78it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  98%|█████████▊| 6202/6336 [03:21<00:04, 30.78it/s, v_num=0, train_loss=0.0456]\n",
      "Epoch 0:  98%|█████████▊| 6208/6336 [03:21<00:04, 30.80it/s, v_num=0, train_loss=0.0235]\n",
      "Epoch 0:  98%|█████████▊| 6214/6336 [03:21<00:03, 30.81it/s, v_num=0, train_loss=0.0312]\n",
      "Epoch 0:  98%|█████████▊| 6219/6336 [03:21<00:03, 30.81it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  98%|█████████▊| 6220/6336 [03:21<00:03, 30.82it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  98%|█████████▊| 6226/6336 [03:21<00:03, 30.83it/s, v_num=0, train_loss=0.0645]\n",
      "Epoch 0:  98%|█████████▊| 6227/6336 [03:21<00:03, 30.83it/s, v_num=0, train_loss=0.467] \n",
      "Epoch 0:  98%|█████████▊| 6233/6336 [03:22<00:03, 30.84it/s, v_num=0, train_loss=0.457] \n",
      "Epoch 0:  98%|█████████▊| 6239/6336 [03:22<00:03, 30.86it/s, v_num=0, train_loss=0.422] \n",
      "Epoch 0:  99%|█████████▊| 6245/6336 [03:22<00:02, 30.87it/s, v_num=0, train_loss=0.231] \n",
      "Epoch 0:  99%|█████████▊| 6252/6336 [03:22<00:02, 30.88it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  99%|█████████▉| 6258/6336 [03:22<00:02, 30.89it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:  99%|█████████▉| 6263/6336 [03:22<00:02, 30.90it/s, v_num=0, train_loss=0.187] \n",
      "Epoch 0:  99%|█████████▉| 6264/6336 [03:22<00:02, 30.90it/s, v_num=0, train_loss=0.0496]\n",
      "Epoch 0:  99%|█████████▉| 6269/6336 [03:22<00:02, 30.91it/s, v_num=0, train_loss=0.298] \n",
      "Epoch 0:  99%|█████████▉| 6270/6336 [03:22<00:02, 30.91it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  99%|█████████▉| 6275/6336 [03:22<00:01, 30.92it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  99%|█████████▉| 6281/6336 [03:23<00:01, 30.93it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  99%|█████████▉| 6286/6336 [03:23<00:01, 30.94it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  99%|█████████▉| 6287/6336 [03:23<00:01, 30.94it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  99%|█████████▉| 6292/6336 [03:23<00:01, 30.95it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  99%|█████████▉| 6298/6336 [03:23<00:01, 30.96it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  99%|█████████▉| 6299/6336 [03:23<00:01, 30.96it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0: 100%|█████████▉| 6306/6336 [03:23<00:00, 30.98it/s, v_num=0, train_loss=0.234] \n",
      "Epoch 0: 100%|█████████▉| 6311/6336 [03:23<00:00, 30.99it/s, v_num=0, train_loss=0.0593]\n",
      "Epoch 0: 100%|█████████▉| 6312/6336 [03:23<00:00, 30.99it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0: 100%|█████████▉| 6319/6336 [03:23<00:00, 31.01it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0: 100%|█████████▉| 6320/6336 [03:23<00:00, 31.01it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0: 100%|█████████▉| 6326/6336 [03:23<00:00, 31.02it/s, v_num=0, train_loss=0.0875]\n",
      "Epoch 0: 100%|█████████▉| 6334/6336 [03:24<00:00, 31.04it/s, v_num=0, train_loss=0.250] \n",
      "Epoch 0: 100%|██████████| 6336/6336 [03:24<00:00, 31.05it/s, v_num=0, train_loss=0.281]\n",
      "Epoch 0: 100%|██████████| 6336/6336 [03:24<00:00, 31.02it/s, v_num=0, train_loss=0.281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/nam/protoplast_results/TorchTrainer_2025-09-19_06-49-40/TorchTrainer_d1335_00000_0_2025-09-19_06-49-40/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 6336/6336 [03:24<00:00, 31.00it/s, v_num=0, train_loss=0.281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=434570)\u001b[0m [rank0]:[W919 06:53:31.467319817 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "# Set up training\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,\n",
    "    DistributedCellLineAnnDataset,\n",
    "    model_keys = [\"num_genes\",\n",
    "                  \"num_classes\"],\n",
    "    metadata_cb = cell_line_metadata_cb,\n",
    "    sparse_keys = \"X\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(result.checkpoint.path, \"checkpoint.ckpt\")\n",
    "\n",
    "result = trainer.train([DS_PATHS[1]],\n",
    "                       batch_size = 1024,\n",
    "                       test_size = test_size, \n",
    "                       val_size = val_size,\n",
    "                       num_workers = 1,\n",
    "                       resource_per_worker = {\"GPU\": 1, \"CPU\": thread_per_worker})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f424dd0-f4f3-40cb-bbdc-dcd9f7651852",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This brings us to the end of the tutorial notebook.\n",
    "\n",
    "This workflow highlights using checkpointing in **PROTOplast**, enabling efficient model development across diverse datasets.\n",
    "\n",
    "Feel free to explore and extend this notebook to suit your own data and use cases!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
