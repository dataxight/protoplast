{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b05804-762a-43b2-b025-cbe5cac5ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix, csr_matrix, vstack as sparse_vstack\n",
    "from adata_utils import fix_genes_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbea37bb-4730-4888-af48-039b8d61e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jiang = ad.read_h5ad(\"/mnt/hdd2/tan/perturbench/jiang24_preprocessed.h5ad\", backed=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca58f38-8e58-4301-9bf6-1ee207488cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jiang_adata = ad.AnnData(X=jiang.layers[\"counts\"], obs=jiang.obs.copy(), var=jiang.var.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f937890b-9691-4baa-ac0c-75c01305282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(jiang_adata, target_sum=1e4)\n",
    "sc.pp.log1p(jiang_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a093e9a-1b75-4966-b761-2af60f553583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18080, ['SAMD11', 'NOC2L', 'KLHL17', 'PLEKHN1', 'PERM1'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_names = open(\"./gene_names.csv\").read().splitlines()\n",
    "len(gene_names), gene_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94cd53a1-da6b-4d56-8248-7e96d580cf38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0/162\n",
      "Processing chunk 1/162\n",
      "Processing chunk 2/162\n",
      "Processing chunk 3/162\n",
      "Processing chunk 4/162\n",
      "Processing chunk 5/162\n",
      "Processing chunk 6/162\n",
      "Processing chunk 7/162\n",
      "Processing chunk 8/162\n",
      "Processing chunk 9/162\n",
      "Processing chunk 10/162\n",
      "Processing chunk 11/162\n",
      "Processing chunk 12/162\n",
      "Processing chunk 13/162\n",
      "Processing chunk 14/162\n",
      "Processing chunk 15/162\n",
      "Processing chunk 16/162\n",
      "Processing chunk 17/162\n",
      "Processing chunk 18/162\n",
      "Processing chunk 19/162\n",
      "Processing chunk 20/162\n",
      "Processing chunk 21/162\n",
      "Processing chunk 22/162\n",
      "Processing chunk 23/162\n",
      "Processing chunk 24/162\n",
      "Processing chunk 25/162\n",
      "Processing chunk 26/162\n",
      "Processing chunk 27/162\n",
      "Processing chunk 28/162\n",
      "Processing chunk 29/162\n",
      "Processing chunk 30/162\n",
      "Processing chunk 31/162\n",
      "Processing chunk 32/162\n",
      "Processing chunk 33/162\n",
      "Processing chunk 34/162\n",
      "Processing chunk 35/162\n",
      "Processing chunk 36/162\n",
      "Processing chunk 37/162\n",
      "Processing chunk 38/162\n",
      "Processing chunk 39/162\n",
      "Processing chunk 40/162\n",
      "Processing chunk 41/162\n",
      "Processing chunk 42/162\n",
      "Processing chunk 43/162\n",
      "Processing chunk 44/162\n",
      "Processing chunk 45/162\n",
      "Processing chunk 46/162\n",
      "Processing chunk 47/162\n",
      "Processing chunk 48/162\n",
      "Processing chunk 49/162\n",
      "Processing chunk 50/162\n",
      "Processing chunk 51/162\n",
      "Processing chunk 52/162\n",
      "Processing chunk 53/162\n",
      "Processing chunk 54/162\n",
      "Processing chunk 55/162\n",
      "Processing chunk 56/162\n",
      "Processing chunk 57/162\n",
      "Processing chunk 58/162\n",
      "Processing chunk 59/162\n",
      "Processing chunk 60/162\n",
      "Processing chunk 61/162\n",
      "Processing chunk 62/162\n",
      "Processing chunk 63/162\n",
      "Processing chunk 64/162\n",
      "Processing chunk 65/162\n",
      "Processing chunk 66/162\n",
      "Processing chunk 67/162\n",
      "Processing chunk 68/162\n",
      "Processing chunk 69/162\n",
      "Processing chunk 70/162\n",
      "Processing chunk 71/162\n",
      "Processing chunk 72/162\n",
      "Processing chunk 73/162\n",
      "Processing chunk 74/162\n",
      "Processing chunk 75/162\n",
      "Processing chunk 76/162\n",
      "Processing chunk 77/162\n",
      "Processing chunk 78/162\n",
      "Processing chunk 79/162\n",
      "Processing chunk 80/162\n",
      "Processing chunk 81/162\n",
      "Processing chunk 82/162\n",
      "Processing chunk 83/162\n",
      "Processing chunk 84/162\n",
      "Processing chunk 85/162\n",
      "Processing chunk 86/162\n",
      "Processing chunk 87/162\n",
      "Processing chunk 88/162\n",
      "Processing chunk 89/162\n",
      "Processing chunk 90/162\n",
      "Processing chunk 91/162\n",
      "Processing chunk 92/162\n",
      "Processing chunk 93/162\n",
      "Processing chunk 94/162\n",
      "Processing chunk 95/162\n",
      "Processing chunk 96/162\n",
      "Processing chunk 97/162\n",
      "Processing chunk 98/162\n",
      "Processing chunk 99/162\n",
      "Processing chunk 100/162\n",
      "Processing chunk 101/162\n",
      "Processing chunk 102/162\n",
      "Processing chunk 103/162\n",
      "Processing chunk 104/162\n",
      "Processing chunk 105/162\n",
      "Processing chunk 106/162\n",
      "Processing chunk 107/162\n",
      "Processing chunk 108/162\n",
      "Processing chunk 109/162\n",
      "Processing chunk 110/162\n",
      "Processing chunk 111/162\n",
      "Processing chunk 112/162\n",
      "Processing chunk 113/162\n",
      "Processing chunk 114/162\n",
      "Processing chunk 115/162\n",
      "Processing chunk 116/162\n",
      "Processing chunk 117/162\n",
      "Processing chunk 118/162\n",
      "Processing chunk 119/162\n",
      "Processing chunk 120/162\n",
      "Processing chunk 121/162\n",
      "Processing chunk 122/162\n",
      "Processing chunk 123/162\n",
      "Processing chunk 124/162\n",
      "Processing chunk 125/162\n",
      "Processing chunk 126/162\n",
      "Processing chunk 127/162\n",
      "Processing chunk 128/162\n",
      "Processing chunk 129/162\n",
      "Processing chunk 130/162\n",
      "Processing chunk 131/162\n",
      "Processing chunk 132/162\n",
      "Processing chunk 133/162\n",
      "Processing chunk 134/162\n",
      "Processing chunk 135/162\n",
      "Processing chunk 136/162\n",
      "Processing chunk 137/162\n",
      "Processing chunk 138/162\n",
      "Processing chunk 139/162\n",
      "Processing chunk 140/162\n",
      "Processing chunk 141/162\n",
      "Processing chunk 142/162\n",
      "Processing chunk 143/162\n",
      "Processing chunk 144/162\n",
      "Processing chunk 145/162\n",
      "Processing chunk 146/162\n",
      "Processing chunk 147/162\n",
      "Processing chunk 148/162\n",
      "Processing chunk 149/162\n",
      "Processing chunk 150/162\n",
      "Processing chunk 151/162\n",
      "Processing chunk 152/162\n",
      "Processing chunk 153/162\n",
      "Processing chunk 154/162\n",
      "Processing chunk 155/162\n",
      "Processing chunk 156/162\n",
      "Processing chunk 157/162\n",
      "Processing chunk 158/162\n",
      "Processing chunk 159/162\n",
      "Processing chunk 160/162\n",
      "Processing chunk 161/162\n",
      "Processing chunk 162/162\n"
     ]
    }
   ],
   "source": [
    "adata = fix_genes_chunked(jiang_adata, gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f22231-a1ff-4bc0-96c9-69c7bc5a78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.drop(columns=[\"highly_variable\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3593e2-ac4b-4850-9e6e-a51ccf578d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene = adata.obs[\"gene\"].tolist()\n",
    "for i, val in enumerate(target_gene):\n",
    "    vals = [val, \"non-targeting\"]\n",
    "    target_gene[i] = vals[int(val == \"NT\")]\n",
    "adata.obs[\"target_gene\"] = target_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbfcc7e-15e8-4143-9a6e-b50ed818b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"batch_var\"] = adata.obs[\"Batch_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa80265-4e17-45a2-a997-f28198346822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a549', 'bxpc3', 'hap1', 'ht29', 'k562', 'mcf7']\n",
       "Categories (6, object): ['a549', 'bxpc3', 'hap1', 'ht29', 'k562', 'mcf7']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.cell_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4da753-8498-4bf6-aba1-fa7476710d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell type:  a549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_core/anndata.py:1175: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell type:  bxpc3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_core/anndata.py:1175: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell type:  hap1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_core/anndata.py:1175: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell type:  ht29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_core/anndata.py:1175: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell type:  k562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_core/anndata.py:1175: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "ename": "BlockingIOError",
     "evalue": "[Errno 11] Unable to synchronously create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBlockingIOError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m ct_adata = adata[adata.obs.cell_type == cell_type, ]\n\u001b[32m      5\u001b[39m ct_adata = ct_adata[ct_adata.obs.target_gene.sort_values().index, ]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mct_adata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/jiang_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcell_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:82\u001b[39m, in \u001b[36mlegacy_api.<locals>.wrapper.<locals>.fn_compatible\u001b[39m\u001b[34m(*args_all, **kw)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_compatible\u001b[39m(*args_all: P.args, **kw: P.kwargs) -> R:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_all) <= n_positional:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     args_pos: P.args\n\u001b[32m     85\u001b[39m     args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_core/anndata.py:1902\u001b[39m, in \u001b[36mAnnData.write_h5ad\u001b[39m\u001b[34m(self, filename, convert_strings_to_categoricals, compression, compression_opts, as_dense)\u001b[39m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     filename = \u001b[38;5;28mself\u001b[39m.filename\n\u001b[32m-> \u001b[39m\u001b[32m1902\u001b[39m \u001b[43mwrite_h5ad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_strings_to_categoricals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_strings_to_categoricals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_dense\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_dense\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isbacked:\n\u001b[32m   1912\u001b[39m     \u001b[38;5;28mself\u001b[39m.file.filename = filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_io/utils.py:325\u001b[39m, in \u001b[36mno_write_dataset_2d.<locals>.raise_error_if_dataset_2d_present\u001b[39m\u001b[34m(store, adata, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m     msg = (\n\u001b[32m    319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWriting AnnData objects with a Dataset2D not supported yet. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease use `ds.to_memory` to bring the dataset into memory. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that if you have generated this object by concatenating several `AnnData` objects\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe original types may be lost.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/anndata/_io/h5ad.py:82\u001b[39m, in \u001b[36mwrite_h5ad\u001b[39m\u001b[34m(filepath, adata, as_dense, convert_strings_to_categoricals, dataset_kwargs, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m adata.isbacked:  \u001b[38;5;66;03m# close so that we can reopen below\u001b[39;00m\n\u001b[32m     80\u001b[39m     adata.file.close()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# TODO: Use spec writing system for this\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# Currently can't use write_dispatched here because this function is also called to do an\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# inplace update of a backed object, which would delete \"/\"\u001b[39;00m\n\u001b[32m     86\u001b[39m     f = cast(\u001b[33m\"\u001b[39m\u001b[33mh5py.Group\u001b[39m\u001b[33m\"\u001b[39m, f[\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     87\u001b[39m     f.attrs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mencoding-type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manndata\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/h5py/_hl/files.py:564\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[39m\n\u001b[32m    555\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    556\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    557\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    558\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    559\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    560\u001b[39m                      **kwds)\n\u001b[32m    561\u001b[39m     fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[32m    562\u001b[39m                      fs_persist=fs_persist, fs_threshold=fs_threshold,\n\u001b[32m    563\u001b[39m                      fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd1/tan/conda/miniconda3/envs/python312/lib/python3.12/site-packages/h5py/_hl/files.py:244\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    242\u001b[39m     fid = h5f.create(name, h5f.ACC_EXCL, fapl=fapl, fcpl=fcpl)\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mACC_TRUNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:122\u001b[39m, in \u001b[36mh5py.h5f.create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mBlockingIOError\u001b[39m: [Errno 11] Unable to synchronously create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')"
     ]
    }
   ],
   "source": [
    "data_dir = \"/mnt/hdd2/tan/competition_support_set_sorted/\"\n",
    "for cell_type in adata.obs.cell_type.unique():\n",
    "    print(\"Processing cell type: \", cell_type)\n",
    "    ct_adata = adata[adata.obs.cell_type == cell_type, ]\n",
    "    ct_adata = ct_adata[ct_adata.obs.target_gene.sort_values().index, ]\n",
    "    ct_adata.write_h5ad(f\"{data_dir}/jiang_{cell_type}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274cf0bf-b969-469c-b85a-6898bbe7191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(\"/mnt/hdd2/tan/competition_support_set_sorted/jiang_ht29.h5\", \"r\")\n",
    "adata.obs.target_gene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
